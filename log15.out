PIL version:  7.0.0.post3
torch version: 1.4.0
cuda version: 10.1
cudnn version:  7603
{'adam': False,
 'batch_size': 64,
 'cosine': False,
 'data_aug': True,
 'data_root': './data/miniImageNet',
 'dataset': 'miniImageNet',
 'epochs': 100,
 'eval_freq': 10,
 'learning_rate': 0.05,
 'lr_decay_epochs': [60, 80],
 'lr_decay_rate': 0.1,
 'model': 'resnet12',
 'model_name': 'resnet12_miniImageNet_lr_0.05_decay_0.0005_trans_A_trial_15',
 'model_path': './models_pretrained',
 'momentum': 0.9,
 'n_aug_support_samples': 5,
 'n_gpu': 1,
 'n_queries': 15,
 'n_shots': 1,
 'n_test_runs': 600,
 'n_ways': 5,
 'num_workers': 0,
 'print_freq': 100,
 'save_folder': './models_pretrained/resnet12_miniImageNet_lr_0.05_decay_0.0005_trans_A_trial_15',
 'save_freq': 10,
 'smoothing': 0.5,
 'tb_folder': './tensorboard/resnet12_miniImageNet_lr_0.05_decay_0.0005_trans_A_trial_15',
 'tb_freq': 500,
 'tb_path': './tensorboard',
 'test_batch_size': 1,
 'transform': 'A',
 'trial': '15',
 'use_trainval': False,
 'weight_decay': 0.0005}
==> training...
Epoch: [1][0/600]	Time 0.775 (0.775)	Data 0.257 (0.257)	Loss 4.4938 (4.4938)	Acc@1 1.562 (1.562)	Acc@5 10.938 (10.938)
Epoch: [1][100/600]	Time 0.282 (0.268)	Data 0.206 (0.189)	Loss 4.1162 (4.2072)	Acc@1 4.688 (5.616)	Acc@5 20.312 (19.771)
Epoch: [1][200/600]	Time 0.279 (0.286)	Data 0.204 (0.204)	Loss 4.0851 (4.1374)	Acc@1 7.812 (7.331)	Acc@5 28.125 (23.624)
Epoch: [1][300/600]	Time 0.227 (0.289)	Data 0.158 (0.208)	Loss 3.9326 (4.1016)	Acc@1 21.875 (8.503)	Acc@5 53.125 (26.781)
Epoch: [1][400/600]	Time 0.258 (0.287)	Data 0.175 (0.207)	Loss 3.9476 (4.0777)	Acc@1 15.625 (9.465)	Acc@5 45.312 (29.134)
Epoch: [1][500/600]	Time 0.212 (0.285)	Data 0.142 (0.206)	Loss 3.9610 (4.0573)	Acc@1 10.938 (10.292)	Acc@5 42.188 (31.156)
 * Acc@1 11.172 Acc@5 33.008
epoch 1, total time 168.99
Test: [0/586]	Time 0.064 (0.064)	Loss 4.1433 (4.1433)	Acc@1 3.125 (3.125)	Acc@5 15.625 (15.625)
Test: [100/586]	Time 0.065 (0.065)	Loss 4.0743 (4.0324)	Acc@1 6.250 (11.819)	Acc@5 31.250 (36.479)
Test: [200/586]	Time 0.062 (0.063)	Loss 3.8016 (3.9721)	Acc@1 21.875 (15.641)	Acc@5 59.375 (40.314)
Test: [300/586]	Time 0.053 (0.064)	Loss 3.7252 (3.9650)	Acc@1 34.375 (15.199)	Acc@5 81.250 (41.777)
Test: [400/586]	Time 0.064 (0.066)	Loss 4.2794 (3.9585)	Acc@1 0.000 (15.804)	Acc@5 0.000 (42.495)
Test: [500/586]	Time 0.053 (0.066)	Loss 3.6642 (3.9452)	Acc@1 59.375 (16.841)	Acc@5 93.750 (44.012)
 * Acc@1 17.607 Acc@5 45.402
==> training...
Epoch: [2][0/600]	Time 0.224 (0.224)	Data 0.157 (0.157)	Loss 3.9106 (3.9106)	Acc@1 17.188 (17.188)	Acc@5 46.875 (46.875)
Epoch: [2][100/600]	Time 0.270 (0.260)	Data 0.196 (0.187)	Loss 3.8484 (3.9218)	Acc@1 20.312 (18.178)	Acc@5 48.438 (45.823)
Epoch: [2][200/600]	Time 0.245 (0.269)	Data 0.172 (0.195)	Loss 3.9244 (3.9099)	Acc@1 18.750 (18.859)	Acc@5 42.188 (47.419)
Epoch: [2][300/600]	Time 0.265 (0.272)	Data 0.194 (0.197)	Loss 3.8317 (3.9021)	Acc@1 25.000 (19.466)	Acc@5 48.438 (48.635)
Epoch: [2][400/600]	Time 0.226 (0.268)	Data 0.153 (0.193)	Loss 3.8668 (3.8895)	Acc@1 17.188 (20.285)	Acc@5 56.250 (50.179)
Epoch: [2][500/600]	Time 0.288 (0.265)	Data 0.215 (0.191)	Loss 3.7711 (3.8778)	Acc@1 32.812 (21.245)	Acc@5 62.500 (51.534)
 * Acc@1 22.013 Acc@5 52.648
epoch 2, total time 162.14
Test: [0/586]	Time 0.073 (0.073)	Loss 3.9378 (3.9378)	Acc@1 28.125 (28.125)	Acc@5 56.250 (56.250)
Test: [100/586]	Time 0.076 (0.077)	Loss 3.7163 (3.8873)	Acc@1 37.500 (20.483)	Acc@5 71.875 (50.835)
Test: [200/586]	Time 0.080 (0.080)	Loss 3.7670 (3.8211)	Acc@1 31.250 (26.026)	Acc@5 68.750 (55.224)
Test: [300/586]	Time 0.075 (0.078)	Loss 3.7675 (3.8158)	Acc@1 21.875 (26.360)	Acc@5 75.000 (57.226)
Test: [400/586]	Time 0.063 (0.077)	Loss 4.0937 (3.7911)	Acc@1 0.000 (28.390)	Acc@5 25.000 (60.139)
Test: [500/586]	Time 0.069 (0.075)	Loss 3.6595 (3.7973)	Acc@1 34.375 (27.289)	Acc@5 81.250 (59.375)
 * Acc@1 27.432 Acc@5 60.150
==> training...
Epoch: [3][0/600]	Time 0.263 (0.263)	Data 0.182 (0.182)	Loss 3.8301 (3.8301)	Acc@1 28.125 (28.125)	Acc@5 59.375 (59.375)
Epoch: [3][100/600]	Time 0.260 (0.269)	Data 0.190 (0.196)	Loss 3.8394 (3.7993)	Acc@1 25.000 (27.692)	Acc@5 57.812 (59.623)
Epoch: [3][200/600]	Time 0.281 (0.260)	Data 0.211 (0.187)	Loss 3.7806 (3.7940)	Acc@1 25.000 (27.938)	Acc@5 64.062 (59.771)
Epoch: [3][300/600]	Time 0.282 (0.269)	Data 0.209 (0.194)	Loss 3.7778 (3.7824)	Acc@1 23.438 (28.644)	Acc@5 57.812 (60.771)
Epoch: [3][400/600]	Time 0.298 (0.276)	Data 0.216 (0.200)	Loss 3.7166 (3.7707)	Acc@1 34.375 (29.602)	Acc@5 68.750 (61.752)
Epoch: [3][500/600]	Time 0.299 (0.282)	Data 0.212 (0.204)	Loss 3.7024 (3.7618)	Acc@1 35.938 (30.283)	Acc@5 67.188 (62.590)
 * Acc@1 30.938 Acc@5 63.135
epoch 3, total time 167.05
Test: [0/586]	Time 0.056 (0.056)	Loss 3.6947 (3.6947)	Acc@1 43.750 (43.750)	Acc@5 75.000 (75.000)
Test: [100/586]	Time 0.062 (0.067)	Loss 3.8795 (3.7334)	Acc@1 12.500 (34.499)	Acc@5 56.250 (62.469)
Test: [200/586]	Time 0.056 (0.067)	Loss 3.5736 (3.7385)	Acc@1 46.875 (32.354)	Acc@5 75.000 (62.655)
Test: [300/586]	Time 0.059 (0.065)	Loss 3.5748 (3.7334)	Acc@1 34.375 (31.904)	Acc@5 90.625 (64.493)
Test: [400/586]	Time 0.056 (0.064)	Loss 3.9842 (3.7180)	Acc@1 6.250 (33.603)	Acc@5 46.875 (65.609)
Test: [500/586]	Time 0.056 (0.064)	Loss 3.6923 (3.7292)	Acc@1 34.375 (32.310)	Acc@5 68.750 (65.039)
 * Acc@1 33.588 Acc@5 66.626
==> training...
Epoch: [4][0/600]	Time 0.219 (0.219)	Data 0.150 (0.150)	Loss 3.6008 (3.6008)	Acc@1 34.375 (34.375)	Acc@5 76.562 (76.562)
Epoch: [4][100/600]	Time 0.226 (0.293)	Data 0.153 (0.216)	Loss 3.6493 (3.7075)	Acc@1 31.250 (34.329)	Acc@5 82.812 (66.971)
Epoch: [4][200/600]	Time 0.238 (0.285)	Data 0.163 (0.208)	Loss 3.6354 (3.6963)	Acc@1 40.625 (35.098)	Acc@5 75.000 (68.035)
Epoch: [4][300/600]	Time 0.266 (0.289)	Data 0.184 (0.211)	Loss 3.6692 (3.6906)	Acc@1 35.938 (35.450)	Acc@5 70.312 (68.558)
Epoch: [4][400/600]	Time 0.262 (0.282)	Data 0.189 (0.205)	Loss 3.6647 (3.6862)	Acc@1 37.500 (35.914)	Acc@5 71.875 (68.832)
Epoch: [4][500/600]	Time 0.275 (0.280)	Data 0.199 (0.203)	Loss 3.6891 (3.6810)	Acc@1 32.812 (36.352)	Acc@5 70.312 (69.180)
 * Acc@1 36.870 Acc@5 69.633
epoch 4, total time 167.20
Test: [0/586]	Time 0.060 (0.060)	Loss 3.5953 (3.5953)	Acc@1 50.000 (50.000)	Acc@5 71.875 (71.875)
Test: [100/586]	Time 0.075 (0.078)	Loss 3.5922 (3.7256)	Acc@1 40.625 (35.551)	Acc@5 75.000 (65.532)
Test: [200/586]	Time 0.065 (0.077)	Loss 3.8556 (3.7158)	Acc@1 31.250 (34.981)	Acc@5 50.000 (66.060)
Test: [300/586]	Time 0.061 (0.079)	Loss 3.7000 (3.6948)	Acc@1 40.625 (37.002)	Acc@5 68.750 (67.203)
Test: [400/586]	Time 0.076 (0.078)	Loss 4.1257 (3.6774)	Acc@1 3.125 (38.272)	Acc@5 21.875 (68.228)
Test: [500/586]	Time 0.073 (0.079)	Loss 3.6166 (3.6857)	Acc@1 40.625 (37.594)	Acc@5 75.000 (68.014)
 * Acc@1 37.572 Acc@5 68.626
==> training...
Epoch: [5][0/600]	Time 0.292 (0.292)	Data 0.212 (0.212)	Loss 3.6814 (3.6814)	Acc@1 37.500 (37.500)	Acc@5 65.625 (65.625)
Epoch: [5][100/600]	Time 0.255 (0.287)	Data 0.183 (0.207)	Loss 3.6041 (3.6340)	Acc@1 45.312 (40.099)	Acc@5 78.125 (72.401)
Epoch: [5][200/600]	Time 0.213 (0.270)	Data 0.144 (0.194)	Loss 3.5737 (3.6227)	Acc@1 46.875 (41.123)	Acc@5 76.562 (73.049)
Epoch: [5][300/600]	Time 0.269 (0.252)	Data 0.197 (0.178)	Loss 3.5752 (3.6168)	Acc@1 57.812 (41.596)	Acc@5 73.438 (73.562)
Epoch: [5][400/600]	Time 0.199 (0.244)	Data 0.130 (0.171)	Loss 3.6770 (3.6120)	Acc@1 29.688 (41.911)	Acc@5 65.625 (73.975)
Epoch: [5][500/600]	Time 0.217 (0.242)	Data 0.142 (0.169)	Loss 3.6150 (3.6064)	Acc@1 42.188 (42.446)	Acc@5 73.438 (74.242)
 * Acc@1 42.922 Acc@5 74.599
epoch 5, total time 145.05
Test: [0/586]	Time 0.065 (0.065)	Loss 3.7698 (3.7698)	Acc@1 18.750 (18.750)	Acc@5 62.500 (62.500)
Test: [100/586]	Time 0.122 (0.075)	Loss 3.3722 (3.6764)	Acc@1 71.875 (37.314)	Acc@5 87.500 (71.040)
Test: [200/586]	Time 0.053 (0.079)	Loss 3.8353 (3.6863)	Acc@1 34.375 (37.562)	Acc@5 56.250 (67.491)
Test: [300/586]	Time 0.068 (0.072)	Loss 3.4042 (3.6332)	Acc@1 59.375 (41.507)	Acc@5 84.375 (71.875)
Test: [400/586]	Time 0.063 (0.070)	Loss 4.0491 (3.6101)	Acc@1 0.000 (43.454)	Acc@5 21.875 (73.075)
Test: [500/586]	Time 0.072 (0.070)	Loss 3.4424 (3.6170)	Acc@1 56.250 (42.652)	Acc@5 93.750 (72.829)
 * Acc@1 41.679 Acc@5 73.085
==> training...
Epoch: [6][0/600]	Time 0.300 (0.300)	Data 0.225 (0.225)	Loss 3.5780 (3.5780)	Acc@1 45.312 (45.312)	Acc@5 76.562 (76.562)
Epoch: [6][100/600]	Time 0.275 (0.285)	Data 0.192 (0.210)	Loss 3.5417 (3.5530)	Acc@1 45.312 (47.030)	Acc@5 82.812 (77.150)
Epoch: [6][200/600]	Time 0.311 (0.284)	Data 0.229 (0.209)	Loss 3.5812 (3.5547)	Acc@1 50.000 (46.992)	Acc@5 76.562 (77.130)
Epoch: [6][300/600]	Time 0.315 (0.278)	Data 0.240 (0.203)	Loss 3.5258 (3.5503)	Acc@1 45.312 (47.264)	Acc@5 82.812 (77.585)
Epoch: [6][400/600]	Time 0.264 (0.275)	Data 0.193 (0.200)	Loss 3.5677 (3.5472)	Acc@1 42.188 (47.475)	Acc@5 78.125 (77.692)
Epoch: [6][500/600]	Time 0.291 (0.276)	Data 0.215 (0.201)	Loss 3.6273 (3.5461)	Acc@1 40.625 (47.424)	Acc@5 73.438 (77.738)
 * Acc@1 47.615 Acc@5 78.018
epoch 6, total time 165.78
Test: [0/586]	Time 0.073 (0.073)	Loss 3.4904 (3.4904)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.072 (0.071)	Loss 3.4269 (3.6215)	Acc@1 56.250 (40.161)	Acc@5 75.000 (72.865)
Test: [200/586]	Time 0.074 (0.071)	Loss 3.4834 (3.5979)	Acc@1 59.375 (42.522)	Acc@5 84.375 (73.989)
Test: [300/586]	Time 0.067 (0.069)	Loss 3.4737 (3.5602)	Acc@1 56.250 (45.287)	Acc@5 81.250 (76.890)
Test: [400/586]	Time 0.063 (0.067)	Loss 4.0350 (3.5300)	Acc@1 9.375 (48.356)	Acc@5 40.625 (78.141)
Test: [500/586]	Time 0.053 (0.065)	Loss 3.3426 (3.5295)	Acc@1 62.500 (48.491)	Acc@5 90.625 (78.144)
 * Acc@1 49.013 Acc@5 79.080
==> training...
Epoch: [7][0/600]	Time 0.304 (0.304)	Data 0.234 (0.234)	Loss 3.4713 (3.4713)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Epoch: [7][100/600]	Time 0.304 (0.261)	Data 0.230 (0.187)	Loss 3.4948 (3.5109)	Acc@1 48.438 (50.186)	Acc@5 82.812 (79.734)
Epoch: [7][200/600]	Time 0.300 (0.277)	Data 0.227 (0.202)	Loss 3.4495 (3.5046)	Acc@1 53.125 (50.622)	Acc@5 84.375 (80.138)
Epoch: [7][300/600]	Time 0.289 (0.280)	Data 0.217 (0.204)	Loss 3.5472 (3.5020)	Acc@1 45.312 (50.597)	Acc@5 78.125 (80.378)
Epoch: [7][400/600]	Time 0.286 (0.278)	Data 0.207 (0.203)	Loss 3.4958 (3.5002)	Acc@1 53.125 (50.655)	Acc@5 81.250 (80.486)
Epoch: [7][500/600]	Time 0.255 (0.277)	Data 0.171 (0.202)	Loss 3.5260 (3.4940)	Acc@1 48.438 (51.185)	Acc@5 76.562 (80.857)
 * Acc@1 51.391 Acc@5 81.034
epoch 7, total time 166.33
Test: [0/586]	Time 0.062 (0.062)	Loss 4.0076 (4.0076)	Acc@1 12.500 (12.500)	Acc@5 43.750 (43.750)
Test: [100/586]	Time 0.079 (0.066)	Loss 3.3932 (3.6322)	Acc@1 53.125 (39.016)	Acc@5 87.500 (74.134)
Test: [200/586]	Time 0.073 (0.067)	Loss 3.3185 (3.5858)	Acc@1 71.875 (44.434)	Acc@5 90.625 (76.213)
Test: [300/586]	Time 0.074 (0.068)	Loss 3.4645 (3.5673)	Acc@1 56.250 (46.211)	Acc@5 84.375 (77.751)
Test: [400/586]	Time 0.054 (0.068)	Loss 3.8534 (3.5205)	Acc@1 28.125 (50.647)	Acc@5 46.875 (79.816)
Test: [500/586]	Time 0.078 (0.068)	Loss 3.2660 (3.5130)	Acc@1 75.000 (51.079)	Acc@5 93.750 (80.040)
 * Acc@1 51.595 Acc@5 80.894
==> training...
Epoch: [8][0/600]	Time 0.238 (0.238)	Data 0.162 (0.162)	Loss 3.4234 (3.4234)	Acc@1 54.688 (54.688)	Acc@5 85.938 (85.938)
Epoch: [8][100/600]	Time 0.254 (0.255)	Data 0.184 (0.182)	Loss 3.3560 (3.4577)	Acc@1 60.938 (54.084)	Acc@5 87.500 (82.828)
Epoch: [8][200/600]	Time 0.279 (0.251)	Data 0.204 (0.179)	Loss 3.4534 (3.4622)	Acc@1 50.000 (54.042)	Acc@5 85.938 (82.400)
Epoch: [8][300/600]	Time 0.262 (0.254)	Data 0.190 (0.181)	Loss 3.4734 (3.4573)	Acc@1 54.688 (54.553)	Acc@5 81.250 (82.859)
Epoch: [8][400/600]	Time 0.305 (0.256)	Data 0.229 (0.183)	Loss 3.4379 (3.4565)	Acc@1 60.938 (54.789)	Acc@5 79.688 (82.867)
Epoch: [8][500/600]	Time 0.236 (0.262)	Data 0.160 (0.189)	Loss 3.5280 (3.4540)	Acc@1 45.312 (54.900)	Acc@5 85.938 (82.866)
 * Acc@1 54.883 Acc@5 82.940
epoch 8, total time 157.06
Test: [0/586]	Time 0.057 (0.057)	Loss 3.7955 (3.7955)	Acc@1 21.875 (21.875)	Acc@5 59.375 (59.375)
Test: [100/586]	Time 0.066 (0.061)	Loss 3.4246 (3.6046)	Acc@1 71.875 (43.657)	Acc@5 78.125 (74.474)
Test: [200/586]	Time 0.070 (0.065)	Loss 3.6218 (3.5687)	Acc@1 34.375 (45.802)	Acc@5 75.000 (77.565)
Test: [300/586]	Time 0.054 (0.065)	Loss 3.3550 (3.5361)	Acc@1 62.500 (48.515)	Acc@5 87.500 (79.703)
Test: [400/586]	Time 0.064 (0.066)	Loss 3.7609 (3.4986)	Acc@1 28.125 (52.416)	Acc@5 65.625 (80.938)
Test: [500/586]	Time 0.071 (0.067)	Loss 3.2380 (3.4881)	Acc@1 87.500 (53.468)	Acc@5 100.000 (81.562)
 * Acc@1 54.075 Acc@5 82.398
==> training...
Epoch: [9][0/600]	Time 0.321 (0.321)	Data 0.246 (0.246)	Loss 3.4554 (3.4554)	Acc@1 46.875 (46.875)	Acc@5 85.938 (85.938)
Epoch: [9][100/600]	Time 0.255 (0.269)	Data 0.181 (0.194)	Loss 3.3610 (3.4244)	Acc@1 65.625 (57.735)	Acc@5 89.062 (84.715)
Epoch: [9][200/600]	Time 0.263 (0.276)	Data 0.194 (0.200)	Loss 3.4288 (3.4191)	Acc@1 54.688 (58.038)	Acc@5 84.375 (84.888)
Epoch: [9][300/600]	Time 0.213 (0.273)	Data 0.146 (0.197)	Loss 3.4132 (3.4187)	Acc@1 54.688 (57.807)	Acc@5 79.688 (84.811)
Epoch: [9][400/600]	Time 0.305 (0.274)	Data 0.233 (0.198)	Loss 3.4564 (3.4178)	Acc@1 56.250 (57.583)	Acc@5 84.375 (84.850)
Epoch: [9][500/600]	Time 0.270 (0.276)	Data 0.192 (0.200)	Loss 3.4694 (3.4167)	Acc@1 53.125 (57.635)	Acc@5 75.000 (84.890)
 * Acc@1 57.740 Acc@5 84.862
epoch 9, total time 167.17
Test: [0/586]	Time 0.054 (0.054)	Loss 3.3937 (3.3937)	Acc@1 71.875 (71.875)	Acc@5 75.000 (75.000)
Test: [100/586]	Time 0.070 (0.069)	Loss 3.2959 (3.5157)	Acc@1 71.875 (52.537)	Acc@5 100.000 (80.693)
Test: [200/586]	Time 0.055 (0.065)	Loss 3.3674 (3.4555)	Acc@1 62.500 (55.908)	Acc@5 96.875 (84.344)
Test: [300/586]	Time 0.052 (0.064)	Loss 3.3547 (3.4541)	Acc@1 65.625 (55.980)	Acc@5 81.250 (84.292)
Test: [400/586]	Time 0.076 (0.066)	Loss 3.9657 (3.4511)	Acc@1 21.875 (56.967)	Acc@5 43.750 (83.829)
Test: [500/586]	Time 0.065 (0.066)	Loss 3.3431 (3.4616)	Acc@1 65.625 (55.838)	Acc@5 90.625 (82.884)
 * Acc@1 56.070 Acc@5 83.156
==> training...
Epoch: [10][0/600]	Time 0.255 (0.255)	Data 0.180 (0.180)	Loss 3.3818 (3.3818)	Acc@1 53.125 (53.125)	Acc@5 93.750 (93.750)
Epoch: [10][100/600]	Time 0.289 (0.277)	Data 0.215 (0.201)	Loss 3.3699 (3.3895)	Acc@1 60.938 (59.375)	Acc@5 89.062 (85.829)
Epoch: [10][200/600]	Time 0.306 (0.281)	Data 0.232 (0.205)	Loss 3.3552 (3.3885)	Acc@1 70.312 (59.632)	Acc@5 87.500 (86.280)
Epoch: [10][300/600]	Time 0.298 (0.281)	Data 0.199 (0.205)	Loss 3.3625 (3.3910)	Acc@1 62.500 (59.193)	Acc@5 87.500 (86.135)
Epoch: [10][400/600]	Time 0.254 (0.274)	Data 0.179 (0.199)	Loss 3.4538 (3.3906)	Acc@1 54.688 (59.239)	Acc@5 81.250 (86.000)
Epoch: [10][500/600]	Time 0.298 (0.274)	Data 0.223 (0.200)	Loss 3.4074 (3.3887)	Acc@1 59.375 (59.559)	Acc@5 81.250 (86.037)
 * Acc@1 59.714 Acc@5 86.047
epoch 10, total time 165.91
Test: [0/586]	Time 0.063 (0.063)	Loss 3.5232 (3.5232)	Acc@1 43.750 (43.750)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.059 (0.067)	Loss 3.4594 (3.4922)	Acc@1 53.125 (52.228)	Acc@5 78.125 (80.941)
Test: [200/586]	Time 0.065 (0.067)	Loss 3.4885 (3.4395)	Acc@1 53.125 (57.525)	Acc@5 87.500 (84.251)
Test: [300/586]	Time 0.062 (0.066)	Loss 3.2160 (3.4238)	Acc@1 65.625 (58.970)	Acc@5 93.750 (84.821)
Test: [400/586]	Time 0.059 (0.067)	Loss 3.7458 (3.4107)	Acc@1 43.750 (60.201)	Acc@5 68.750 (85.147)
Test: [500/586]	Time 0.064 (0.067)	Loss 3.2998 (3.4155)	Acc@1 71.875 (59.306)	Acc@5 90.625 (85.030)
 * Acc@1 60.342 Acc@5 86.015
==> Saving...
==> training...
Epoch: [11][0/600]	Time 0.273 (0.273)	Data 0.193 (0.193)	Loss 3.3273 (3.3273)	Acc@1 67.188 (67.188)	Acc@5 90.625 (90.625)
Epoch: [11][100/600]	Time 0.245 (0.255)	Data 0.176 (0.182)	Loss 3.3399 (3.3636)	Acc@1 60.938 (61.433)	Acc@5 90.625 (87.113)
Epoch: [11][200/600]	Time 0.311 (0.268)	Data 0.239 (0.194)	Loss 3.3562 (3.3656)	Acc@1 64.062 (61.342)	Acc@5 90.625 (87.104)
Epoch: [11][300/600]	Time 0.242 (0.275)	Data 0.170 (0.201)	Loss 3.4138 (3.3631)	Acc@1 48.438 (61.675)	Acc@5 84.375 (87.054)
Epoch: [11][400/600]	Time 0.249 (0.278)	Data 0.179 (0.204)	Loss 3.3826 (3.3624)	Acc@1 62.500 (61.635)	Acc@5 89.062 (87.165)
Epoch: [11][500/600]	Time 0.199 (0.272)	Data 0.128 (0.199)	Loss 3.3623 (3.3633)	Acc@1 59.375 (61.624)	Acc@5 85.938 (87.194)
 * Acc@1 61.643 Acc@5 87.182
epoch 11, total time 160.87
Test: [0/586]	Time 0.057 (0.057)	Loss 3.2695 (3.2695)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.075 (0.065)	Loss 3.3965 (3.4743)	Acc@1 62.500 (50.031)	Acc@5 87.500 (85.056)
Test: [200/586]	Time 0.064 (0.064)	Loss 3.3507 (3.4455)	Acc@1 71.875 (54.073)	Acc@5 90.625 (84.624)
Test: [300/586]	Time 0.051 (0.065)	Loss 3.1832 (3.4233)	Acc@1 75.000 (56.260)	Acc@5 90.625 (85.673)
Test: [400/586]	Time 0.053 (0.062)	Loss 3.8068 (3.4138)	Acc@1 28.125 (57.520)	Acc@5 59.375 (85.256)
Test: [500/586]	Time 0.050 (0.061)	Loss 3.2252 (3.4074)	Acc@1 75.000 (58.277)	Acc@5 100.000 (85.660)
 * Acc@1 60.124 Acc@5 86.580
==> training...
Epoch: [12][0/600]	Time 0.191 (0.191)	Data 0.125 (0.125)	Loss 3.3988 (3.3988)	Acc@1 60.938 (60.938)	Acc@5 84.375 (84.375)
Epoch: [12][100/600]	Time 0.177 (0.231)	Data 0.111 (0.159)	Loss 3.3455 (3.3412)	Acc@1 60.938 (63.088)	Acc@5 89.062 (88.459)
Epoch: [12][200/600]	Time 0.232 (0.244)	Data 0.154 (0.171)	Loss 3.3681 (3.3433)	Acc@1 62.500 (63.355)	Acc@5 85.938 (88.005)
Epoch: [12][300/600]	Time 0.274 (0.250)	Data 0.203 (0.176)	Loss 3.3205 (3.3423)	Acc@1 59.375 (63.491)	Acc@5 90.625 (88.097)
Epoch: [12][400/600]	Time 0.289 (0.258)	Data 0.216 (0.184)	Loss 3.2957 (3.3417)	Acc@1 62.500 (63.478)	Acc@5 90.625 (88.104)
Epoch: [12][500/600]	Time 0.290 (0.263)	Data 0.212 (0.189)	Loss 3.3919 (3.3424)	Acc@1 56.250 (63.545)	Acc@5 87.500 (88.080)
 * Acc@1 63.419 Acc@5 88.065
epoch 12, total time 157.65
Test: [0/586]	Time 0.070 (0.070)	Loss 3.3406 (3.3406)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.053 (0.060)	Loss 3.3621 (3.4788)	Acc@1 84.375 (56.498)	Acc@5 96.875 (83.663)
Test: [200/586]	Time 0.066 (0.061)	Loss 3.4413 (3.4637)	Acc@1 56.250 (57.758)	Acc@5 78.125 (84.593)
Test: [300/586]	Time 0.064 (0.062)	Loss 3.1923 (3.4741)	Acc@1 75.000 (56.478)	Acc@5 90.625 (83.783)
Test: [400/586]	Time 0.061 (0.062)	Loss 3.8153 (3.4602)	Acc@1 25.000 (57.099)	Acc@5 56.250 (83.518)
Test: [500/586]	Time 0.068 (0.063)	Loss 3.1690 (3.4559)	Acc@1 71.875 (57.260)	Acc@5 96.875 (83.527)
 * Acc@1 57.958 Acc@5 84.062
==> training...
Epoch: [13][0/600]	Time 0.282 (0.282)	Data 0.208 (0.208)	Loss 3.4522 (3.4522)	Acc@1 51.562 (51.562)	Acc@5 78.125 (78.125)
Epoch: [13][100/600]	Time 0.256 (0.294)	Data 0.183 (0.217)	Loss 3.2775 (3.3156)	Acc@1 68.750 (65.671)	Acc@5 85.938 (89.171)
Epoch: [13][200/600]	Time 0.268 (0.293)	Data 0.190 (0.216)	Loss 3.3692 (3.3227)	Acc@1 60.938 (64.933)	Acc@5 85.938 (88.977)
Epoch: [13][300/600]	Time 0.258 (0.282)	Data 0.192 (0.207)	Loss 3.3765 (3.3220)	Acc@1 57.812 (64.909)	Acc@5 85.938 (88.907)
Epoch: [13][400/600]	Time 0.292 (0.279)	Data 0.216 (0.203)	Loss 3.4110 (3.3246)	Acc@1 53.125 (64.725)	Acc@5 87.500 (88.724)
Epoch: [13][500/600]	Time 0.294 (0.282)	Data 0.222 (0.206)	Loss 3.2448 (3.3247)	Acc@1 76.562 (64.755)	Acc@5 92.188 (88.748)
 * Acc@1 64.727 Acc@5 88.758
epoch 13, total time 167.49
Test: [0/586]	Time 0.065 (0.065)	Loss 3.4060 (3.4060)	Acc@1 53.125 (53.125)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.052 (0.060)	Loss 3.4782 (3.4523)	Acc@1 50.000 (53.527)	Acc@5 84.375 (83.942)
Test: [200/586]	Time 0.050 (0.057)	Loss 3.4512 (3.4279)	Acc@1 43.750 (57.090)	Acc@5 84.375 (85.292)
Test: [300/586]	Time 0.049 (0.056)	Loss 3.1902 (3.4366)	Acc@1 78.125 (56.665)	Acc@5 96.875 (84.728)
Test: [400/586]	Time 0.072 (0.056)	Loss 3.6586 (3.4017)	Acc@1 40.625 (59.897)	Acc@5 75.000 (85.754)
Test: [500/586]	Time 0.050 (0.056)	Loss 3.2846 (3.3909)	Acc@1 71.875 (61.009)	Acc@5 90.625 (86.309)
 * Acc@1 61.324 Acc@5 86.841
==> training...
Epoch: [14][0/600]	Time 0.243 (0.243)	Data 0.174 (0.174)	Loss 3.2216 (3.2216)	Acc@1 70.312 (70.312)	Acc@5 92.188 (92.188)
Epoch: [14][100/600]	Time 0.218 (0.239)	Data 0.149 (0.169)	Loss 3.3455 (3.3049)	Acc@1 65.625 (66.259)	Acc@5 84.375 (89.913)
Epoch: [14][200/600]	Time 0.275 (0.260)	Data 0.198 (0.188)	Loss 3.4157 (3.3083)	Acc@1 60.938 (66.123)	Acc@5 85.938 (89.801)
Epoch: [14][300/600]	Time 0.263 (0.265)	Data 0.194 (0.192)	Loss 3.3666 (3.3089)	Acc@1 59.375 (66.103)	Acc@5 87.500 (89.613)
Epoch: [14][400/600]	Time 0.196 (0.266)	Data 0.125 (0.193)	Loss 3.3995 (3.3122)	Acc@1 57.812 (65.824)	Acc@5 85.938 (89.351)
Epoch: [14][500/600]	Time 0.261 (0.269)	Data 0.189 (0.195)	Loss 3.3264 (3.3141)	Acc@1 65.625 (65.619)	Acc@5 95.312 (89.240)
 * Acc@1 65.617 Acc@5 89.234
epoch 14, total time 163.78
Test: [0/586]	Time 0.074 (0.074)	Loss 3.4620 (3.4620)	Acc@1 56.250 (56.250)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.067 (0.073)	Loss 3.3289 (3.4349)	Acc@1 75.000 (55.879)	Acc@5 96.875 (82.457)
Test: [200/586]	Time 0.066 (0.081)	Loss 3.3298 (3.3796)	Acc@1 75.000 (61.971)	Acc@5 96.875 (85.790)
Test: [300/586]	Time 0.066 (0.078)	Loss 3.3383 (3.3573)	Acc@1 59.375 (62.832)	Acc@5 93.750 (87.510)
Test: [400/586]	Time 0.080 (0.076)	Loss 4.0019 (3.3598)	Acc@1 21.875 (62.975)	Acc@5 34.375 (86.908)
Test: [500/586]	Time 0.060 (0.075)	Loss 3.2259 (3.3695)	Acc@1 81.250 (62.506)	Acc@5 93.750 (86.627)
 * Acc@1 62.796 Acc@5 87.540
==> training...
Epoch: [15][0/600]	Time 0.283 (0.283)	Data 0.212 (0.212)	Loss 3.1835 (3.1835)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Epoch: [15][100/600]	Time 0.239 (0.295)	Data 0.169 (0.217)	Loss 3.2275 (3.2827)	Acc@1 70.312 (68.564)	Acc@5 89.062 (90.455)
Epoch: [15][200/600]	Time 0.276 (0.286)	Data 0.203 (0.210)	Loss 3.3505 (3.2880)	Acc@1 60.938 (67.957)	Acc@5 89.062 (90.361)
Epoch: [15][300/600]	Time 0.289 (0.288)	Data 0.216 (0.213)	Loss 3.3302 (3.2933)	Acc@1 65.625 (67.297)	Acc@5 90.625 (90.376)
Epoch: [15][400/600]	Time 0.224 (0.285)	Data 0.155 (0.210)	Loss 3.3393 (3.2930)	Acc@1 67.188 (67.359)	Acc@5 85.938 (90.247)
Epoch: [15][500/600]	Time 0.220 (0.279)	Data 0.149 (0.205)	Loss 3.2651 (3.2947)	Acc@1 73.438 (67.253)	Acc@5 87.500 (90.092)
 * Acc@1 67.000 Acc@5 89.932
epoch 15, total time 165.63
Test: [0/586]	Time 0.059 (0.059)	Loss 3.4421 (3.4421)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.056 (0.056)	Loss 3.5362 (3.4358)	Acc@1 43.750 (58.880)	Acc@5 84.375 (85.582)
Test: [200/586]	Time 0.055 (0.057)	Loss 3.3631 (3.4071)	Acc@1 62.500 (62.889)	Acc@5 96.875 (87.065)
Test: [300/586]	Time 0.057 (0.058)	Loss 3.2901 (3.3984)	Acc@1 65.625 (62.915)	Acc@5 90.625 (87.375)
Test: [400/586]	Time 0.061 (0.058)	Loss 3.9991 (3.3876)	Acc@1 21.875 (64.253)	Acc@5 37.500 (87.508)
Test: [500/586]	Time 0.066 (0.059)	Loss 3.3668 (3.3927)	Acc@1 71.875 (63.074)	Acc@5 84.375 (86.995)
 * Acc@1 62.753 Acc@5 87.487
==> training...
Epoch: [16][0/600]	Time 0.246 (0.246)	Data 0.177 (0.177)	Loss 3.1998 (3.1998)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Epoch: [16][100/600]	Time 0.330 (0.256)	Data 0.247 (0.183)	Loss 3.2253 (3.2709)	Acc@1 64.062 (69.059)	Acc@5 92.188 (90.919)
Epoch: [16][200/600]	Time 0.288 (0.266)	Data 0.215 (0.192)	Loss 3.3262 (3.2765)	Acc@1 68.750 (68.641)	Acc@5 89.062 (90.812)
Epoch: [16][300/600]	Time 0.246 (0.273)	Data 0.172 (0.198)	Loss 3.3220 (3.2820)	Acc@1 65.625 (67.977)	Acc@5 87.500 (90.630)
Epoch: [16][400/600]	Time 0.321 (0.277)	Data 0.223 (0.202)	Loss 3.2865 (3.2828)	Acc@1 68.750 (67.901)	Acc@5 90.625 (90.516)
Epoch: [16][500/600]	Time 0.220 (0.276)	Data 0.150 (0.201)	Loss 3.3732 (3.2860)	Acc@1 56.250 (67.755)	Acc@5 85.938 (90.357)
 * Acc@1 67.602 Acc@5 90.190
epoch 16, total time 166.37
Test: [0/586]	Time 0.070 (0.070)	Loss 3.3352 (3.3352)	Acc@1 59.375 (59.375)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.057 (0.065)	Loss 3.3788 (3.4486)	Acc@1 71.875 (54.425)	Acc@5 96.875 (84.684)
Test: [200/586]	Time 0.063 (0.067)	Loss 3.3210 (3.3752)	Acc@1 75.000 (62.718)	Acc@5 100.000 (87.858)
Test: [300/586]	Time 0.081 (0.068)	Loss 3.2097 (3.3606)	Acc@1 78.125 (64.338)	Acc@5 87.500 (88.611)
Test: [400/586]	Time 0.058 (0.068)	Loss 3.6731 (3.3443)	Acc@1 31.250 (65.625)	Acc@5 68.750 (88.825)
Test: [500/586]	Time 0.078 (0.069)	Loss 3.1821 (3.3454)	Acc@1 75.000 (65.519)	Acc@5 93.750 (89.003)
 * Acc@1 65.474 Acc@5 89.049
==> training...
Epoch: [17][0/600]	Time 0.336 (0.336)	Data 0.264 (0.264)	Loss 3.2422 (3.2422)	Acc@1 68.750 (68.750)	Acc@5 92.188 (92.188)
Epoch: [17][100/600]	Time 0.311 (0.291)	Data 0.240 (0.214)	Loss 3.2342 (3.2654)	Acc@1 75.000 (69.508)	Acc@5 92.188 (91.476)
Epoch: [17][200/600]	Time 0.241 (0.283)	Data 0.170 (0.208)	Loss 3.3321 (3.2672)	Acc@1 60.938 (69.146)	Acc@5 84.375 (91.294)
Epoch: [17][300/600]	Time 0.313 (0.282)	Data 0.238 (0.206)	Loss 3.3361 (3.2730)	Acc@1 59.375 (68.683)	Acc@5 90.625 (91.066)
Epoch: [17][400/600]	Time 0.286 (0.286)	Data 0.215 (0.210)	Loss 3.2646 (3.2790)	Acc@1 67.188 (68.247)	Acc@5 95.312 (90.796)
Epoch: [17][500/600]	Time 0.249 (0.288)	Data 0.178 (0.212)	Loss 3.2035 (3.2804)	Acc@1 76.562 (68.129)	Acc@5 95.312 (90.672)
 * Acc@1 68.151 Acc@5 90.674
epoch 17, total time 171.92
Test: [0/586]	Time 0.060 (0.060)	Loss 3.4805 (3.4805)	Acc@1 62.500 (62.500)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.074 (0.073)	Loss 3.4309 (3.4834)	Acc@1 56.250 (55.476)	Acc@5 87.500 (84.468)
Test: [200/586]	Time 0.056 (0.069)	Loss 3.2258 (3.4357)	Acc@1 71.875 (58.924)	Acc@5 100.000 (85.090)
Test: [300/586]	Time 0.066 (0.067)	Loss 3.2665 (3.4087)	Acc@1 71.875 (61.109)	Acc@5 93.750 (85.943)
Test: [400/586]	Time 0.066 (0.066)	Loss 3.8114 (3.3968)	Acc@1 31.250 (62.827)	Acc@5 62.500 (86.339)
Test: [500/586]	Time 0.059 (0.070)	Loss 3.2835 (3.3974)	Acc@1 81.250 (62.587)	Acc@5 100.000 (86.577)
 * Acc@1 63.052 Acc@5 87.396
==> training...
Epoch: [18][0/600]	Time 0.353 (0.353)	Data 0.278 (0.278)	Loss 3.2324 (3.2324)	Acc@1 73.438 (73.438)	Acc@5 92.188 (92.188)
Epoch: [18][100/600]	Time 0.284 (0.288)	Data 0.209 (0.211)	Loss 3.3789 (3.2656)	Acc@1 59.375 (69.493)	Acc@5 87.500 (91.399)
Epoch: [18][200/600]	Time 0.281 (0.288)	Data 0.207 (0.211)	Loss 3.2623 (3.2637)	Acc@1 71.875 (69.512)	Acc@5 92.188 (91.224)
Epoch: [18][300/600]	Time 0.249 (0.283)	Data 0.176 (0.207)	Loss 3.2477 (3.2697)	Acc@1 73.438 (68.978)	Acc@5 93.750 (91.071)
Epoch: [18][400/600]	Time 0.245 (0.277)	Data 0.174 (0.202)	Loss 3.2351 (3.2743)	Acc@1 73.438 (68.575)	Acc@5 90.625 (90.793)
Epoch: [18][500/600]	Time 0.281 (0.278)	Data 0.206 (0.203)	Loss 3.2115 (3.2751)	Acc@1 76.562 (68.525)	Acc@5 92.188 (90.709)
 * Acc@1 68.609 Acc@5 90.753
epoch 18, total time 167.01
Test: [0/586]	Time 0.079 (0.079)	Loss 3.6261 (3.6261)	Acc@1 43.750 (43.750)	Acc@5 71.875 (71.875)
Test: [100/586]	Time 0.080 (0.070)	Loss 3.3418 (3.4715)	Acc@1 62.500 (56.590)	Acc@5 90.625 (83.014)
Test: [200/586]	Time 0.073 (0.070)	Loss 3.1952 (3.4025)	Acc@1 81.250 (61.878)	Acc@5 100.000 (85.945)
Test: [300/586]	Time 0.058 (0.070)	Loss 3.1840 (3.3774)	Acc@1 78.125 (64.774)	Acc@5 96.875 (87.490)
Test: [400/586]	Time 0.072 (0.069)	Loss 3.7864 (3.3500)	Acc@1 25.000 (66.381)	Acc@5 75.000 (87.905)
Test: [500/586]	Time 0.061 (0.069)	Loss 3.2989 (3.3484)	Acc@1 75.000 (66.473)	Acc@5 96.875 (88.018)
 * Acc@1 64.924 Acc@5 88.063
==> training...
Epoch: [19][0/600]	Time 0.245 (0.245)	Data 0.170 (0.170)	Loss 3.2686 (3.2686)	Acc@1 67.188 (67.188)	Acc@5 92.188 (92.188)
Epoch: [19][100/600]	Time 0.286 (0.273)	Data 0.213 (0.199)	Loss 3.3269 (3.2583)	Acc@1 64.062 (70.173)	Acc@5 92.188 (91.770)
Epoch: [19][200/600]	Time 0.270 (0.279)	Data 0.200 (0.204)	Loss 3.2026 (3.2581)	Acc@1 76.562 (69.932)	Acc@5 95.312 (91.721)
Epoch: [19][300/600]	Time 0.279 (0.283)	Data 0.199 (0.208)	Loss 3.3307 (3.2623)	Acc@1 57.812 (69.409)	Acc@5 95.312 (91.419)
Epoch: [19][400/600]	Time 0.271 (0.279)	Data 0.192 (0.205)	Loss 3.1886 (3.2630)	Acc@1 76.562 (69.366)	Acc@5 95.312 (91.474)
Epoch: [19][500/600]	Time 0.279 (0.276)	Data 0.201 (0.202)	Loss 3.2052 (3.2648)	Acc@1 75.000 (69.249)	Acc@5 95.312 (91.398)
 * Acc@1 69.161 Acc@5 91.263
epoch 19, total time 163.51
Test: [0/586]	Time 0.085 (0.085)	Loss 3.3631 (3.3631)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.069 (0.065)	Loss 3.4758 (3.3595)	Acc@1 56.250 (63.861)	Acc@5 84.375 (88.861)
Test: [200/586]	Time 0.054 (0.068)	Loss 3.2279 (3.3341)	Acc@1 75.000 (65.641)	Acc@5 100.000 (89.241)
Test: [300/586]	Time 0.053 (0.068)	Loss 3.3252 (3.3396)	Acc@1 65.625 (65.635)	Acc@5 87.500 (89.587)
Test: [400/586]	Time 0.073 (0.067)	Loss 3.7444 (3.3349)	Acc@1 31.250 (67.526)	Acc@5 68.750 (89.760)
Test: [500/586]	Time 0.051 (0.067)	Loss 3.3813 (3.3377)	Acc@1 62.500 (66.729)	Acc@5 90.625 (89.658)
 * Acc@1 66.983 Acc@5 89.988
==> training...
Epoch: [20][0/600]	Time 0.320 (0.320)	Data 0.244 (0.244)	Loss 3.2049 (3.2049)	Acc@1 73.438 (73.438)	Acc@5 95.312 (95.312)
Epoch: [20][100/600]	Time 0.321 (0.278)	Data 0.237 (0.203)	Loss 3.2448 (3.2492)	Acc@1 68.750 (70.777)	Acc@5 89.062 (92.048)
Epoch: [20][200/600]	Time 0.262 (0.273)	Data 0.189 (0.198)	Loss 3.2256 (3.2500)	Acc@1 76.562 (70.569)	Acc@5 96.875 (91.861)
Epoch: [20][300/600]	Time 0.269 (0.269)	Data 0.197 (0.195)	Loss 3.2598 (3.2540)	Acc@1 73.438 (70.209)	Acc@5 90.625 (91.788)
Epoch: [20][400/600]	Time 0.216 (0.269)	Data 0.147 (0.195)	Loss 3.2847 (3.2569)	Acc@1 70.312 (69.981)	Acc@5 89.062 (91.521)
Epoch: [20][500/600]	Time 0.282 (0.269)	Data 0.211 (0.195)	Loss 3.2418 (3.2577)	Acc@1 78.125 (70.085)	Acc@5 90.625 (91.458)
 * Acc@1 69.781 Acc@5 91.385
epoch 20, total time 160.41
Test: [0/586]	Time 0.090 (0.090)	Loss 3.5037 (3.5037)	Acc@1 62.500 (62.500)	Acc@5 75.000 (75.000)
Test: [100/586]	Time 0.069 (0.072)	Loss 3.3523 (3.5109)	Acc@1 59.375 (52.939)	Acc@5 90.625 (82.271)
Test: [200/586]	Time 0.061 (0.071)	Loss 3.2889 (3.4541)	Acc@1 65.625 (57.509)	Acc@5 96.875 (85.463)
Test: [300/586]	Time 0.087 (0.070)	Loss 3.7581 (3.4370)	Acc@1 87.500 (60.008)	Acc@5 100.000 (86.815)
Test: [400/586]	Time 0.056 (0.068)	Loss 3.6237 (3.4299)	Acc@1 62.500 (61.954)	Acc@5 84.375 (86.845)
Test: [500/586]	Time 0.074 (0.068)	Loss 3.2636 (3.4310)	Acc@1 78.125 (61.864)	Acc@5 87.500 (86.733)
 * Acc@1 61.740 Acc@5 87.033
==> Saving...
==> training...
Epoch: [21][0/600]	Time 0.278 (0.278)	Data 0.200 (0.200)	Loss 3.2235 (3.2235)	Acc@1 73.438 (73.438)	Acc@5 92.188 (92.188)
Epoch: [21][100/600]	Time 0.247 (0.262)	Data 0.175 (0.189)	Loss 3.2127 (3.2437)	Acc@1 70.312 (71.411)	Acc@5 96.875 (92.203)
Epoch: [21][200/600]	Time 0.299 (0.267)	Data 0.224 (0.193)	Loss 3.1567 (3.2439)	Acc@1 78.125 (71.284)	Acc@5 95.312 (92.289)
Epoch: [21][300/600]	Time 0.260 (0.265)	Data 0.190 (0.192)	Loss 3.2865 (3.2466)	Acc@1 62.500 (70.702)	Acc@5 89.062 (91.990)
Epoch: [21][400/600]	Time 0.259 (0.265)	Data 0.187 (0.192)	Loss 3.2786 (3.2475)	Acc@1 67.188 (70.620)	Acc@5 92.188 (91.950)
Epoch: [21][500/600]	Time 0.230 (0.258)	Data 0.156 (0.186)	Loss 3.2943 (3.2498)	Acc@1 65.625 (70.431)	Acc@5 89.062 (91.763)
 * Acc@1 70.255 Acc@5 91.661
epoch 21, total time 152.59
Test: [0/586]	Time 0.066 (0.066)	Loss 3.4465 (3.4465)	Acc@1 65.625 (65.625)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.059 (0.060)	Loss 3.4426 (3.5765)	Acc@1 62.500 (51.671)	Acc@5 78.125 (82.550)
Test: [200/586]	Time 0.051 (0.059)	Loss 3.2252 (3.5032)	Acc@1 78.125 (61.754)	Acc@5 93.750 (86.707)
Test: [300/586]	Time 0.055 (0.057)	Loss 3.6797 (3.4803)	Acc@1 40.625 (61.400)	Acc@5 78.125 (87.656)
Test: [400/586]	Time 0.053 (0.058)	Loss 4.0767 (3.4462)	Acc@1 15.625 (63.248)	Acc@5 46.875 (88.217)
Test: [500/586]	Time 0.059 (0.058)	Loss 3.4223 (3.4433)	Acc@1 68.750 (62.874)	Acc@5 87.500 (87.706)
 * Acc@1 62.945 Acc@5 87.849
==> training...
Epoch: [22][0/600]	Time 0.216 (0.216)	Data 0.146 (0.146)	Loss 3.2781 (3.2781)	Acc@1 62.500 (62.500)	Acc@5 92.188 (92.188)
Epoch: [22][100/600]	Time 0.221 (0.235)	Data 0.154 (0.164)	Loss 3.1750 (3.2326)	Acc@1 70.312 (71.689)	Acc@5 95.312 (92.404)
Epoch: [22][200/600]	Time 0.264 (0.238)	Data 0.191 (0.167)	Loss 3.3212 (3.2341)	Acc@1 67.188 (71.961)	Acc@5 87.500 (92.467)
Epoch: [22][300/600]	Time 0.221 (0.236)	Data 0.151 (0.165)	Loss 3.2293 (3.2376)	Acc@1 75.000 (71.673)	Acc@5 92.188 (92.473)
Epoch: [22][400/600]	Time 0.256 (0.236)	Data 0.185 (0.165)	Loss 3.3799 (3.2407)	Acc@1 53.125 (71.446)	Acc@5 85.938 (92.289)
Epoch: [22][500/600]	Time 0.232 (0.236)	Data 0.160 (0.165)	Loss 3.3512 (3.2461)	Acc@1 62.500 (70.933)	Acc@5 87.500 (91.982)
 * Acc@1 70.763 Acc@5 91.875
epoch 22, total time 142.02
Test: [0/586]	Time 0.069 (0.069)	Loss 3.3493 (3.3493)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.054 (0.063)	Loss 3.4975 (3.3924)	Acc@1 56.250 (62.902)	Acc@5 84.375 (85.922)
Test: [200/586]	Time 0.055 (0.063)	Loss 3.2265 (3.4079)	Acc@1 62.500 (61.039)	Acc@5 93.750 (84.795)
Test: [300/586]	Time 0.072 (0.062)	Loss 3.3361 (3.3722)	Acc@1 87.500 (64.151)	Acc@5 96.875 (86.991)
Test: [400/586]	Time 0.052 (0.062)	Loss 3.6174 (3.3616)	Acc@1 46.875 (65.243)	Acc@5 71.875 (86.861)
Test: [500/586]	Time 0.054 (0.062)	Loss 3.1849 (3.3532)	Acc@1 68.750 (65.613)	Acc@5 96.875 (87.388)
 * Acc@1 64.860 Acc@5 87.961
==> training...
Epoch: [23][0/600]	Time 0.267 (0.267)	Data 0.198 (0.198)	Loss 3.2404 (3.2404)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
Epoch: [23][100/600]	Time 0.258 (0.239)	Data 0.188 (0.168)	Loss 3.1995 (3.2322)	Acc@1 73.438 (72.618)	Acc@5 92.188 (92.311)
Epoch: [23][200/600]	Time 0.219 (0.237)	Data 0.150 (0.167)	Loss 3.2190 (3.2357)	Acc@1 75.000 (72.116)	Acc@5 95.312 (92.110)
Epoch: [23][300/600]	Time 0.206 (0.239)	Data 0.138 (0.168)	Loss 3.2714 (3.2369)	Acc@1 68.750 (71.750)	Acc@5 93.750 (92.141)
Epoch: [23][400/600]	Time 0.211 (0.240)	Data 0.142 (0.169)	Loss 3.2541 (3.2370)	Acc@1 68.750 (71.657)	Acc@5 92.188 (92.141)
Epoch: [23][500/600]	Time 0.196 (0.233)	Data 0.127 (0.162)	Loss 3.2511 (3.2397)	Acc@1 73.438 (71.423)	Acc@5 90.625 (92.019)
 * Acc@1 71.122 Acc@5 91.919
epoch 23, total time 135.70
Test: [0/586]	Time 0.057 (0.057)	Loss 3.3337 (3.3337)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.052 (0.056)	Loss 3.4457 (3.5142)	Acc@1 50.000 (50.959)	Acc@5 87.500 (82.797)
Test: [200/586]	Time 0.049 (0.054)	Loss 3.2714 (3.4254)	Acc@1 75.000 (60.137)	Acc@5 93.750 (86.754)
Test: [300/586]	Time 0.048 (0.054)	Loss 3.2846 (3.3940)	Acc@1 68.750 (62.105)	Acc@5 90.625 (87.718)
Test: [400/586]	Time 0.048 (0.053)	Loss 3.8132 (3.3748)	Acc@1 34.375 (63.926)	Acc@5 59.375 (87.890)
Test: [500/586]	Time 0.050 (0.053)	Loss 3.3180 (3.3883)	Acc@1 75.000 (63.311)	Acc@5 93.750 (87.406)
 * Acc@1 64.359 Acc@5 88.068
==> training...
Epoch: [24][0/600]	Time 0.252 (0.252)	Data 0.177 (0.177)	Loss 3.2204 (3.2204)	Acc@1 73.438 (73.438)	Acc@5 93.750 (93.750)
Epoch: [24][100/600]	Time 0.217 (0.239)	Data 0.148 (0.168)	Loss 3.2107 (3.2168)	Acc@1 71.875 (74.087)	Acc@5 96.875 (93.116)
Epoch: [24][200/600]	Time 0.256 (0.243)	Data 0.183 (0.171)	Loss 3.2239 (3.2260)	Acc@1 71.875 (72.831)	Acc@5 92.188 (92.592)
Epoch: [24][300/600]	Time 0.242 (0.244)	Data 0.168 (0.173)	Loss 3.2641 (3.2298)	Acc@1 71.875 (72.545)	Acc@5 92.188 (92.582)
Epoch: [24][400/600]	Time 0.209 (0.246)	Data 0.139 (0.175)	Loss 3.2456 (3.2325)	Acc@1 67.188 (72.245)	Acc@5 93.750 (92.511)
Epoch: [24][500/600]	Time 0.218 (0.248)	Data 0.140 (0.176)	Loss 3.2811 (3.2361)	Acc@1 64.062 (71.866)	Acc@5 90.625 (92.356)
 * Acc@1 71.781 Acc@5 92.232
epoch 24, total time 149.03
Test: [0/586]	Time 0.072 (0.072)	Loss 3.3085 (3.3085)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.052 (0.060)	Loss 3.3688 (3.3618)	Acc@1 71.875 (65.687)	Acc@5 90.625 (89.016)
Test: [200/586]	Time 0.076 (0.063)	Loss 3.2478 (3.3290)	Acc@1 71.875 (68.159)	Acc@5 93.750 (89.599)
Test: [300/586]	Time 0.065 (0.064)	Loss 3.1588 (3.3182)	Acc@1 71.875 (68.740)	Acc@5 90.625 (90.137)
Test: [400/586]	Time 0.059 (0.063)	Loss 3.7589 (3.3091)	Acc@1 21.875 (70.176)	Acc@5 71.875 (90.290)
Test: [500/586]	Time 0.052 (0.063)	Loss 3.0882 (3.3082)	Acc@1 90.625 (70.029)	Acc@5 96.875 (90.301)
 * Acc@1 70.418 Acc@5 90.879
==> training...
Epoch: [25][0/600]	Time 0.268 (0.268)	Data 0.197 (0.197)	Loss 3.2203 (3.2203)	Acc@1 73.438 (73.438)	Acc@5 96.875 (96.875)
Epoch: [25][100/600]	Time 0.267 (0.246)	Data 0.196 (0.174)	Loss 3.2505 (3.2248)	Acc@1 67.188 (72.989)	Acc@5 85.938 (92.837)
Epoch: [25][200/600]	Time 0.216 (0.247)	Data 0.147 (0.175)	Loss 3.1881 (3.2342)	Acc@1 73.438 (71.859)	Acc@5 95.312 (92.654)
Epoch: [25][300/600]	Time 0.209 (0.245)	Data 0.138 (0.174)	Loss 3.2346 (3.2344)	Acc@1 65.625 (71.974)	Acc@5 90.625 (92.483)
Epoch: [25][400/600]	Time 0.244 (0.244)	Data 0.175 (0.173)	Loss 3.2511 (3.2340)	Acc@1 73.438 (72.078)	Acc@5 96.875 (92.433)
Epoch: [25][500/600]	Time 0.229 (0.243)	Data 0.159 (0.172)	Loss 3.3193 (3.2358)	Acc@1 67.188 (71.869)	Acc@5 82.812 (92.306)
 * Acc@1 71.789 Acc@5 92.203
epoch 25, total time 146.47
Test: [0/586]	Time 0.072 (0.072)	Loss 3.3693 (3.3693)	Acc@1 71.875 (71.875)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.063 (0.062)	Loss 3.3948 (3.4238)	Acc@1 59.375 (58.694)	Acc@5 81.250 (84.746)
Test: [200/586]	Time 0.060 (0.064)	Loss 3.6793 (3.3760)	Acc@1 87.500 (65.174)	Acc@5 100.000 (87.826)
Test: [300/586]	Time 0.071 (0.068)	Loss 3.3027 (3.3695)	Acc@1 62.500 (65.667)	Acc@5 90.625 (87.915)
Test: [400/586]	Time 0.077 (0.067)	Loss 3.7193 (3.3477)	Acc@1 40.625 (67.495)	Acc@5 71.875 (88.786)
Test: [500/586]	Time 0.052 (0.065)	Loss 3.2789 (3.3436)	Acc@1 84.375 (67.927)	Acc@5 96.875 (89.047)
 * Acc@1 67.629 Acc@5 89.466
==> training...
Epoch: [26][0/600]	Time 0.279 (0.279)	Data 0.207 (0.207)	Loss 3.2937 (3.2937)	Acc@1 67.188 (67.188)	Acc@5 95.312 (95.312)
Epoch: [26][100/600]	Time 0.222 (0.252)	Data 0.153 (0.180)	Loss 3.2231 (3.2263)	Acc@1 81.250 (72.772)	Acc@5 90.625 (93.054)
Epoch: [26][200/600]	Time 0.272 (0.251)	Data 0.199 (0.179)	Loss 3.2073 (3.2255)	Acc@1 76.562 (73.041)	Acc@5 96.875 (92.864)
Epoch: [26][300/600]	Time 0.209 (0.248)	Data 0.140 (0.176)	Loss 3.2851 (3.2284)	Acc@1 71.875 (72.680)	Acc@5 90.625 (92.743)
Epoch: [26][400/600]	Time 0.197 (0.247)	Data 0.129 (0.176)	Loss 3.2177 (3.2325)	Acc@1 76.562 (72.269)	Acc@5 90.625 (92.452)
Epoch: [26][500/600]	Time 0.227 (0.247)	Data 0.157 (0.175)	Loss 3.2784 (3.2330)	Acc@1 67.188 (72.209)	Acc@5 87.500 (92.425)
 * Acc@1 71.932 Acc@5 92.237
epoch 26, total time 147.91
Test: [0/586]	Time 0.064 (0.064)	Loss 3.4776 (3.4776)	Acc@1 59.375 (59.375)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.073 (0.063)	Loss 3.3589 (3.4235)	Acc@1 62.500 (63.800)	Acc@5 87.500 (87.500)
Test: [200/586]	Time 0.052 (0.064)	Loss 3.1805 (3.3754)	Acc@1 84.375 (66.402)	Acc@5 100.000 (88.557)
Test: [300/586]	Time 0.053 (0.064)	Loss 3.1948 (3.3634)	Acc@1 81.250 (66.975)	Acc@5 93.750 (88.839)
Test: [400/586]	Time 0.060 (0.064)	Loss 3.5089 (3.3458)	Acc@1 59.375 (69.031)	Acc@5 93.750 (89.433)
Test: [500/586]	Time 0.055 (0.066)	Loss 3.2018 (3.3499)	Acc@1 90.625 (68.756)	Acc@5 96.875 (89.122)
 * Acc@1 67.917 Acc@5 89.306
==> training...
Epoch: [27][0/600]	Time 0.236 (0.236)	Data 0.165 (0.165)	Loss 3.1804 (3.1804)	Acc@1 76.562 (76.562)	Acc@5 95.312 (95.312)
Epoch: [27][100/600]	Time 0.216 (0.249)	Data 0.146 (0.177)	Loss 3.2003 (3.2246)	Acc@1 70.312 (72.772)	Acc@5 92.188 (93.162)
Epoch: [27][200/600]	Time 0.219 (0.246)	Data 0.151 (0.175)	Loss 3.1862 (3.2299)	Acc@1 76.562 (72.380)	Acc@5 92.188 (92.654)
Epoch: [27][300/600]	Time 0.254 (0.243)	Data 0.182 (0.171)	Loss 3.2390 (3.2309)	Acc@1 75.000 (72.290)	Acc@5 95.312 (92.608)
Epoch: [27][400/600]	Time 0.228 (0.244)	Data 0.158 (0.173)	Loss 3.2951 (3.2313)	Acc@1 70.312 (72.288)	Acc@5 89.062 (92.425)
Epoch: [27][500/600]	Time 0.254 (0.244)	Data 0.180 (0.173)	Loss 3.1974 (3.2322)	Acc@1 71.875 (72.181)	Acc@5 92.188 (92.337)
 * Acc@1 71.971 Acc@5 92.279
epoch 27, total time 148.14
Test: [0/586]	Time 0.065 (0.065)	Loss 3.5567 (3.5567)	Acc@1 50.000 (50.000)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.070 (0.061)	Loss 3.2431 (3.4006)	Acc@1 75.000 (59.994)	Acc@5 96.875 (84.375)
Test: [200/586]	Time 0.062 (0.063)	Loss 3.1803 (3.3788)	Acc@1 84.375 (63.122)	Acc@5 100.000 (85.588)
Test: [300/586]	Time 0.063 (0.063)	Loss 3.2608 (3.3737)	Acc@1 81.250 (63.839)	Acc@5 90.625 (86.047)
Test: [400/586]	Time 0.063 (0.063)	Loss 3.8311 (3.3570)	Acc@1 28.125 (65.851)	Acc@5 56.250 (87.212)
Test: [500/586]	Time 0.055 (0.062)	Loss 3.3806 (3.3475)	Acc@1 65.625 (66.448)	Acc@5 87.500 (87.612)
 * Acc@1 65.282 Acc@5 87.721
==> training...
Epoch: [28][0/600]	Time 0.259 (0.259)	Data 0.186 (0.186)	Loss 3.1922 (3.1922)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)
Epoch: [28][100/600]	Time 0.257 (0.243)	Data 0.179 (0.172)	Loss 3.2130 (3.2123)	Acc@1 76.562 (73.747)	Acc@5 95.312 (93.270)
Epoch: [28][200/600]	Time 0.199 (0.243)	Data 0.128 (0.172)	Loss 3.1936 (3.2171)	Acc@1 78.125 (73.469)	Acc@5 92.188 (93.159)
Epoch: [28][300/600]	Time 0.247 (0.243)	Data 0.174 (0.171)	Loss 3.2923 (3.2201)	Acc@1 67.188 (73.199)	Acc@5 87.500 (93.143)
Epoch: [28][400/600]	Time 0.254 (0.244)	Data 0.183 (0.172)	Loss 3.2457 (3.2242)	Acc@1 68.750 (72.869)	Acc@5 93.750 (92.865)
Epoch: [28][500/600]	Time 0.248 (0.244)	Data 0.179 (0.173)	Loss 3.2200 (3.2263)	Acc@1 67.188 (72.714)	Acc@5 93.750 (92.761)
 * Acc@1 72.474 Acc@5 92.641
epoch 28, total time 147.08
Test: [0/586]	Time 0.071 (0.071)	Loss 3.4717 (3.4717)	Acc@1 68.750 (68.750)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.054 (0.062)	Loss 3.4713 (3.4832)	Acc@1 53.125 (56.188)	Acc@5 78.125 (84.313)
Test: [200/586]	Time 0.068 (0.062)	Loss 3.2694 (3.4257)	Acc@1 75.000 (61.598)	Acc@5 96.875 (86.334)
Test: [300/586]	Time 0.053 (0.062)	Loss 3.3279 (3.4048)	Acc@1 87.500 (62.521)	Acc@5 96.875 (86.908)
Test: [400/586]	Time 0.061 (0.062)	Loss 3.5623 (3.3758)	Acc@1 56.250 (65.360)	Acc@5 87.500 (88.420)
Test: [500/586]	Time 0.062 (0.062)	Loss 3.2640 (3.3648)	Acc@1 68.750 (66.292)	Acc@5 90.625 (89.097)
 * Acc@1 66.514 Acc@5 89.652
==> training...
Epoch: [29][0/600]	Time 0.224 (0.224)	Data 0.152 (0.152)	Loss 3.2636 (3.2636)	Acc@1 73.438 (73.438)	Acc@5 95.312 (95.312)
Epoch: [29][100/600]	Time 0.261 (0.242)	Data 0.187 (0.170)	Loss 3.2583 (3.2003)	Acc@1 67.188 (74.536)	Acc@5 90.625 (93.796)
Epoch: [29][200/600]	Time 0.245 (0.249)	Data 0.174 (0.177)	Loss 3.2126 (3.2093)	Acc@1 70.312 (73.741)	Acc@5 90.625 (93.268)
Epoch: [29][300/600]	Time 0.258 (0.248)	Data 0.187 (0.176)	Loss 3.2433 (3.2146)	Acc@1 75.000 (73.510)	Acc@5 92.188 (93.049)
Epoch: [29][400/600]	Time 0.230 (0.247)	Data 0.163 (0.175)	Loss 3.1966 (3.2178)	Acc@1 68.750 (73.227)	Acc@5 96.875 (92.850)
Epoch: [29][500/600]	Time 0.241 (0.248)	Data 0.171 (0.176)	Loss 3.2786 (3.2214)	Acc@1 70.312 (72.979)	Acc@5 89.062 (92.730)
 * Acc@1 72.841 Acc@5 92.633
epoch 29, total time 148.58
Test: [0/586]	Time 0.095 (0.095)	Loss 3.3995 (3.3995)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.072 (0.062)	Loss 3.3661 (3.4179)	Acc@1 65.625 (59.870)	Acc@5 93.750 (85.241)
Test: [200/586]	Time 0.072 (0.062)	Loss 3.3843 (3.3446)	Acc@1 75.000 (66.760)	Acc@5 90.625 (88.573)
Test: [300/586]	Time 0.057 (0.063)	Loss 3.4089 (3.3329)	Acc@1 59.375 (68.106)	Acc@5 78.125 (89.099)
Test: [400/586]	Time 0.055 (0.062)	Loss 3.6887 (3.3376)	Acc@1 40.625 (68.392)	Acc@5 71.875 (89.207)
Test: [500/586]	Time 0.073 (0.062)	Loss 3.1118 (3.3377)	Acc@1 90.625 (67.927)	Acc@5 96.875 (89.290)
 * Acc@1 68.098 Acc@5 89.754
==> training...
Epoch: [30][0/600]	Time 0.234 (0.234)	Data 0.165 (0.165)	Loss 3.2265 (3.2265)	Acc@1 71.875 (71.875)	Acc@5 90.625 (90.625)
Epoch: [30][100/600]	Time 0.198 (0.252)	Data 0.128 (0.180)	Loss 3.2986 (3.2097)	Acc@1 65.625 (74.072)	Acc@5 89.062 (93.410)
Epoch: [30][200/600]	Time 0.215 (0.248)	Data 0.144 (0.176)	Loss 3.2244 (3.2172)	Acc@1 70.312 (73.484)	Acc@5 93.750 (93.175)
Epoch: [30][300/600]	Time 0.239 (0.246)	Data 0.165 (0.174)	Loss 3.2928 (3.2229)	Acc@1 67.188 (72.950)	Acc@5 84.375 (92.868)
Epoch: [30][400/600]	Time 0.237 (0.244)	Data 0.166 (0.173)	Loss 3.2342 (3.2223)	Acc@1 70.312 (72.900)	Acc@5 90.625 (92.897)
Epoch: [30][500/600]	Time 0.243 (0.245)	Data 0.165 (0.173)	Loss 3.2879 (3.2242)	Acc@1 62.500 (72.583)	Acc@5 93.750 (92.892)
 * Acc@1 72.466 Acc@5 92.753
epoch 30, total time 147.55
Test: [0/586]	Time 0.063 (0.063)	Loss 3.4316 (3.4316)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.061 (0.064)	Loss 3.4206 (3.4219)	Acc@1 65.625 (58.385)	Acc@5 90.625 (85.458)
Test: [200/586]	Time 0.064 (0.064)	Loss 3.2440 (3.3786)	Acc@1 75.000 (62.920)	Acc@5 96.875 (86.769)
Test: [300/586]	Time 0.052 (0.063)	Loss 3.3733 (3.3645)	Acc@1 81.250 (65.002)	Acc@5 100.000 (88.196)
Test: [400/586]	Time 0.062 (0.063)	Loss 3.6756 (3.3513)	Acc@1 46.875 (67.121)	Acc@5 75.000 (88.801)
Test: [500/586]	Time 0.062 (0.062)	Loss 3.4119 (3.3540)	Acc@1 56.250 (66.055)	Acc@5 78.125 (88.579)
 * Acc@1 66.562 Acc@5 89.007
==> Saving...
==> training...
Epoch: [31][0/600]	Time 0.286 (0.286)	Data 0.213 (0.213)	Loss 3.2420 (3.2420)	Acc@1 73.438 (73.438)	Acc@5 93.750 (93.750)
Epoch: [31][100/600]	Time 0.248 (0.251)	Data 0.177 (0.179)	Loss 3.2940 (3.2069)	Acc@1 71.875 (73.902)	Acc@5 90.625 (93.673)
Epoch: [31][200/600]	Time 0.225 (0.239)	Data 0.157 (0.168)	Loss 3.2299 (3.2081)	Acc@1 68.750 (73.741)	Acc@5 92.188 (93.361)
Epoch: [31][300/600]	Time 0.183 (0.231)	Data 0.117 (0.161)	Loss 3.3250 (3.2127)	Acc@1 64.062 (73.624)	Acc@5 90.625 (93.200)
Epoch: [31][400/600]	Time 0.222 (0.221)	Data 0.152 (0.152)	Loss 3.3119 (3.2176)	Acc@1 59.375 (73.130)	Acc@5 93.750 (93.049)
Epoch: [31][500/600]	Time 0.206 (0.220)	Data 0.135 (0.151)	Loss 3.1857 (3.2185)	Acc@1 78.125 (73.066)	Acc@5 95.312 (92.908)
 * Acc@1 73.029 Acc@5 92.904
epoch 31, total time 137.79
Test: [0/586]	Time 0.070 (0.070)	Loss 3.3729 (3.3729)	Acc@1 84.375 (84.375)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.069 (0.062)	Loss 3.3510 (3.3859)	Acc@1 71.875 (63.335)	Acc@5 93.750 (88.521)
Test: [200/586]	Time 0.064 (0.062)	Loss 3.0968 (3.3598)	Acc@1 87.500 (65.314)	Acc@5 96.875 (88.884)
Test: [300/586]	Time 0.063 (0.062)	Loss 3.1882 (3.3390)	Acc@1 78.125 (68.428)	Acc@5 93.750 (90.106)
Test: [400/586]	Time 0.069 (0.061)	Loss 3.9265 (3.3343)	Acc@1 28.125 (68.446)	Acc@5 59.375 (89.612)
Test: [500/586]	Time 0.063 (0.062)	Loss 3.2242 (3.3466)	Acc@1 68.750 (66.685)	Acc@5 93.750 (89.259)
 * Acc@1 67.405 Acc@5 89.796
==> training...
Epoch: [32][0/600]	Time 0.285 (0.285)	Data 0.210 (0.210)	Loss 3.3142 (3.3142)	Acc@1 67.188 (67.188)	Acc@5 89.062 (89.062)
Epoch: [32][100/600]	Time 0.240 (0.248)	Data 0.167 (0.176)	Loss 3.2393 (3.2081)	Acc@1 78.125 (74.134)	Acc@5 90.625 (93.533)
Epoch: [32][200/600]	Time 0.227 (0.246)	Data 0.156 (0.174)	Loss 3.2457 (3.2157)	Acc@1 75.000 (73.469)	Acc@5 93.750 (93.361)
Epoch: [32][300/600]	Time 0.277 (0.249)	Data 0.204 (0.177)	Loss 3.2790 (3.2180)	Acc@1 73.438 (73.297)	Acc@5 87.500 (93.137)
Epoch: [32][400/600]	Time 0.243 (0.246)	Data 0.173 (0.174)	Loss 3.2342 (3.2211)	Acc@1 73.438 (72.982)	Acc@5 93.750 (93.060)
Epoch: [32][500/600]	Time 0.274 (0.247)	Data 0.203 (0.175)	Loss 3.1744 (3.2214)	Acc@1 78.125 (72.876)	Acc@5 93.750 (93.011)
 * Acc@1 72.750 Acc@5 92.911
epoch 32, total time 148.20
Test: [0/586]	Time 0.080 (0.080)	Loss 3.3968 (3.3968)	Acc@1 65.625 (65.625)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.055 (0.062)	Loss 3.2755 (3.3810)	Acc@1 62.500 (62.871)	Acc@5 90.625 (85.427)
Test: [200/586]	Time 0.068 (0.063)	Loss 3.2115 (3.3590)	Acc@1 78.125 (64.988)	Acc@5 96.875 (86.987)
Test: [300/586]	Time 0.054 (0.064)	Loss 3.3117 (3.3743)	Acc@1 68.750 (63.268)	Acc@5 84.375 (86.493)
Test: [400/586]	Time 0.053 (0.064)	Loss 4.0488 (3.3640)	Acc@1 21.875 (64.051)	Acc@5 40.625 (86.012)
Test: [500/586]	Time 0.068 (0.064)	Loss 3.3320 (3.3648)	Acc@1 68.750 (64.602)	Acc@5 90.625 (86.053)
 * Acc@1 64.599 Acc@5 86.953
==> training...
Epoch: [33][0/600]	Time 0.292 (0.292)	Data 0.221 (0.221)	Loss 3.2720 (3.2720)	Acc@1 68.750 (68.750)	Acc@5 95.312 (95.312)
Epoch: [33][100/600]	Time 0.239 (0.249)	Data 0.166 (0.177)	Loss 3.2292 (3.2054)	Acc@1 76.562 (74.582)	Acc@5 96.875 (93.472)
Epoch: [33][200/600]	Time 0.210 (0.246)	Data 0.141 (0.174)	Loss 3.2787 (3.2112)	Acc@1 67.188 (74.207)	Acc@5 85.938 (93.175)
Epoch: [33][300/600]	Time 0.265 (0.242)	Data 0.185 (0.171)	Loss 3.2218 (3.2146)	Acc@1 70.312 (73.723)	Acc@5 95.312 (93.002)
Epoch: [33][400/600]	Time 0.224 (0.242)	Data 0.155 (0.171)	Loss 3.1342 (3.2140)	Acc@1 81.250 (73.582)	Acc@5 93.750 (93.154)
Epoch: [33][500/600]	Time 0.239 (0.244)	Data 0.166 (0.172)	Loss 3.2409 (3.2175)	Acc@1 71.875 (73.269)	Acc@5 93.750 (92.983)
 * Acc@1 73.073 Acc@5 92.922
epoch 33, total time 146.30
Test: [0/586]	Time 0.061 (0.061)	Loss 3.4882 (3.4882)	Acc@1 46.875 (46.875)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.061 (0.061)	Loss 3.2912 (3.4616)	Acc@1 68.750 (55.415)	Acc@5 96.875 (81.528)
Test: [200/586]	Time 0.061 (0.061)	Loss 3.2257 (3.3804)	Acc@1 68.750 (63.557)	Acc@5 96.875 (85.790)
Test: [300/586]	Time 0.053 (0.062)	Loss 3.3102 (3.3530)	Acc@1 87.500 (66.300)	Acc@5 100.000 (88.289)
Test: [400/586]	Time 0.065 (0.061)	Loss 3.6003 (3.3474)	Acc@1 50.000 (66.919)	Acc@5 78.125 (88.513)
Test: [500/586]	Time 0.060 (0.061)	Loss 3.2291 (3.3488)	Acc@1 71.875 (66.224)	Acc@5 93.750 (88.404)
 * Acc@1 65.858 Acc@5 88.708
==> training...
Epoch: [34][0/600]	Time 0.249 (0.249)	Data 0.181 (0.181)	Loss 3.3461 (3.3461)	Acc@1 59.375 (59.375)	Acc@5 82.812 (82.812)
Epoch: [34][100/600]	Time 0.230 (0.243)	Data 0.157 (0.172)	Loss 3.1849 (3.1988)	Acc@1 75.000 (75.186)	Acc@5 93.750 (93.332)
Epoch: [34][200/600]	Time 0.270 (0.240)	Data 0.196 (0.169)	Loss 3.2725 (3.2009)	Acc@1 62.500 (74.790)	Acc@5 90.625 (93.455)
Epoch: [34][300/600]	Time 0.213 (0.241)	Data 0.143 (0.170)	Loss 3.1974 (3.2062)	Acc@1 75.000 (74.242)	Acc@5 95.312 (93.407)
Epoch: [34][400/600]	Time 0.213 (0.241)	Data 0.145 (0.170)	Loss 3.1655 (3.2102)	Acc@1 81.250 (73.967)	Acc@5 98.438 (93.345)
Epoch: [34][500/600]	Time 0.251 (0.242)	Data 0.176 (0.171)	Loss 3.1684 (3.2124)	Acc@1 75.000 (73.650)	Acc@5 95.312 (93.276)
 * Acc@1 73.466 Acc@5 93.091
epoch 34, total time 145.83
Test: [0/586]	Time 0.072 (0.072)	Loss 3.2681 (3.2681)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.052 (0.062)	Loss 3.4449 (3.4063)	Acc@1 71.875 (59.808)	Acc@5 100.000 (86.355)
Test: [200/586]	Time 0.052 (0.061)	Loss 3.2863 (3.3901)	Acc@1 87.500 (65.050)	Acc@5 96.875 (87.609)
Test: [300/586]	Time 0.066 (0.061)	Loss 3.1536 (3.3657)	Acc@1 68.750 (66.653)	Acc@5 93.750 (88.611)
Test: [400/586]	Time 0.068 (0.061)	Loss 3.8227 (3.3414)	Acc@1 34.375 (68.430)	Acc@5 59.375 (89.401)
Test: [500/586]	Time 0.054 (0.061)	Loss 3.1882 (3.3345)	Acc@1 90.625 (68.906)	Acc@5 96.875 (89.727)
 * Acc@1 68.567 Acc@5 90.207
==> training...
Epoch: [35][0/600]	Time 0.207 (0.207)	Data 0.135 (0.135)	Loss 3.1236 (3.1236)	Acc@1 84.375 (84.375)	Acc@5 96.875 (96.875)
Epoch: [35][100/600]	Time 0.271 (0.254)	Data 0.192 (0.182)	Loss 3.2198 (3.1985)	Acc@1 70.312 (74.722)	Acc@5 92.188 (93.642)
Epoch: [35][200/600]	Time 0.233 (0.251)	Data 0.165 (0.179)	Loss 3.1654 (3.2044)	Acc@1 73.438 (74.207)	Acc@5 93.750 (93.330)
Epoch: [35][300/600]	Time 0.213 (0.249)	Data 0.146 (0.177)	Loss 3.2827 (3.2079)	Acc@1 70.312 (74.092)	Acc@5 92.188 (93.195)
Epoch: [35][400/600]	Time 0.196 (0.247)	Data 0.126 (0.176)	Loss 3.2726 (3.2086)	Acc@1 64.062 (73.971)	Acc@5 93.750 (93.232)
Epoch: [35][500/600]	Time 0.270 (0.246)	Data 0.197 (0.175)	Loss 3.2824 (3.2146)	Acc@1 60.938 (73.522)	Acc@5 89.062 (92.983)
 * Acc@1 73.344 Acc@5 92.938
epoch 35, total time 147.25
Test: [0/586]	Time 0.061 (0.061)	Loss 3.5881 (3.5881)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.069 (0.063)	Loss 3.6673 (3.5018)	Acc@1 34.375 (59.870)	Acc@5 68.750 (86.881)
Test: [200/586]	Time 0.061 (0.062)	Loss 3.1533 (3.4497)	Acc@1 90.625 (64.117)	Acc@5 96.875 (88.619)
Test: [300/586]	Time 0.067 (0.063)	Loss 3.5403 (3.4501)	Acc@1 46.875 (63.466)	Acc@5 75.000 (87.998)
Test: [400/586]	Time 0.052 (0.063)	Loss 3.6145 (3.4162)	Acc@1 46.875 (65.648)	Acc@5 81.250 (88.770)
Test: [500/586]	Time 0.053 (0.062)	Loss 3.5394 (3.4154)	Acc@1 87.500 (65.407)	Acc@5 96.875 (88.885)
 * Acc@1 65.458 Acc@5 88.932
==> training...
Epoch: [36][0/600]	Time 0.256 (0.256)	Data 0.186 (0.186)	Loss 3.1504 (3.1504)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Epoch: [36][100/600]	Time 0.238 (0.241)	Data 0.169 (0.170)	Loss 3.1997 (3.2072)	Acc@1 75.000 (73.793)	Acc@5 89.062 (93.518)
Epoch: [36][200/600]	Time 0.226 (0.238)	Data 0.155 (0.167)	Loss 3.2082 (3.2090)	Acc@1 73.438 (74.036)	Acc@5 90.625 (93.532)
Epoch: [36][300/600]	Time 0.255 (0.226)	Data 0.183 (0.156)	Loss 3.1787 (3.2108)	Acc@1 76.562 (73.707)	Acc@5 95.312 (93.516)
Epoch: [36][400/600]	Time 0.260 (0.229)	Data 0.186 (0.159)	Loss 3.1790 (3.2125)	Acc@1 75.000 (73.628)	Acc@5 93.750 (93.384)
Epoch: [36][500/600]	Time 0.236 (0.231)	Data 0.167 (0.161)	Loss 3.2730 (3.2151)	Acc@1 67.188 (73.438)	Acc@5 87.500 (93.210)
 * Acc@1 73.576 Acc@5 93.279
epoch 36, total time 140.01
Test: [0/586]	Time 0.052 (0.052)	Loss 3.3081 (3.3081)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.070 (0.063)	Loss 3.2795 (3.3704)	Acc@1 71.875 (61.355)	Acc@5 90.625 (87.283)
Test: [200/586]	Time 0.058 (0.061)	Loss 3.3217 (3.3214)	Acc@1 96.875 (68.968)	Acc@5 100.000 (90.003)
Test: [300/586]	Time 0.064 (0.061)	Loss 3.2728 (3.3160)	Acc@1 68.750 (68.387)	Acc@5 93.750 (90.303)
Test: [400/586]	Time 0.074 (0.061)	Loss 3.6711 (3.3151)	Acc@1 43.750 (69.966)	Acc@5 71.875 (90.485)
Test: [500/586]	Time 0.053 (0.061)	Loss 3.3089 (3.3204)	Acc@1 71.875 (69.343)	Acc@5 90.625 (90.394)
 * Acc@1 69.437 Acc@5 90.687
==> training...
Epoch: [37][0/600]	Time 0.257 (0.257)	Data 0.187 (0.187)	Loss 3.2134 (3.2134)	Acc@1 73.438 (73.438)	Acc@5 93.750 (93.750)
Epoch: [37][100/600]	Time 0.224 (0.239)	Data 0.153 (0.168)	Loss 3.1283 (3.1909)	Acc@1 79.688 (75.170)	Acc@5 95.312 (93.967)
Epoch: [37][200/600]	Time 0.223 (0.241)	Data 0.152 (0.169)	Loss 3.1364 (3.1977)	Acc@1 82.812 (74.938)	Acc@5 95.312 (93.773)
Epoch: [37][300/600]	Time 0.240 (0.239)	Data 0.171 (0.168)	Loss 3.2254 (3.2056)	Acc@1 76.562 (74.413)	Acc@5 93.750 (93.449)
Epoch: [37][400/600]	Time 0.213 (0.242)	Data 0.141 (0.171)	Loss 3.1830 (3.2064)	Acc@1 78.125 (74.310)	Acc@5 93.750 (93.356)
Epoch: [37][500/600]	Time 0.224 (0.241)	Data 0.152 (0.170)	Loss 3.1726 (3.2102)	Acc@1 76.562 (73.880)	Acc@5 96.875 (93.288)
 * Acc@1 73.799 Acc@5 93.156
epoch 37, total time 145.12
Test: [0/586]	Time 0.058 (0.058)	Loss 3.3467 (3.3467)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.051 (0.057)	Loss 3.3920 (3.3550)	Acc@1 65.625 (62.469)	Acc@5 87.500 (89.140)
Test: [200/586]	Time 0.063 (0.069)	Loss 3.2571 (3.3423)	Acc@1 93.750 (69.061)	Acc@5 100.000 (90.454)
Test: [300/586]	Time 0.073 (0.066)	Loss 3.5481 (3.3330)	Acc@1 87.500 (69.279)	Acc@5 100.000 (90.874)
Test: [400/586]	Time 0.062 (0.064)	Loss 3.6310 (3.3099)	Acc@1 40.625 (70.846)	Acc@5 75.000 (91.342)
Test: [500/586]	Time 0.058 (0.064)	Loss 3.2232 (3.3120)	Acc@1 71.875 (70.571)	Acc@5 87.500 (91.180)
 * Acc@1 71.053 Acc@5 91.487
==> training...
Epoch: [38][0/600]	Time 0.275 (0.275)	Data 0.202 (0.202)	Loss 3.2792 (3.2792)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)
Epoch: [38][100/600]	Time 0.230 (0.249)	Data 0.161 (0.177)	Loss 3.2693 (3.1904)	Acc@1 62.500 (75.665)	Acc@5 90.625 (94.059)
Epoch: [38][200/600]	Time 0.228 (0.240)	Data 0.158 (0.169)	Loss 3.2170 (3.1992)	Acc@1 70.312 (75.016)	Acc@5 90.625 (93.766)
Epoch: [38][300/600]	Time 0.253 (0.240)	Data 0.183 (0.169)	Loss 3.2005 (3.2043)	Acc@1 75.000 (74.268)	Acc@5 95.312 (93.490)
Epoch: [38][400/600]	Time 0.227 (0.238)	Data 0.158 (0.168)	Loss 3.1680 (3.2039)	Acc@1 70.312 (74.396)	Acc@5 98.438 (93.481)
Epoch: [38][500/600]	Time 0.219 (0.238)	Data 0.151 (0.167)	Loss 3.1730 (3.2057)	Acc@1 73.438 (74.192)	Acc@5 93.750 (93.398)
 * Acc@1 73.909 Acc@5 93.253
epoch 38, total time 143.36
Test: [0/586]	Time 0.080 (0.080)	Loss 3.7291 (3.7291)	Acc@1 68.750 (68.750)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.073 (0.062)	Loss 3.3736 (3.4606)	Acc@1 68.750 (57.240)	Acc@5 90.625 (89.356)
Test: [200/586]	Time 0.052 (0.062)	Loss 3.2398 (3.4164)	Acc@1 75.000 (60.805)	Acc@5 100.000 (89.086)
Test: [300/586]	Time 0.055 (0.061)	Loss 3.1793 (3.3888)	Acc@1 84.375 (64.545)	Acc@5 93.750 (89.379)
Test: [400/586]	Time 0.055 (0.061)	Loss 3.6666 (3.3477)	Acc@1 37.500 (67.869)	Acc@5 71.875 (90.157)
Test: [500/586]	Time 0.067 (0.061)	Loss 3.1537 (3.3427)	Acc@1 81.250 (68.195)	Acc@5 93.750 (90.195)
 * Acc@1 68.605 Acc@5 90.559
==> training...
Epoch: [39][0/600]	Time 0.272 (0.272)	Data 0.199 (0.199)	Loss 3.2510 (3.2510)	Acc@1 68.750 (68.750)	Acc@5 89.062 (89.062)
Epoch: [39][100/600]	Time 0.209 (0.197)	Data 0.142 (0.130)	Loss 3.2496 (3.2051)	Acc@1 71.875 (74.149)	Acc@5 93.750 (93.642)
Epoch: [39][200/600]	Time 0.179 (0.198)	Data 0.112 (0.131)	Loss 3.0865 (3.2008)	Acc@1 92.188 (74.930)	Acc@5 96.875 (93.571)
Epoch: [39][300/600]	Time 0.200 (0.200)	Data 0.132 (0.132)	Loss 3.1814 (3.2039)	Acc@1 81.250 (74.548)	Acc@5 93.750 (93.439)
Epoch: [39][400/600]	Time 0.212 (0.201)	Data 0.145 (0.133)	Loss 3.1657 (3.2052)	Acc@1 78.125 (74.423)	Acc@5 95.312 (93.333)
Epoch: [39][500/600]	Time 0.262 (0.209)	Data 0.192 (0.140)	Loss 3.2441 (3.2086)	Acc@1 68.750 (73.993)	Acc@5 90.625 (93.276)
 * Acc@1 73.826 Acc@5 93.221
epoch 39, total time 130.05
Test: [0/586]	Time 0.064 (0.064)	Loss 3.3748 (3.3748)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.073 (0.065)	Loss 3.5201 (3.4812)	Acc@1 68.750 (56.095)	Acc@5 96.875 (87.191)
Test: [200/586]	Time 0.053 (0.066)	Loss 3.3480 (3.4222)	Acc@1 71.875 (62.718)	Acc@5 87.500 (87.951)
Test: [300/586]	Time 0.058 (0.065)	Loss 3.2285 (3.3889)	Acc@1 65.625 (65.303)	Acc@5 90.625 (88.995)
Test: [400/586]	Time 0.072 (0.066)	Loss 3.7435 (3.3543)	Acc@1 37.500 (67.542)	Acc@5 68.750 (89.627)
Test: [500/586]	Time 0.060 (0.066)	Loss 3.2704 (3.3528)	Acc@1 71.875 (67.696)	Acc@5 93.750 (89.858)
 * Acc@1 67.677 Acc@5 90.228
==> training...
Epoch: [40][0/600]	Time 0.228 (0.228)	Data 0.157 (0.157)	Loss 3.2446 (3.2446)	Acc@1 73.438 (73.438)	Acc@5 89.062 (89.062)
Epoch: [40][100/600]	Time 0.242 (0.254)	Data 0.170 (0.182)	Loss 3.1680 (3.1862)	Acc@1 79.688 (75.619)	Acc@5 96.875 (94.431)
Epoch: [40][200/600]	Time 0.246 (0.253)	Data 0.174 (0.181)	Loss 3.2904 (3.1925)	Acc@1 67.188 (75.008)	Acc@5 85.938 (93.937)
Epoch: [40][300/600]	Time 0.274 (0.252)	Data 0.200 (0.180)	Loss 3.2257 (3.1959)	Acc@1 70.312 (74.766)	Acc@5 92.188 (93.745)
Epoch: [40][400/600]	Time 0.274 (0.252)	Data 0.198 (0.180)	Loss 3.2282 (3.1999)	Acc@1 65.625 (74.486)	Acc@5 92.188 (93.493)
Epoch: [40][500/600]	Time 0.241 (0.251)	Data 0.168 (0.179)	Loss 3.2332 (3.2029)	Acc@1 75.000 (74.289)	Acc@5 93.750 (93.282)
 * Acc@1 74.049 Acc@5 93.206
epoch 40, total time 151.41
Test: [0/586]	Time 0.059 (0.059)	Loss 3.5494 (3.5494)	Acc@1 81.250 (81.250)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.058 (0.069)	Loss 3.4609 (3.4665)	Acc@1 65.625 (58.601)	Acc@5 87.500 (87.407)
Test: [200/586]	Time 0.070 (0.070)	Loss 3.2537 (3.4128)	Acc@1 78.125 (63.822)	Acc@5 100.000 (87.547)
Test: [300/586]	Time 0.054 (0.069)	Loss 3.3362 (3.3874)	Acc@1 59.375 (65.718)	Acc@5 81.250 (88.029)
Test: [400/586]	Time 0.057 (0.068)	Loss 3.8916 (3.3758)	Acc@1 12.500 (67.565)	Acc@5 53.125 (88.716)
Test: [500/586]	Time 0.054 (0.069)	Loss 3.3103 (3.3705)	Acc@1 81.250 (67.440)	Acc@5 96.875 (88.885)
 * Acc@1 66.636 Acc@5 88.932
==> Saving...
==> training...
Epoch: [41][0/600]	Time 0.210 (0.210)	Data 0.141 (0.141)	Loss 3.1041 (3.1041)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [41][100/600]	Time 0.263 (0.251)	Data 0.193 (0.178)	Loss 3.1790 (3.1900)	Acc@1 75.000 (75.371)	Acc@5 93.750 (94.415)
Epoch: [41][200/600]	Time 0.223 (0.252)	Data 0.152 (0.179)	Loss 3.1688 (3.1898)	Acc@1 78.125 (75.435)	Acc@5 98.438 (94.333)
Epoch: [41][300/600]	Time 0.248 (0.252)	Data 0.175 (0.180)	Loss 3.2581 (3.1972)	Acc@1 75.000 (74.704)	Acc@5 89.062 (93.958)
Epoch: [41][400/600]	Time 0.208 (0.251)	Data 0.136 (0.179)	Loss 3.1122 (3.2010)	Acc@1 79.688 (74.427)	Acc@5 98.438 (93.684)
Epoch: [41][500/600]	Time 0.257 (0.251)	Data 0.185 (0.179)	Loss 3.2521 (3.2022)	Acc@1 70.312 (74.317)	Acc@5 89.062 (93.641)
 * Acc@1 73.984 Acc@5 93.466
epoch 41, total time 150.91
Test: [0/586]	Time 0.074 (0.074)	Loss 3.4392 (3.4392)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.053 (0.066)	Loss 3.5536 (3.4165)	Acc@1 53.125 (61.231)	Acc@5 71.875 (86.634)
Test: [200/586]	Time 0.067 (0.066)	Loss 3.2862 (3.3857)	Acc@1 90.625 (63.231)	Acc@5 100.000 (87.500)
Test: [300/586]	Time 0.056 (0.067)	Loss 3.2300 (3.3803)	Acc@1 87.500 (64.348)	Acc@5 93.750 (87.988)
Test: [400/586]	Time 0.077 (0.066)	Loss 3.6586 (3.3572)	Acc@1 43.750 (66.950)	Acc@5 68.750 (88.653)
Test: [500/586]	Time 0.073 (0.066)	Loss 3.2755 (3.3545)	Acc@1 81.250 (66.922)	Acc@5 93.750 (88.492)
 * Acc@1 67.575 Acc@5 89.258
==> training...
Epoch: [42][0/600]	Time 0.275 (0.275)	Data 0.196 (0.196)	Loss 3.1267 (3.1267)	Acc@1 82.812 (82.812)	Acc@5 95.312 (95.312)
Epoch: [42][100/600]	Time 0.211 (0.248)	Data 0.139 (0.177)	Loss 3.0956 (3.1921)	Acc@1 82.812 (75.480)	Acc@5 95.312 (94.028)
Epoch: [42][200/600]	Time 0.214 (0.249)	Data 0.144 (0.178)	Loss 3.2166 (3.1906)	Acc@1 78.125 (75.847)	Acc@5 92.188 (93.882)
Epoch: [42][300/600]	Time 0.221 (0.246)	Data 0.152 (0.175)	Loss 3.2614 (3.1956)	Acc@1 60.938 (75.317)	Acc@5 93.750 (93.792)
Epoch: [42][400/600]	Time 0.258 (0.245)	Data 0.187 (0.174)	Loss 3.2120 (3.2000)	Acc@1 73.438 (74.864)	Acc@5 93.750 (93.684)
Epoch: [42][500/600]	Time 0.276 (0.248)	Data 0.202 (0.177)	Loss 3.2292 (3.2018)	Acc@1 75.000 (74.691)	Acc@5 90.625 (93.591)
 * Acc@1 74.419 Acc@5 93.474
epoch 42, total time 149.68
Test: [0/586]	Time 0.072 (0.072)	Loss 3.2415 (3.2415)	Acc@1 75.000 (75.000)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.060 (0.071)	Loss 3.3433 (3.4774)	Acc@1 65.625 (58.354)	Acc@5 93.750 (84.870)
Test: [200/586]	Time 0.053 (0.068)	Loss 3.2028 (3.4212)	Acc@1 81.250 (60.930)	Acc@5 96.875 (86.163)
Test: [300/586]	Time 0.071 (0.065)	Loss 3.4693 (3.4093)	Acc@1 53.125 (60.725)	Acc@5 78.125 (86.919)
Test: [400/586]	Time 0.069 (0.065)	Loss 3.8320 (3.3897)	Acc@1 31.250 (61.674)	Acc@5 53.125 (87.204)
Test: [500/586]	Time 0.063 (0.065)	Loss 3.1734 (3.3877)	Acc@1 81.250 (61.546)	Acc@5 96.875 (87.163)
 * Acc@1 61.815 Acc@5 87.620
==> training...
Epoch: [43][0/600]	Time 0.218 (0.218)	Data 0.150 (0.150)	Loss 3.2823 (3.2823)	Acc@1 62.500 (62.500)	Acc@5 89.062 (89.062)
Epoch: [43][100/600]	Time 0.246 (0.246)	Data 0.172 (0.175)	Loss 3.2643 (3.1791)	Acc@1 71.875 (76.872)	Acc@5 90.625 (94.338)
Epoch: [43][200/600]	Time 0.272 (0.249)	Data 0.202 (0.178)	Loss 3.1874 (3.1830)	Acc@1 78.125 (76.539)	Acc@5 93.750 (94.030)
Epoch: [43][300/600]	Time 0.217 (0.250)	Data 0.144 (0.179)	Loss 3.1893 (3.1838)	Acc@1 78.125 (76.241)	Acc@5 93.750 (93.901)
Epoch: [43][400/600]	Time 0.197 (0.248)	Data 0.129 (0.176)	Loss 3.2607 (3.1908)	Acc@1 70.312 (75.475)	Acc@5 92.188 (93.715)
Epoch: [43][500/600]	Time 0.239 (0.250)	Data 0.167 (0.178)	Loss 3.1956 (3.1948)	Acc@1 75.000 (75.012)	Acc@5 92.188 (93.560)
 * Acc@1 74.599 Acc@5 93.349
epoch 43, total time 149.15
Test: [0/586]	Time 0.068 (0.068)	Loss 3.4282 (3.4282)	Acc@1 65.625 (65.625)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.064 (0.066)	Loss 3.4850 (3.4093)	Acc@1 84.375 (62.191)	Acc@5 96.875 (87.407)
Test: [200/586]	Time 0.065 (0.064)	Loss 3.1984 (3.3797)	Acc@1 93.750 (66.060)	Acc@5 96.875 (88.495)
Test: [300/586]	Time 0.057 (0.065)	Loss 3.3217 (3.3710)	Acc@1 59.375 (66.757)	Acc@5 87.500 (88.632)
Test: [400/586]	Time 0.057 (0.066)	Loss 3.6196 (3.3390)	Acc@1 46.875 (68.851)	Acc@5 78.125 (89.472)
Test: [500/586]	Time 0.057 (0.066)	Loss 3.3268 (3.3421)	Acc@1 68.750 (68.831)	Acc@5 84.375 (89.471)
 * Acc@1 69.207 Acc@5 89.887
==> training...
Epoch: [44][0/600]	Time 0.307 (0.307)	Data 0.234 (0.234)	Loss 3.0599 (3.0599)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [44][100/600]	Time 0.247 (0.257)	Data 0.177 (0.184)	Loss 3.1607 (3.1740)	Acc@1 81.250 (76.903)	Acc@5 96.875 (94.663)
Epoch: [44][200/600]	Time 0.259 (0.253)	Data 0.184 (0.181)	Loss 3.1953 (3.1829)	Acc@1 71.875 (75.995)	Acc@5 93.750 (94.045)
Epoch: [44][300/600]	Time 0.250 (0.251)	Data 0.181 (0.179)	Loss 3.1419 (3.1880)	Acc@1 79.688 (75.472)	Acc@5 96.875 (93.973)
Epoch: [44][400/600]	Time 0.246 (0.250)	Data 0.177 (0.179)	Loss 3.1752 (3.1925)	Acc@1 71.875 (75.070)	Acc@5 93.750 (93.758)
Epoch: [44][500/600]	Time 0.222 (0.251)	Data 0.150 (0.179)	Loss 3.2179 (3.1969)	Acc@1 71.875 (74.713)	Acc@5 92.188 (93.625)
 * Acc@1 74.482 Acc@5 93.534
epoch 44, total time 151.20
Test: [0/586]	Time 0.070 (0.070)	Loss 3.4345 (3.4345)	Acc@1 56.250 (56.250)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.054 (0.061)	Loss 3.3885 (3.3912)	Acc@1 56.250 (62.252)	Acc@5 84.375 (87.871)
Test: [200/586]	Time 0.055 (0.061)	Loss 3.3224 (3.3567)	Acc@1 96.875 (67.957)	Acc@5 100.000 (90.050)
Test: [300/586]	Time 0.058 (0.065)	Loss 3.3041 (3.3417)	Acc@1 81.250 (70.172)	Acc@5 96.875 (90.999)
Test: [400/586]	Time 0.055 (0.065)	Loss 3.7826 (3.3310)	Acc@1 31.250 (70.387)	Acc@5 62.500 (90.734)
Test: [500/586]	Time 0.072 (0.065)	Loss 3.3428 (3.3369)	Acc@1 62.500 (69.561)	Acc@5 87.500 (90.400)
 * Acc@1 70.381 Acc@5 90.943
==> training...
Epoch: [45][0/600]	Time 0.274 (0.274)	Data 0.199 (0.199)	Loss 3.1675 (3.1675)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
Epoch: [45][100/600]	Time 0.265 (0.250)	Data 0.191 (0.179)	Loss 3.1620 (3.1799)	Acc@1 76.562 (76.578)	Acc@5 96.875 (93.998)
Epoch: [45][200/600]	Time 0.273 (0.252)	Data 0.203 (0.180)	Loss 3.1905 (3.1867)	Acc@1 76.562 (76.189)	Acc@5 93.750 (93.944)
Epoch: [45][300/600]	Time 0.257 (0.253)	Data 0.182 (0.181)	Loss 3.1384 (3.1931)	Acc@1 76.562 (75.566)	Acc@5 92.188 (93.755)
Epoch: [45][400/600]	Time 0.282 (0.253)	Data 0.207 (0.181)	Loss 3.2380 (3.1955)	Acc@1 73.438 (75.253)	Acc@5 92.188 (93.762)
Epoch: [45][500/600]	Time 0.265 (0.253)	Data 0.196 (0.181)	Loss 3.2758 (3.1982)	Acc@1 75.000 (74.900)	Acc@5 89.062 (93.681)
 * Acc@1 74.747 Acc@5 93.625
epoch 45, total time 151.99
Test: [0/586]	Time 0.068 (0.068)	Loss 3.3349 (3.3349)	Acc@1 71.875 (71.875)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.072 (0.068)	Loss 3.6258 (3.4424)	Acc@1 75.000 (66.151)	Acc@5 93.750 (88.026)
Test: [200/586]	Time 0.051 (0.067)	Loss 3.1760 (3.3851)	Acc@1 81.250 (69.170)	Acc@5 96.875 (89.614)
Test: [300/586]	Time 0.076 (0.067)	Loss 3.3281 (3.3757)	Acc@1 68.750 (67.535)	Acc@5 84.375 (89.255)
Test: [400/586]	Time 0.058 (0.067)	Loss 3.6008 (3.3574)	Acc@1 37.500 (68.641)	Acc@5 78.125 (89.550)
Test: [500/586]	Time 0.070 (0.067)	Loss 3.0971 (3.3575)	Acc@1 93.750 (68.095)	Acc@5 96.875 (89.627)
 * Acc@1 68.418 Acc@5 89.892
==> training...
Epoch: [46][0/600]	Time 0.280 (0.280)	Data 0.208 (0.208)	Loss 3.2319 (3.2319)	Acc@1 67.188 (67.188)	Acc@5 89.062 (89.062)
Epoch: [46][100/600]	Time 0.227 (0.242)	Data 0.156 (0.171)	Loss 3.1309 (3.1807)	Acc@1 82.812 (76.315)	Acc@5 92.188 (94.152)
Epoch: [46][200/600]	Time 0.237 (0.239)	Data 0.166 (0.169)	Loss 3.2031 (3.1865)	Acc@1 75.000 (75.894)	Acc@5 93.750 (93.898)
Epoch: [46][300/600]	Time 0.189 (0.238)	Data 0.122 (0.168)	Loss 3.1826 (3.1893)	Acc@1 78.125 (75.535)	Acc@5 95.312 (93.864)
Epoch: [46][400/600]	Time 0.226 (0.238)	Data 0.154 (0.167)	Loss 3.2666 (3.1924)	Acc@1 75.000 (75.323)	Acc@5 89.062 (93.742)
Epoch: [46][500/600]	Time 0.246 (0.240)	Data 0.176 (0.169)	Loss 3.2180 (3.1962)	Acc@1 71.875 (74.903)	Acc@5 96.875 (93.669)
 * Acc@1 74.669 Acc@5 93.487
epoch 46, total time 146.22
Test: [0/586]	Time 0.065 (0.065)	Loss 3.3938 (3.3938)	Acc@1 65.625 (65.625)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.050 (0.067)	Loss 3.3653 (3.3729)	Acc@1 65.625 (67.853)	Acc@5 87.500 (88.645)
Test: [200/586]	Time 0.049 (0.062)	Loss 3.1653 (3.3383)	Acc@1 71.875 (68.968)	Acc@5 96.875 (89.335)
Test: [300/586]	Time 0.061 (0.060)	Loss 3.3633 (3.3631)	Acc@1 62.500 (65.314)	Acc@5 84.375 (88.227)
Test: [400/586]	Time 0.048 (0.059)	Loss 3.9620 (3.3434)	Acc@1 25.000 (66.615)	Acc@5 53.125 (88.388)
Test: [500/586]	Time 0.051 (0.058)	Loss 3.1920 (3.3481)	Acc@1 68.750 (66.922)	Acc@5 96.875 (88.486)
 * Acc@1 67.677 Acc@5 89.274
==> training...
Epoch: [47][0/600]	Time 0.266 (0.266)	Data 0.195 (0.195)	Loss 3.2616 (3.2616)	Acc@1 71.875 (71.875)	Acc@5 92.188 (92.188)
Epoch: [47][100/600]	Time 0.198 (0.195)	Data 0.131 (0.128)	Loss 3.2703 (3.1773)	Acc@1 73.438 (76.810)	Acc@5 90.625 (94.678)
Epoch: [47][200/600]	Time 0.176 (0.202)	Data 0.109 (0.134)	Loss 3.2548 (3.1818)	Acc@1 73.438 (76.182)	Acc@5 92.188 (94.317)
Epoch: [47][300/600]	Time 0.262 (0.218)	Data 0.190 (0.149)	Loss 3.2009 (3.1880)	Acc@1 78.125 (75.799)	Acc@5 87.500 (94.030)
Epoch: [47][400/600]	Time 0.242 (0.226)	Data 0.175 (0.157)	Loss 3.2631 (3.1908)	Acc@1 70.312 (75.514)	Acc@5 89.062 (93.918)
Epoch: [47][500/600]	Time 0.243 (0.232)	Data 0.173 (0.162)	Loss 3.1700 (3.1924)	Acc@1 75.000 (75.240)	Acc@5 93.750 (93.809)
 * Acc@1 74.893 Acc@5 93.737
epoch 47, total time 141.66
Test: [0/586]	Time 0.085 (0.085)	Loss 3.5065 (3.5065)	Acc@1 59.375 (59.375)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.078 (0.068)	Loss 3.3211 (3.4001)	Acc@1 81.250 (63.923)	Acc@5 96.875 (88.181)
Test: [200/586]	Time 0.065 (0.069)	Loss 3.2755 (3.3767)	Acc@1 65.625 (66.869)	Acc@5 93.750 (89.350)
Test: [300/586]	Time 0.063 (0.069)	Loss 3.3309 (3.3621)	Acc@1 68.750 (68.314)	Acc@5 84.375 (90.262)
Test: [400/586]	Time 0.071 (0.069)	Loss 3.7572 (3.3481)	Acc@1 34.375 (69.303)	Acc@5 71.875 (90.555)
Test: [500/586]	Time 0.071 (0.068)	Loss 3.2356 (3.3530)	Acc@1 71.875 (68.519)	Acc@5 93.750 (90.026)
 * Acc@1 67.837 Acc@5 89.978
==> training...
Epoch: [48][0/600]	Time 0.236 (0.236)	Data 0.165 (0.165)	Loss 3.1417 (3.1417)	Acc@1 81.250 (81.250)	Acc@5 93.750 (93.750)
Epoch: [48][100/600]	Time 0.274 (0.242)	Data 0.201 (0.171)	Loss 3.1757 (3.1847)	Acc@1 78.125 (76.392)	Acc@5 93.750 (93.735)
Epoch: [48][200/600]	Time 0.218 (0.244)	Data 0.145 (0.172)	Loss 3.1692 (3.1881)	Acc@1 76.562 (75.910)	Acc@5 96.875 (93.758)
Epoch: [48][300/600]	Time 0.273 (0.246)	Data 0.205 (0.175)	Loss 3.1872 (3.1913)	Acc@1 75.000 (75.452)	Acc@5 90.625 (93.594)
Epoch: [48][400/600]	Time 0.254 (0.249)	Data 0.181 (0.178)	Loss 3.1765 (3.1914)	Acc@1 79.688 (75.596)	Acc@5 93.750 (93.672)
Epoch: [48][500/600]	Time 0.220 (0.250)	Data 0.151 (0.178)	Loss 3.1956 (3.1924)	Acc@1 70.312 (75.409)	Acc@5 90.625 (93.706)
 * Acc@1 75.115 Acc@5 93.635
epoch 48, total time 150.84
Test: [0/586]	Time 0.086 (0.086)	Loss 3.5693 (3.5693)	Acc@1 46.875 (46.875)	Acc@5 78.125 (78.125)
Test: [100/586]	Time 0.071 (0.067)	Loss 3.4012 (3.4788)	Acc@1 78.125 (59.282)	Acc@5 100.000 (85.520)
Test: [200/586]	Time 0.064 (0.069)	Loss 3.2334 (3.4160)	Acc@1 84.375 (63.790)	Acc@5 100.000 (86.800)
Test: [300/586]	Time 0.056 (0.068)	Loss 3.2942 (3.4099)	Acc@1 71.875 (62.770)	Acc@5 84.375 (87.095)
Test: [400/586]	Time 0.074 (0.068)	Loss 3.6945 (3.3872)	Acc@1 40.625 (64.659)	Acc@5 75.000 (87.656)
Test: [500/586]	Time 0.058 (0.068)	Loss 3.2195 (3.3744)	Acc@1 65.625 (65.475)	Acc@5 96.875 (87.880)
 * Acc@1 65.602 Acc@5 88.505
==> training...
Epoch: [49][0/600]	Time 0.304 (0.304)	Data 0.225 (0.225)	Loss 3.1818 (3.1818)	Acc@1 76.562 (76.562)	Acc@5 95.312 (95.312)
Epoch: [49][100/600]	Time 0.255 (0.262)	Data 0.182 (0.189)	Loss 3.2037 (3.1811)	Acc@1 75.000 (76.284)	Acc@5 98.438 (94.322)
Epoch: [49][200/600]	Time 0.230 (0.258)	Data 0.160 (0.186)	Loss 3.2167 (3.1763)	Acc@1 71.875 (76.353)	Acc@5 89.062 (94.426)
Epoch: [49][300/600]	Time 0.227 (0.256)	Data 0.153 (0.184)	Loss 3.2986 (3.1835)	Acc@1 60.938 (75.857)	Acc@5 85.938 (94.191)
Epoch: [49][400/600]	Time 0.275 (0.256)	Data 0.203 (0.184)	Loss 3.1528 (3.1905)	Acc@1 81.250 (75.429)	Acc@5 93.750 (93.898)
Epoch: [49][500/600]	Time 0.225 (0.255)	Data 0.155 (0.183)	Loss 3.2886 (3.1919)	Acc@1 67.188 (75.306)	Acc@5 87.500 (93.834)
 * Acc@1 75.169 Acc@5 93.831
epoch 49, total time 153.58
Test: [0/586]	Time 0.061 (0.061)	Loss 3.3098 (3.3098)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.054 (0.066)	Loss 3.4577 (3.3882)	Acc@1 46.875 (60.334)	Acc@5 84.375 (87.840)
Test: [200/586]	Time 0.053 (0.066)	Loss 3.2253 (3.3707)	Acc@1 78.125 (62.624)	Acc@5 100.000 (87.578)
Test: [300/586]	Time 0.073 (0.066)	Loss 3.3090 (3.3388)	Acc@1 71.875 (66.092)	Acc@5 84.375 (89.099)
Test: [400/586]	Time 0.060 (0.066)	Loss 3.7599 (3.3263)	Acc@1 34.375 (68.095)	Acc@5 62.500 (89.612)
Test: [500/586]	Time 0.056 (0.066)	Loss 3.4271 (3.3420)	Acc@1 65.625 (66.966)	Acc@5 87.500 (89.109)
 * Acc@1 66.220 Acc@5 89.172
==> training...
Epoch: [50][0/600]	Time 0.283 (0.283)	Data 0.211 (0.211)	Loss 3.1733 (3.1733)	Acc@1 76.562 (76.562)	Acc@5 95.312 (95.312)
Epoch: [50][100/600]	Time 0.243 (0.249)	Data 0.174 (0.177)	Loss 3.3128 (3.1739)	Acc@1 64.062 (77.042)	Acc@5 84.375 (94.338)
Epoch: [50][200/600]	Time 0.219 (0.252)	Data 0.150 (0.180)	Loss 3.1561 (3.1814)	Acc@1 71.875 (76.446)	Acc@5 96.875 (94.014)
Epoch: [50][300/600]	Time 0.267 (0.251)	Data 0.196 (0.179)	Loss 3.2679 (3.1850)	Acc@1 70.312 (76.095)	Acc@5 90.625 (93.838)
Epoch: [50][400/600]	Time 0.274 (0.251)	Data 0.200 (0.179)	Loss 3.1941 (3.1889)	Acc@1 71.875 (75.705)	Acc@5 96.875 (93.801)
Epoch: [50][500/600]	Time 0.205 (0.246)	Data 0.138 (0.174)	Loss 3.2083 (3.1929)	Acc@1 71.875 (75.293)	Acc@5 92.188 (93.644)
 * Acc@1 75.117 Acc@5 93.615
epoch 50, total time 144.82
Test: [0/586]	Time 0.060 (0.060)	Loss 3.3618 (3.3618)	Acc@1 62.500 (62.500)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.049 (0.058)	Loss 3.4659 (3.4218)	Acc@1 53.125 (58.540)	Acc@5 84.375 (83.818)
Test: [200/586]	Time 0.050 (0.057)	Loss 3.1573 (3.3551)	Acc@1 75.000 (65.236)	Acc@5 96.875 (86.536)
Test: [300/586]	Time 0.052 (0.057)	Loss 3.1206 (3.3404)	Acc@1 87.500 (67.068)	Acc@5 100.000 (87.739)
Test: [400/586]	Time 0.048 (0.057)	Loss 3.5964 (3.3184)	Acc@1 50.000 (69.514)	Acc@5 71.875 (88.988)
Test: [500/586]	Time 0.062 (0.058)	Loss 3.1894 (3.3283)	Acc@1 87.500 (68.582)	Acc@5 96.875 (88.548)
 * Acc@1 67.762 Acc@5 88.809
==> Saving...
==> training...
Epoch: [51][0/600]	Time 0.228 (0.228)	Data 0.160 (0.160)	Loss 3.1494 (3.1494)	Acc@1 76.562 (76.562)	Acc@5 92.188 (92.188)
Epoch: [51][100/600]	Time 0.269 (0.248)	Data 0.201 (0.177)	Loss 3.1226 (3.1747)	Acc@1 78.125 (76.408)	Acc@5 100.000 (94.709)
Epoch: [51][200/600]	Time 0.223 (0.246)	Data 0.155 (0.175)	Loss 3.1777 (3.1840)	Acc@1 76.562 (75.871)	Acc@5 93.750 (94.286)
Epoch: [51][300/600]	Time 0.255 (0.245)	Data 0.186 (0.174)	Loss 3.1465 (3.1894)	Acc@1 76.562 (75.509)	Acc@5 90.625 (93.942)
Epoch: [51][400/600]	Time 0.241 (0.246)	Data 0.163 (0.175)	Loss 3.2288 (3.1897)	Acc@1 76.562 (75.386)	Acc@5 92.188 (94.003)
Epoch: [51][500/600]	Time 0.236 (0.247)	Data 0.163 (0.176)	Loss 3.2375 (3.1923)	Acc@1 70.312 (75.246)	Acc@5 90.625 (93.853)
 * Acc@1 75.016 Acc@5 93.815
epoch 51, total time 149.36
Test: [0/586]	Time 0.055 (0.055)	Loss 3.4089 (3.4089)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.073 (0.066)	Loss 3.5710 (3.3886)	Acc@1 46.875 (67.296)	Acc@5 81.250 (89.511)
Test: [200/586]	Time 0.061 (0.069)	Loss 3.2592 (3.3531)	Acc@1 84.375 (69.185)	Acc@5 96.875 (89.397)
Test: [300/586]	Time 0.070 (0.069)	Loss 3.1980 (3.3523)	Acc@1 75.000 (68.397)	Acc@5 96.875 (89.348)
Test: [400/586]	Time 0.059 (0.074)	Loss 3.7988 (3.3404)	Acc@1 34.375 (69.810)	Acc@5 62.500 (89.885)
Test: [500/586]	Time 0.060 (0.074)	Loss 3.3070 (3.3402)	Acc@1 68.750 (69.280)	Acc@5 84.375 (89.696)
 * Acc@1 68.221 Acc@5 89.956
==> training...
Epoch: [52][0/600]	Time 0.265 (0.265)	Data 0.192 (0.192)	Loss 3.2205 (3.2205)	Acc@1 71.875 (71.875)	Acc@5 95.312 (95.312)
Epoch: [52][100/600]	Time 0.278 (0.251)	Data 0.207 (0.179)	Loss 3.1252 (3.1702)	Acc@1 79.688 (77.135)	Acc@5 95.312 (94.307)
Epoch: [52][200/600]	Time 0.263 (0.253)	Data 0.193 (0.181)	Loss 3.1735 (3.1763)	Acc@1 75.000 (76.827)	Acc@5 95.312 (94.193)
Epoch: [52][300/600]	Time 0.291 (0.251)	Data 0.209 (0.179)	Loss 3.1372 (3.1827)	Acc@1 82.812 (76.121)	Acc@5 92.188 (93.942)
Epoch: [52][400/600]	Time 0.231 (0.252)	Data 0.160 (0.180)	Loss 3.2127 (3.1874)	Acc@1 78.125 (75.674)	Acc@5 89.062 (93.863)
Epoch: [52][500/600]	Time 0.250 (0.251)	Data 0.179 (0.179)	Loss 3.1862 (3.1911)	Acc@1 78.125 (75.256)	Acc@5 95.312 (93.753)
 * Acc@1 75.117 Acc@5 93.695
epoch 52, total time 151.66
Test: [0/586]	Time 0.052 (0.052)	Loss 3.5356 (3.5356)	Acc@1 50.000 (50.000)	Acc@5 75.000 (75.000)
Test: [100/586]	Time 0.075 (0.068)	Loss 3.3279 (3.3855)	Acc@1 78.125 (61.974)	Acc@5 96.875 (87.407)
Test: [200/586]	Time 0.063 (0.067)	Loss 3.1553 (3.4022)	Acc@1 78.125 (63.573)	Acc@5 100.000 (86.894)
Test: [300/586]	Time 0.067 (0.066)	Loss 3.4094 (3.3771)	Acc@1 62.500 (65.230)	Acc@5 81.250 (88.248)
Test: [400/586]	Time 0.058 (0.066)	Loss 3.6325 (3.3551)	Acc@1 46.875 (65.812)	Acc@5 81.250 (88.669)
Test: [500/586]	Time 0.053 (0.066)	Loss 3.3667 (3.3645)	Acc@1 56.250 (64.758)	Acc@5 81.250 (88.055)
 * Acc@1 64.866 Acc@5 88.617
==> training...
Epoch: [53][0/600]	Time 0.273 (0.273)	Data 0.200 (0.200)	Loss 3.2860 (3.2860)	Acc@1 68.750 (68.750)	Acc@5 90.625 (90.625)
Epoch: [53][100/600]	Time 0.256 (0.243)	Data 0.176 (0.171)	Loss 3.1616 (3.1714)	Acc@1 84.375 (76.423)	Acc@5 93.750 (94.554)
Epoch: [53][200/600]	Time 0.234 (0.245)	Data 0.161 (0.173)	Loss 3.1446 (3.1724)	Acc@1 76.562 (76.757)	Acc@5 95.312 (94.613)
Epoch: [53][300/600]	Time 0.248 (0.246)	Data 0.177 (0.174)	Loss 3.2779 (3.1796)	Acc@1 68.750 (76.428)	Acc@5 89.062 (94.279)
Epoch: [53][400/600]	Time 0.254 (0.250)	Data 0.182 (0.178)	Loss 3.1521 (3.1835)	Acc@1 78.125 (76.001)	Acc@5 96.875 (94.011)
Epoch: [53][500/600]	Time 0.219 (0.250)	Data 0.147 (0.178)	Loss 3.1751 (3.1866)	Acc@1 73.438 (75.783)	Acc@5 96.875 (93.993)
 * Acc@1 75.576 Acc@5 93.940
epoch 53, total time 151.16
Test: [0/586]	Time 0.060 (0.060)	Loss 3.3715 (3.3715)	Acc@1 56.250 (56.250)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.064 (0.070)	Loss 3.3195 (3.3591)	Acc@1 68.750 (62.995)	Acc@5 96.875 (88.212)
Test: [200/586]	Time 0.060 (0.069)	Loss 3.2231 (3.3339)	Acc@1 81.250 (67.444)	Acc@5 96.875 (89.692)
Test: [300/586]	Time 0.072 (0.069)	Loss 3.5228 (3.3131)	Acc@1 84.375 (69.321)	Acc@5 96.875 (90.563)
Test: [400/586]	Time 0.050 (0.067)	Loss 3.8479 (3.2968)	Acc@1 25.000 (70.948)	Acc@5 50.000 (90.648)
Test: [500/586]	Time 0.062 (0.067)	Loss 3.1969 (3.3041)	Acc@1 75.000 (70.865)	Acc@5 93.750 (90.887)
 * Acc@1 71.192 Acc@5 91.194
==> training...
Epoch: [54][0/600]	Time 0.252 (0.252)	Data 0.184 (0.184)	Loss 3.1635 (3.1635)	Acc@1 78.125 (78.125)	Acc@5 95.312 (95.312)
Epoch: [54][100/600]	Time 0.244 (0.249)	Data 0.168 (0.177)	Loss 3.2367 (3.1714)	Acc@1 70.312 (76.872)	Acc@5 93.750 (94.817)
Epoch: [54][200/600]	Time 0.265 (0.248)	Data 0.190 (0.176)	Loss 3.0863 (3.1717)	Acc@1 76.562 (76.803)	Acc@5 100.000 (94.768)
Epoch: [54][300/600]	Time 0.243 (0.246)	Data 0.174 (0.175)	Loss 3.2413 (3.1788)	Acc@1 68.750 (76.184)	Acc@5 89.062 (94.425)
Epoch: [54][400/600]	Time 0.246 (0.237)	Data 0.175 (0.166)	Loss 3.2120 (3.1836)	Acc@1 73.438 (75.814)	Acc@5 96.875 (94.155)
Epoch: [54][500/600]	Time 0.189 (0.231)	Data 0.121 (0.160)	Loss 3.1292 (3.1859)	Acc@1 76.562 (75.649)	Acc@5 95.312 (94.000)
 * Acc@1 75.458 Acc@5 93.938
epoch 54, total time 135.64
Test: [0/586]	Time 0.058 (0.058)	Loss 3.3858 (3.3858)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.062 (0.066)	Loss 3.3833 (3.3619)	Acc@1 75.000 (70.080)	Acc@5 93.750 (90.532)
Test: [200/586]	Time 0.073 (0.068)	Loss 3.1951 (3.3403)	Acc@1 75.000 (72.341)	Acc@5 93.750 (90.951)
Test: [300/586]	Time 0.053 (0.068)	Loss 3.4091 (3.3516)	Acc@1 87.500 (70.941)	Acc@5 100.000 (90.916)
Test: [400/586]	Time 0.056 (0.067)	Loss 3.8005 (3.3278)	Acc@1 37.500 (72.623)	Acc@5 65.625 (91.513)
Test: [500/586]	Time 0.067 (0.068)	Loss 3.3863 (3.3370)	Acc@1 65.625 (71.320)	Acc@5 87.500 (91.018)
 * Acc@1 70.829 Acc@5 91.103
==> training...
Epoch: [55][0/600]	Time 0.256 (0.256)	Data 0.182 (0.182)	Loss 3.1670 (3.1670)	Acc@1 78.125 (78.125)	Acc@5 92.188 (92.188)
Epoch: [55][100/600]	Time 0.229 (0.252)	Data 0.161 (0.180)	Loss 3.1146 (3.1757)	Acc@1 81.250 (76.748)	Acc@5 96.875 (94.508)
Epoch: [55][200/600]	Time 0.228 (0.252)	Data 0.161 (0.180)	Loss 3.2484 (3.1790)	Acc@1 75.000 (76.228)	Acc@5 93.750 (94.543)
Epoch: [55][300/600]	Time 0.204 (0.323)	Data 0.136 (0.252)	Loss 3.1693 (3.1799)	Acc@1 78.125 (76.168)	Acc@5 93.750 (94.363)
Epoch: [55][400/600]	Time 0.232 (0.304)	Data 0.155 (0.232)	Loss 3.1541 (3.1823)	Acc@1 76.562 (76.001)	Acc@5 93.750 (94.233)
Epoch: [55][500/600]	Time 0.245 (0.293)	Data 0.177 (0.222)	Loss 3.1970 (3.1861)	Acc@1 71.875 (75.593)	Acc@5 93.750 (94.046)
 * Acc@1 75.367 Acc@5 93.904
epoch 55, total time 171.46
Test: [0/586]	Time 0.069 (0.069)	Loss 3.4583 (3.4583)	Acc@1 78.125 (78.125)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.075 (0.067)	Loss 3.4786 (3.4096)	Acc@1 75.000 (63.150)	Acc@5 96.875 (86.696)
Test: [200/586]	Time 0.065 (0.066)	Loss 3.1559 (3.3374)	Acc@1 78.125 (70.429)	Acc@5 100.000 (89.754)
Test: [300/586]	Time 0.062 (0.065)	Loss 3.3104 (3.3263)	Acc@1 75.000 (70.390)	Acc@5 84.375 (90.345)
Test: [400/586]	Time 0.056 (0.065)	Loss 3.6857 (3.3187)	Acc@1 40.625 (70.987)	Acc@5 62.500 (90.415)
Test: [500/586]	Time 0.058 (0.065)	Loss 3.2641 (3.3288)	Acc@1 65.625 (69.686)	Acc@5 93.750 (90.082)
 * Acc@1 70.077 Acc@5 90.671
==> training...
Epoch: [56][0/600]	Time 0.228 (0.228)	Data 0.161 (0.161)	Loss 3.2457 (3.2457)	Acc@1 67.188 (67.188)	Acc@5 92.188 (92.188)
Epoch: [56][100/600]	Time 0.223 (0.253)	Data 0.154 (0.182)	Loss 3.1727 (3.1691)	Acc@1 76.562 (77.537)	Acc@5 95.312 (94.725)
Epoch: [56][200/600]	Time 0.257 (0.253)	Data 0.187 (0.182)	Loss 3.2352 (3.1758)	Acc@1 73.438 (76.796)	Acc@5 93.750 (94.411)
Epoch: [56][300/600]	Time 0.270 (0.250)	Data 0.188 (0.180)	Loss 3.1057 (3.1765)	Acc@1 81.250 (76.573)	Acc@5 95.312 (94.248)
Epoch: [56][400/600]	Time 0.271 (0.250)	Data 0.196 (0.180)	Loss 3.1326 (3.1829)	Acc@1 78.125 (75.799)	Acc@5 96.875 (94.031)
Epoch: [56][500/600]	Time 0.229 (0.249)	Data 0.158 (0.179)	Loss 3.2646 (3.1859)	Acc@1 67.188 (75.589)	Acc@5 90.625 (93.968)
 * Acc@1 75.516 Acc@5 93.979
epoch 56, total time 151.02
Test: [0/586]	Time 0.073 (0.073)	Loss 3.6146 (3.6146)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Test: [100/586]	Time 0.065 (0.066)	Loss 3.4479 (3.4846)	Acc@1 53.125 (68.410)	Acc@5 78.125 (91.739)
Test: [200/586]	Time 0.054 (0.065)	Loss 3.4854 (3.4329)	Acc@1 78.125 (68.439)	Acc@5 100.000 (90.236)
Test: [300/586]	Time 0.064 (0.065)	Loss 3.4957 (3.4166)	Acc@1 43.750 (66.653)	Acc@5 78.125 (89.421)
Test: [400/586]	Time 0.064 (0.066)	Loss 3.8504 (3.3899)	Acc@1 40.625 (67.791)	Acc@5 68.750 (89.534)
Test: [500/586]	Time 0.069 (0.065)	Loss 3.4669 (3.3810)	Acc@1 56.250 (67.808)	Acc@5 93.750 (89.827)
 * Acc@1 67.042 Acc@5 90.074
==> training...
Epoch: [57][0/600]	Time 0.252 (0.252)	Data 0.181 (0.181)	Loss 3.2668 (3.2668)	Acc@1 71.875 (71.875)	Acc@5 84.375 (84.375)
Epoch: [57][100/600]	Time 0.252 (0.247)	Data 0.182 (0.177)	Loss 3.1324 (3.1565)	Acc@1 81.250 (78.775)	Acc@5 96.875 (95.359)
Epoch: [57][200/600]	Time 0.272 (0.245)	Data 0.205 (0.175)	Loss 3.1879 (3.1681)	Acc@1 73.438 (77.464)	Acc@5 92.188 (94.442)
Epoch: [57][300/600]	Time 0.258 (0.245)	Data 0.185 (0.175)	Loss 3.1070 (3.1788)	Acc@1 81.250 (76.453)	Acc@5 98.438 (94.098)
Epoch: [57][400/600]	Time 0.253 (0.246)	Data 0.184 (0.176)	Loss 3.1861 (3.1837)	Acc@1 79.688 (75.962)	Acc@5 93.750 (93.929)
Epoch: [57][500/600]	Time 0.247 (0.246)	Data 0.178 (0.176)	Loss 3.2094 (3.1875)	Acc@1 75.000 (75.633)	Acc@5 93.750 (93.803)
 * Acc@1 75.344 Acc@5 93.737
epoch 57, total time 146.92
Test: [0/586]	Time 0.073 (0.073)	Loss 3.3615 (3.3615)	Acc@1 78.125 (78.125)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.059 (0.065)	Loss 3.4438 (3.4493)	Acc@1 53.125 (55.476)	Acc@5 84.375 (84.653)
Test: [200/586]	Time 0.052 (0.066)	Loss 3.3507 (3.3986)	Acc@1 81.250 (61.023)	Acc@5 100.000 (85.712)
Test: [300/586]	Time 0.072 (0.066)	Loss 3.1117 (3.3645)	Acc@1 84.375 (64.327)	Acc@5 96.875 (87.500)
Test: [400/586]	Time 0.057 (0.064)	Loss 3.7116 (3.3342)	Acc@1 34.375 (66.513)	Acc@5 75.000 (88.287)
Test: [500/586]	Time 0.070 (0.065)	Loss 3.4859 (3.3376)	Acc@1 93.750 (67.178)	Acc@5 100.000 (88.804)
 * Acc@1 67.693 Acc@5 89.375
==> training...
Epoch: [58][0/600]	Time 0.271 (0.271)	Data 0.194 (0.194)	Loss 3.1860 (3.1860)	Acc@1 75.000 (75.000)	Acc@5 92.188 (92.188)
Epoch: [58][100/600]	Time 0.245 (0.250)	Data 0.174 (0.180)	Loss 3.1099 (3.1794)	Acc@1 82.812 (75.975)	Acc@5 92.188 (94.261)
Epoch: [58][200/600]	Time 0.254 (0.246)	Data 0.183 (0.176)	Loss 3.2950 (3.1812)	Acc@1 62.500 (75.964)	Acc@5 85.938 (94.053)
Epoch: [58][300/600]	Time 0.249 (0.247)	Data 0.180 (0.177)	Loss 3.1620 (3.1824)	Acc@1 81.250 (76.106)	Acc@5 93.750 (94.051)
Epoch: [58][400/600]	Time 0.262 (0.247)	Data 0.192 (0.177)	Loss 3.2102 (3.1847)	Acc@1 79.688 (75.927)	Acc@5 93.750 (94.031)
Epoch: [58][500/600]	Time 0.252 (0.248)	Data 0.180 (0.178)	Loss 3.1331 (3.1868)	Acc@1 79.688 (75.661)	Acc@5 98.438 (94.012)
 * Acc@1 75.557 Acc@5 93.924
epoch 58, total time 151.76
Test: [0/586]	Time 0.067 (0.067)	Loss 3.4032 (3.4032)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.067 (0.071)	Loss 3.4162 (3.3916)	Acc@1 75.000 (65.006)	Acc@5 96.875 (88.954)
Test: [200/586]	Time 0.063 (0.069)	Loss 3.0839 (3.3777)	Acc@1 87.500 (67.802)	Acc@5 100.000 (89.303)
Test: [300/586]	Time 0.052 (0.068)	Loss 3.1929 (3.3429)	Acc@1 81.250 (69.985)	Acc@5 93.750 (90.459)
Test: [400/586]	Time 0.054 (0.067)	Loss 3.6279 (3.3260)	Acc@1 59.375 (70.418)	Acc@5 87.500 (90.485)
Test: [500/586]	Time 0.076 (0.067)	Loss 3.1474 (3.3233)	Acc@1 84.375 (71.039)	Acc@5 90.625 (90.912)
 * Acc@1 69.453 Acc@5 90.756
==> training...
Epoch: [59][0/600]	Time 0.261 (0.261)	Data 0.191 (0.191)	Loss 3.1541 (3.1541)	Acc@1 81.250 (81.250)	Acc@5 96.875 (96.875)
Epoch: [59][100/600]	Time 0.284 (0.240)	Data 0.215 (0.170)	Loss 3.1796 (3.1629)	Acc@1 76.562 (77.707)	Acc@5 92.188 (94.787)
Epoch: [59][200/600]	Time 0.265 (0.245)	Data 0.192 (0.175)	Loss 3.1864 (3.1706)	Acc@1 78.125 (77.130)	Acc@5 95.312 (94.543)
Epoch: [59][300/600]	Time 0.268 (0.247)	Data 0.182 (0.176)	Loss 3.1815 (3.1767)	Acc@1 79.688 (76.588)	Acc@5 100.000 (94.466)
Epoch: [59][400/600]	Time 0.218 (0.246)	Data 0.149 (0.176)	Loss 3.1870 (3.1818)	Acc@1 76.562 (76.009)	Acc@5 95.312 (94.272)
Epoch: [59][500/600]	Time 0.230 (0.246)	Data 0.162 (0.176)	Loss 3.2600 (3.1842)	Acc@1 70.312 (75.811)	Acc@5 93.750 (94.205)
 * Acc@1 75.612 Acc@5 94.034
epoch 59, total time 148.29
Test: [0/586]	Time 0.079 (0.079)	Loss 3.3823 (3.3823)	Acc@1 65.625 (65.625)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.058 (0.062)	Loss 3.3367 (3.3936)	Acc@1 68.750 (62.562)	Acc@5 93.750 (87.717)
Test: [200/586]	Time 0.062 (0.061)	Loss 3.3406 (3.3388)	Acc@1 93.750 (68.797)	Acc@5 100.000 (90.081)
Test: [300/586]	Time 0.058 (0.061)	Loss 3.2114 (3.3288)	Acc@1 75.000 (67.971)	Acc@5 93.750 (90.210)
Test: [400/586]	Time 0.065 (0.062)	Loss 3.6799 (3.3157)	Acc@1 34.375 (68.664)	Acc@5 81.250 (90.157)
Test: [500/586]	Time 0.074 (0.062)	Loss 3.2639 (3.3260)	Acc@1 81.250 (67.952)	Acc@5 87.500 (89.515)
 * Acc@1 68.173 Acc@5 89.802
==> training...
Epoch: [60][0/600]	Time 0.283 (0.283)	Data 0.208 (0.208)	Loss 3.1362 (3.1362)	Acc@1 81.250 (81.250)	Acc@5 92.188 (92.188)
Epoch: [60][100/600]	Time 0.232 (0.240)	Data 0.165 (0.170)	Loss 3.2389 (3.1638)	Acc@1 70.312 (77.444)	Acc@5 90.625 (94.539)
Epoch: [60][200/600]	Time 0.221 (0.240)	Data 0.153 (0.171)	Loss 3.2737 (3.1732)	Acc@1 60.938 (76.920)	Acc@5 92.188 (94.209)
Epoch: [60][300/600]	Time 0.239 (0.242)	Data 0.165 (0.171)	Loss 3.1316 (3.1776)	Acc@1 82.812 (76.568)	Acc@5 96.875 (94.119)
Epoch: [60][400/600]	Time 0.266 (0.239)	Data 0.195 (0.169)	Loss 3.2220 (3.1819)	Acc@1 70.312 (76.021)	Acc@5 90.625 (93.968)
Epoch: [60][500/600]	Time 0.230 (0.240)	Data 0.159 (0.170)	Loss 3.1616 (3.1850)	Acc@1 78.125 (75.727)	Acc@5 90.625 (93.897)
 * Acc@1 75.534 Acc@5 93.909
epoch 60, total time 144.63
Test: [0/586]	Time 0.073 (0.073)	Loss 3.3356 (3.3356)	Acc@1 65.625 (65.625)	Acc@5 81.250 (81.250)
Test: [100/586]	Time 0.057 (0.063)	Loss 3.4489 (3.4532)	Acc@1 75.000 (57.488)	Acc@5 87.500 (83.137)
Test: [200/586]	Time 0.053 (0.064)	Loss 3.2257 (3.3911)	Acc@1 96.875 (64.490)	Acc@5 100.000 (87.080)
Test: [300/586]	Time 0.053 (0.063)	Loss 3.3995 (3.3654)	Acc@1 56.250 (65.718)	Acc@5 87.500 (88.279)
Test: [400/586]	Time 0.069 (0.062)	Loss 3.6199 (3.3466)	Acc@1 59.375 (66.895)	Acc@5 87.500 (88.638)
Test: [500/586]	Time 0.055 (0.062)	Loss 3.3131 (3.3490)	Acc@1 59.375 (66.748)	Acc@5 90.625 (88.748)
 * Acc@1 66.423 Acc@5 89.236
==> Saving...
==> training...
Epoch: [61][0/600]	Time 0.253 (0.253)	Data 0.184 (0.184)	Loss 3.1939 (3.1939)	Acc@1 76.562 (76.562)	Acc@5 98.438 (98.438)
Epoch: [61][100/600]	Time 0.223 (0.238)	Data 0.154 (0.167)	Loss 3.0718 (3.1079)	Acc@1 82.812 (82.271)	Acc@5 98.438 (96.256)
Epoch: [61][200/600]	Time 0.232 (0.240)	Data 0.159 (0.170)	Loss 3.0372 (3.0840)	Acc@1 89.062 (83.947)	Acc@5 98.438 (96.657)
Epoch: [61][300/600]	Time 0.260 (0.243)	Data 0.187 (0.173)	Loss 3.0650 (3.0745)	Acc@1 84.375 (84.546)	Acc@5 100.000 (96.896)
Epoch: [61][400/600]	Time 0.245 (0.241)	Data 0.173 (0.170)	Loss 3.0480 (3.0689)	Acc@1 85.938 (85.057)	Acc@5 96.875 (97.011)
Epoch: [61][500/600]	Time 0.246 (0.241)	Data 0.177 (0.171)	Loss 3.0201 (3.0630)	Acc@1 87.500 (85.532)	Acc@5 96.875 (97.118)
 * Acc@1 85.833 Acc@5 97.172
epoch 61, total time 145.63
Test: [0/586]	Time 0.072 (0.072)	Loss 3.2952 (3.2952)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.056 (0.062)	Loss 3.2423 (3.2254)	Acc@1 75.000 (77.599)	Acc@5 93.750 (94.276)
Test: [200/586]	Time 0.052 (0.060)	Loss 3.0080 (3.1858)	Acc@1 93.750 (80.426)	Acc@5 100.000 (94.854)
Test: [300/586]	Time 0.055 (0.062)	Loss 3.1271 (3.1691)	Acc@1 78.125 (81.250)	Acc@5 96.875 (95.162)
Test: [400/586]	Time 0.061 (0.062)	Loss 3.5678 (3.1576)	Acc@1 53.125 (82.248)	Acc@5 78.125 (95.254)
Test: [500/586]	Time 0.051 (0.062)	Loss 3.1432 (3.1616)	Acc@1 81.250 (81.755)	Acc@5 96.875 (95.241)
 * Acc@1 81.913 Acc@5 95.424
==> training...
Epoch: [62][0/600]	Time 0.257 (0.257)	Data 0.186 (0.186)	Loss 3.0479 (3.0479)	Acc@1 89.062 (89.062)	Acc@5 93.750 (93.750)
Epoch: [62][100/600]	Time 0.225 (0.229)	Data 0.157 (0.160)	Loss 3.0748 (3.0216)	Acc@1 81.250 (88.413)	Acc@5 95.312 (98.051)
Epoch: [62][200/600]	Time 0.170 (0.209)	Data 0.107 (0.142)	Loss 3.0072 (3.0211)	Acc@1 95.312 (88.790)	Acc@5 100.000 (97.940)
Epoch: [62][300/600]	Time 0.177 (0.203)	Data 0.114 (0.136)	Loss 3.0283 (3.0190)	Acc@1 93.750 (88.959)	Acc@5 98.438 (97.991)
Epoch: [62][400/600]	Time 0.192 (0.200)	Data 0.128 (0.134)	Loss 3.0264 (3.0183)	Acc@1 85.938 (89.047)	Acc@5 96.875 (98.056)
Epoch: [62][500/600]	Time 0.259 (0.206)	Data 0.190 (0.139)	Loss 3.0696 (3.0180)	Acc@1 85.938 (89.041)	Acc@5 93.750 (98.016)
 * Acc@1 89.042 Acc@5 98.047
epoch 62, total time 126.79
Test: [0/586]	Time 0.061 (0.061)	Loss 3.2717 (3.2717)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.066 (0.061)	Loss 3.2428 (3.2060)	Acc@1 75.000 (79.084)	Acc@5 100.000 (95.050)
Test: [200/586]	Time 0.053 (0.061)	Loss 2.9905 (3.1662)	Acc@1 93.750 (81.499)	Acc@5 100.000 (95.476)
Test: [300/586]	Time 0.053 (0.062)	Loss 3.1595 (3.1539)	Acc@1 75.000 (82.081)	Acc@5 96.875 (95.619)
Test: [400/586]	Time 0.068 (0.062)	Loss 3.5435 (3.1410)	Acc@1 59.375 (82.770)	Acc@5 84.375 (95.714)
Test: [500/586]	Time 0.060 (0.062)	Loss 3.1334 (3.1460)	Acc@1 84.375 (82.317)	Acc@5 96.875 (95.584)
 * Acc@1 82.558 Acc@5 95.818
==> training...
Epoch: [63][0/600]	Time 0.295 (0.295)	Data 0.216 (0.216)	Loss 2.9962 (2.9962)	Acc@1 93.750 (93.750)	Acc@5 96.875 (96.875)
Epoch: [63][100/600]	Time 0.213 (0.248)	Data 0.141 (0.177)	Loss 2.9997 (3.0000)	Acc@1 87.500 (90.006)	Acc@5 98.438 (98.298)
Epoch: [63][200/600]	Time 0.231 (0.247)	Data 0.165 (0.177)	Loss 3.0077 (3.0019)	Acc@1 92.188 (89.801)	Acc@5 98.438 (98.368)
Epoch: [63][300/600]	Time 0.225 (0.244)	Data 0.155 (0.174)	Loss 2.9920 (3.0031)	Acc@1 90.625 (90.028)	Acc@5 100.000 (98.266)
Epoch: [63][400/600]	Time 0.227 (0.243)	Data 0.156 (0.173)	Loss 3.0112 (3.0024)	Acc@1 84.375 (90.091)	Acc@5 96.875 (98.328)
Epoch: [63][500/600]	Time 0.233 (0.244)	Data 0.163 (0.174)	Loss 3.0599 (3.0027)	Acc@1 82.812 (90.070)	Acc@5 96.875 (98.344)
 * Acc@1 90.206 Acc@5 98.372
epoch 63, total time 146.63
Test: [0/586]	Time 0.066 (0.066)	Loss 3.2738 (3.2738)	Acc@1 78.125 (78.125)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.054 (0.059)	Loss 3.2509 (3.2008)	Acc@1 75.000 (78.991)	Acc@5 100.000 (95.080)
Test: [200/586]	Time 0.062 (0.061)	Loss 3.0266 (3.1647)	Acc@1 90.625 (81.530)	Acc@5 100.000 (95.351)
Test: [300/586]	Time 0.056 (0.062)	Loss 3.0985 (3.1509)	Acc@1 78.125 (82.371)	Acc@5 96.875 (95.619)
Test: [400/586]	Time 0.062 (0.062)	Loss 3.5470 (3.1350)	Acc@1 53.125 (83.081)	Acc@5 78.125 (95.722)
Test: [500/586]	Time 0.056 (0.062)	Loss 3.1362 (3.1422)	Acc@1 84.375 (82.610)	Acc@5 93.750 (95.590)
 * Acc@1 82.766 Acc@5 95.776
==> training...
Epoch: [64][0/600]	Time 0.240 (0.240)	Data 0.172 (0.172)	Loss 3.0100 (3.0100)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [64][100/600]	Time 0.272 (0.246)	Data 0.201 (0.175)	Loss 2.9723 (2.9904)	Acc@1 90.625 (90.857)	Acc@5 98.438 (98.329)
Epoch: [64][200/600]	Time 0.238 (0.246)	Data 0.171 (0.176)	Loss 2.9689 (2.9888)	Acc@1 95.312 (91.130)	Acc@5 100.000 (98.484)
Epoch: [64][300/600]	Time 0.232 (0.252)	Data 0.163 (0.182)	Loss 3.0398 (2.9894)	Acc@1 87.500 (90.988)	Acc@5 100.000 (98.469)
Epoch: [64][400/600]	Time 0.219 (0.246)	Data 0.148 (0.176)	Loss 2.9841 (2.9892)	Acc@1 93.750 (91.015)	Acc@5 100.000 (98.465)
Epoch: [64][500/600]	Time 0.251 (0.243)	Data 0.183 (0.173)	Loss 2.9998 (2.9890)	Acc@1 92.188 (91.055)	Acc@5 100.000 (98.553)
 * Acc@1 91.081 Acc@5 98.586
epoch 64, total time 144.82
Test: [0/586]	Time 0.052 (0.052)	Loss 3.2588 (3.2588)	Acc@1 81.250 (81.250)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.058 (0.061)	Loss 3.2457 (3.1960)	Acc@1 75.000 (78.744)	Acc@5 96.875 (94.493)
Test: [200/586]	Time 0.054 (0.060)	Loss 2.9544 (3.1558)	Acc@1 93.750 (81.794)	Acc@5 100.000 (95.305)
Test: [300/586]	Time 0.053 (0.060)	Loss 3.0850 (3.1404)	Acc@1 81.250 (82.787)	Acc@5 100.000 (95.754)
Test: [400/586]	Time 0.062 (0.068)	Loss 3.5262 (3.1240)	Acc@1 56.250 (83.603)	Acc@5 81.250 (95.870)
Test: [500/586]	Time 0.061 (0.066)	Loss 3.1059 (3.1276)	Acc@1 81.250 (83.383)	Acc@5 96.875 (95.796)
 * Acc@1 83.300 Acc@5 95.936
==> training...
Epoch: [65][0/600]	Time 0.273 (0.273)	Data 0.202 (0.202)	Loss 2.9973 (2.9973)	Acc@1 90.625 (90.625)	Acc@5 96.875 (96.875)
Epoch: [65][100/600]	Time 0.252 (0.243)	Data 0.180 (0.173)	Loss 2.9664 (2.9780)	Acc@1 92.188 (91.940)	Acc@5 98.438 (98.855)
Epoch: [65][200/600]	Time 0.241 (0.244)	Data 0.171 (0.174)	Loss 3.0094 (2.9793)	Acc@1 89.062 (91.768)	Acc@5 95.312 (98.818)
Epoch: [65][300/600]	Time 0.233 (0.243)	Data 0.162 (0.173)	Loss 2.9918 (2.9779)	Acc@1 93.750 (91.845)	Acc@5 98.438 (98.656)
Epoch: [65][400/600]	Time 0.268 (0.243)	Data 0.193 (0.173)	Loss 2.9217 (2.9787)	Acc@1 95.312 (91.821)	Acc@5 100.000 (98.648)
Epoch: [65][500/600]	Time 0.261 (0.244)	Data 0.193 (0.174)	Loss 3.0422 (2.9783)	Acc@1 87.500 (91.785)	Acc@5 93.750 (98.653)
 * Acc@1 91.784 Acc@5 98.633
epoch 65, total time 147.20
Test: [0/586]	Time 0.071 (0.071)	Loss 3.2233 (3.2233)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.062 (0.061)	Loss 3.1801 (3.1864)	Acc@1 78.125 (78.868)	Acc@5 96.875 (95.204)
Test: [200/586]	Time 0.070 (0.063)	Loss 3.0374 (3.1503)	Acc@1 93.750 (82.105)	Acc@5 100.000 (95.849)
Test: [300/586]	Time 0.064 (0.065)	Loss 3.1670 (3.1372)	Acc@1 81.250 (82.496)	Acc@5 100.000 (95.826)
Test: [400/586]	Time 0.075 (0.064)	Loss 3.4559 (3.1247)	Acc@1 56.250 (83.042)	Acc@5 78.125 (95.823)
Test: [500/586]	Time 0.063 (0.064)	Loss 3.1149 (3.1293)	Acc@1 84.375 (82.878)	Acc@5 93.750 (95.684)
 * Acc@1 83.172 Acc@5 95.882
==> training...
Epoch: [66][0/600]	Time 0.261 (0.261)	Data 0.187 (0.187)	Loss 2.9486 (2.9486)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [66][100/600]	Time 0.209 (0.235)	Data 0.138 (0.166)	Loss 2.9035 (2.9657)	Acc@1 98.438 (93.100)	Acc@5 100.000 (98.886)
Epoch: [66][200/600]	Time 0.234 (0.239)	Data 0.161 (0.170)	Loss 3.0226 (2.9688)	Acc@1 90.625 (92.786)	Acc@5 95.312 (98.865)
Epoch: [66][300/600]	Time 0.228 (0.243)	Data 0.161 (0.173)	Loss 2.9199 (2.9673)	Acc@1 96.875 (92.868)	Acc@5 100.000 (98.884)
Epoch: [66][400/600]	Time 0.216 (0.244)	Data 0.141 (0.174)	Loss 2.9720 (2.9679)	Acc@1 89.062 (92.694)	Acc@5 98.438 (98.874)
Epoch: [66][500/600]	Time 0.224 (0.243)	Data 0.156 (0.173)	Loss 2.9793 (2.9696)	Acc@1 92.188 (92.593)	Acc@5 100.000 (98.855)
 * Acc@1 92.513 Acc@5 98.859
epoch 66, total time 146.42
Test: [0/586]	Time 0.059 (0.059)	Loss 3.2163 (3.2163)	Acc@1 81.250 (81.250)	Acc@5 84.375 (84.375)
Test: [100/586]	Time 0.065 (0.063)	Loss 3.2363 (3.1768)	Acc@1 75.000 (78.527)	Acc@5 96.875 (94.616)
Test: [200/586]	Time 0.070 (0.062)	Loss 3.0537 (3.1421)	Acc@1 93.750 (81.312)	Acc@5 100.000 (95.180)
Test: [300/586]	Time 0.059 (0.063)	Loss 3.0650 (3.1321)	Acc@1 81.250 (82.164)	Acc@5 96.875 (95.307)
Test: [400/586]	Time 0.057 (0.062)	Loss 3.4636 (3.1195)	Acc@1 53.125 (83.183)	Acc@5 81.250 (95.589)
Test: [500/586]	Time 0.051 (0.061)	Loss 3.0842 (3.1231)	Acc@1 90.625 (82.984)	Acc@5 93.750 (95.528)
 * Acc@1 82.937 Acc@5 95.712
==> training...
Epoch: [67][0/600]	Time 0.207 (0.207)	Data 0.136 (0.136)	Loss 2.9938 (2.9938)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [67][100/600]	Time 0.263 (0.240)	Data 0.191 (0.170)	Loss 2.9967 (2.9645)	Acc@1 92.188 (92.899)	Acc@5 95.312 (98.917)
Epoch: [67][200/600]	Time 0.273 (0.247)	Data 0.202 (0.177)	Loss 2.9644 (2.9613)	Acc@1 93.750 (93.198)	Acc@5 98.438 (98.997)
Epoch: [67][300/600]	Time 0.226 (0.247)	Data 0.155 (0.177)	Loss 2.9971 (2.9631)	Acc@1 85.938 (92.893)	Acc@5 95.312 (98.931)
Epoch: [67][400/600]	Time 0.217 (0.247)	Data 0.147 (0.176)	Loss 2.9851 (2.9640)	Acc@1 89.062 (92.799)	Acc@5 100.000 (98.928)
Epoch: [67][500/600]	Time 0.237 (0.245)	Data 0.168 (0.175)	Loss 3.0191 (2.9640)	Acc@1 87.500 (92.805)	Acc@5 96.875 (98.958)
 * Acc@1 92.818 Acc@5 98.977
epoch 67, total time 146.64
Test: [0/586]	Time 0.068 (0.068)	Loss 3.2899 (3.2899)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.067 (0.065)	Loss 3.2210 (3.1888)	Acc@1 75.000 (77.506)	Acc@5 93.750 (94.709)
Test: [200/586]	Time 0.052 (0.064)	Loss 2.9884 (3.1408)	Acc@1 93.750 (81.203)	Acc@5 100.000 (95.336)
Test: [300/586]	Time 0.056 (0.064)	Loss 3.0400 (3.1243)	Acc@1 84.375 (82.018)	Acc@5 93.750 (95.494)
Test: [400/586]	Time 0.052 (0.063)	Loss 3.4513 (3.1091)	Acc@1 53.125 (83.120)	Acc@5 87.500 (95.768)
Test: [500/586]	Time 0.059 (0.063)	Loss 3.1237 (3.1140)	Acc@1 84.375 (82.940)	Acc@5 93.750 (95.690)
 * Acc@1 83.204 Acc@5 95.882
==> training...
Epoch: [68][0/600]	Time 0.271 (0.271)	Data 0.200 (0.200)	Loss 2.9751 (2.9751)	Acc@1 95.312 (95.312)	Acc@5 96.875 (96.875)
Epoch: [68][100/600]	Time 0.255 (0.245)	Data 0.182 (0.175)	Loss 2.9777 (2.9537)	Acc@1 90.625 (93.502)	Acc@5 100.000 (99.257)
Epoch: [68][200/600]	Time 0.216 (0.247)	Data 0.147 (0.176)	Loss 2.9420 (2.9563)	Acc@1 95.312 (93.330)	Acc@5 98.438 (99.168)
Epoch: [68][300/600]	Time 0.232 (0.249)	Data 0.165 (0.178)	Loss 3.0157 (2.9552)	Acc@1 82.812 (93.428)	Acc@5 98.438 (99.143)
Epoch: [68][400/600]	Time 0.256 (0.248)	Data 0.187 (0.178)	Loss 2.9931 (2.9560)	Acc@1 87.500 (93.353)	Acc@5 98.438 (99.119)
Epoch: [68][500/600]	Time 0.287 (0.247)	Data 0.211 (0.176)	Loss 2.9741 (2.9568)	Acc@1 96.875 (93.335)	Acc@5 98.438 (99.077)
 * Acc@1 93.292 Acc@5 99.021
epoch 68, total time 147.81
Test: [0/586]	Time 0.075 (0.075)	Loss 3.2417 (3.2417)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.062 (0.061)	Loss 3.1947 (3.1779)	Acc@1 81.250 (80.817)	Acc@5 100.000 (94.864)
Test: [200/586]	Time 0.053 (0.061)	Loss 2.9834 (3.1316)	Acc@1 90.625 (82.945)	Acc@5 100.000 (95.351)
Test: [300/586]	Time 0.053 (0.060)	Loss 3.0600 (3.1202)	Acc@1 84.375 (83.056)	Acc@5 96.875 (95.515)
Test: [400/586]	Time 0.050 (0.060)	Loss 3.5117 (3.1094)	Acc@1 53.125 (83.752)	Acc@5 78.125 (95.683)
Test: [500/586]	Time 0.051 (0.060)	Loss 3.1048 (3.1171)	Acc@1 87.500 (83.196)	Acc@5 93.750 (95.534)
 * Acc@1 83.300 Acc@5 95.722
==> training...
Epoch: [69][0/600]	Time 0.267 (0.267)	Data 0.193 (0.193)	Loss 2.9092 (2.9092)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [69][100/600]	Time 0.207 (0.249)	Data 0.139 (0.178)	Loss 2.9454 (2.9489)	Acc@1 93.750 (93.982)	Acc@5 100.000 (99.288)
Epoch: [69][200/600]	Time 0.230 (0.246)	Data 0.162 (0.176)	Loss 2.9073 (2.9484)	Acc@1 100.000 (94.209)	Acc@5 100.000 (99.331)
Epoch: [69][300/600]	Time 0.240 (0.245)	Data 0.171 (0.175)	Loss 2.9847 (2.9495)	Acc@1 92.188 (94.061)	Acc@5 96.875 (99.263)
Epoch: [69][400/600]	Time 0.210 (0.244)	Data 0.144 (0.174)	Loss 2.9731 (2.9492)	Acc@1 90.625 (94.058)	Acc@5 96.875 (99.236)
Epoch: [69][500/600]	Time 0.276 (0.244)	Data 0.206 (0.174)	Loss 2.9441 (2.9503)	Acc@1 92.188 (93.925)	Acc@5 96.875 (99.205)
 * Acc@1 93.883 Acc@5 99.206
epoch 69, total time 146.44
Test: [0/586]	Time 0.060 (0.060)	Loss 3.2281 (3.2281)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.064 (0.062)	Loss 3.1489 (3.1712)	Acc@1 75.000 (79.425)	Acc@5 96.875 (94.895)
Test: [200/586]	Time 0.064 (0.063)	Loss 3.0054 (3.1266)	Acc@1 90.625 (81.810)	Acc@5 100.000 (95.289)
Test: [300/586]	Time 0.054 (0.063)	Loss 3.0633 (3.1152)	Acc@1 87.500 (82.527)	Acc@5 100.000 (95.546)
Test: [400/586]	Time 0.056 (0.063)	Loss 3.5137 (3.1031)	Acc@1 56.250 (83.167)	Acc@5 78.125 (95.597)
Test: [500/586]	Time 0.050 (0.064)	Loss 3.1270 (3.1098)	Acc@1 84.375 (82.672)	Acc@5 93.750 (95.497)
 * Acc@1 83.081 Acc@5 95.738
==> training...
Epoch: [70][0/600]	Time 0.272 (0.272)	Data 0.203 (0.203)	Loss 2.9125 (2.9125)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [70][100/600]	Time 0.205 (0.234)	Data 0.138 (0.165)	Loss 2.9922 (2.9436)	Acc@1 89.062 (94.291)	Acc@5 98.438 (99.242)
Epoch: [70][200/600]	Time 0.200 (0.221)	Data 0.135 (0.153)	Loss 2.9532 (2.9416)	Acc@1 93.750 (94.434)	Acc@5 100.000 (99.324)
Epoch: [70][300/600]	Time 0.191 (0.214)	Data 0.125 (0.146)	Loss 2.9589 (2.9432)	Acc@1 92.188 (94.295)	Acc@5 98.438 (99.362)
Epoch: [70][400/600]	Time 0.181 (0.208)	Data 0.115 (0.141)	Loss 2.9290 (2.9435)	Acc@1 93.750 (94.272)	Acc@5 100.000 (99.338)
Epoch: [70][500/600]	Time 0.215 (0.214)	Data 0.147 (0.146)	Loss 2.9485 (2.9447)	Acc@1 93.750 (94.171)	Acc@5 100.000 (99.270)
 * Acc@1 94.177 Acc@5 99.250
epoch 70, total time 132.44
Test: [0/586]	Time 0.068 (0.068)	Loss 3.1895 (3.1895)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.071 (0.063)	Loss 3.1757 (3.1789)	Acc@1 81.250 (77.908)	Acc@5 100.000 (94.276)
Test: [200/586]	Time 0.052 (0.062)	Loss 2.9933 (3.1282)	Acc@1 87.500 (81.561)	Acc@5 100.000 (95.211)
Test: [300/586]	Time 0.066 (0.064)	Loss 3.0508 (3.1143)	Acc@1 87.500 (82.278)	Acc@5 93.750 (95.525)
Test: [400/586]	Time 0.056 (0.064)	Loss 3.4738 (3.1030)	Acc@1 56.250 (83.074)	Acc@5 84.375 (95.597)
Test: [500/586]	Time 0.070 (0.064)	Loss 3.0779 (3.1088)	Acc@1 90.625 (82.653)	Acc@5 93.750 (95.528)
 * Acc@1 82.905 Acc@5 95.754
==> Saving...
==> training...
Epoch: [71][0/600]	Time 0.240 (0.240)	Data 0.170 (0.170)	Loss 2.9479 (2.9479)	Acc@1 95.312 (95.312)	Acc@5 98.438 (98.438)
Epoch: [71][100/600]	Time 0.272 (0.245)	Data 0.200 (0.174)	Loss 2.9171 (2.9314)	Acc@1 90.625 (95.096)	Acc@5 100.000 (99.520)
Epoch: [71][200/600]	Time 0.253 (0.244)	Data 0.186 (0.174)	Loss 2.9230 (2.9355)	Acc@1 98.438 (94.955)	Acc@5 100.000 (99.409)
Epoch: [71][300/600]	Time 0.256 (0.244)	Data 0.185 (0.174)	Loss 2.9015 (2.9388)	Acc@1 100.000 (94.845)	Acc@5 100.000 (99.377)
Epoch: [71][400/600]	Time 0.207 (0.242)	Data 0.140 (0.172)	Loss 2.9586 (2.9398)	Acc@1 92.188 (94.732)	Acc@5 98.438 (99.295)
Epoch: [71][500/600]	Time 0.228 (0.242)	Data 0.161 (0.172)	Loss 2.9475 (2.9412)	Acc@1 96.875 (94.539)	Acc@5 98.438 (99.245)
 * Acc@1 94.570 Acc@5 99.242
epoch 71, total time 145.23
Test: [0/586]	Time 0.066 (0.066)	Loss 3.2299 (3.2299)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.065 (0.063)	Loss 3.1986 (3.1723)	Acc@1 81.250 (79.579)	Acc@5 90.625 (94.895)
Test: [200/586]	Time 0.058 (0.064)	Loss 3.0050 (3.1291)	Acc@1 90.625 (81.732)	Acc@5 100.000 (95.149)
Test: [300/586]	Time 0.068 (0.063)	Loss 3.0964 (3.1179)	Acc@1 84.375 (82.195)	Acc@5 93.750 (95.370)
Test: [400/586]	Time 0.057 (0.063)	Loss 3.4541 (3.1063)	Acc@1 59.375 (82.925)	Acc@5 87.500 (95.519)
Test: [500/586]	Time 0.051 (0.063)	Loss 3.0982 (3.1110)	Acc@1 87.500 (82.791)	Acc@5 93.750 (95.459)
 * Acc@1 83.129 Acc@5 95.626
==> training...
Epoch: [72][0/600]	Time 0.268 (0.268)	Data 0.197 (0.197)	Loss 2.9124 (2.9124)	Acc@1 95.312 (95.312)	Acc@5 98.438 (98.438)
Epoch: [72][100/600]	Time 0.214 (0.225)	Data 0.145 (0.156)	Loss 2.9362 (2.9279)	Acc@1 95.312 (95.514)	Acc@5 98.438 (99.381)
Epoch: [72][200/600]	Time 0.212 (0.225)	Data 0.144 (0.156)	Loss 2.9450 (2.9301)	Acc@1 95.312 (95.585)	Acc@5 100.000 (99.409)
Epoch: [72][300/600]	Time 0.237 (0.231)	Data 0.169 (0.162)	Loss 2.9339 (2.9323)	Acc@1 93.750 (95.416)	Acc@5 100.000 (99.372)
Epoch: [72][400/600]	Time 0.250 (0.234)	Data 0.181 (0.165)	Loss 2.9379 (2.9345)	Acc@1 95.312 (95.289)	Acc@5 98.438 (99.377)
Epoch: [72][500/600]	Time 0.201 (0.232)	Data 0.134 (0.163)	Loss 2.9532 (2.9356)	Acc@1 92.188 (95.147)	Acc@5 100.000 (99.386)
 * Acc@1 95.112 Acc@5 99.393
epoch 72, total time 136.94
Test: [0/586]	Time 0.049 (0.049)	Loss 3.2103 (3.2103)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.059 (0.053)	Loss 3.1629 (3.1825)	Acc@1 78.125 (77.197)	Acc@5 90.625 (93.998)
Test: [200/586]	Time 0.050 (0.057)	Loss 2.9748 (3.1364)	Acc@1 90.625 (81.172)	Acc@5 100.000 (94.916)
Test: [300/586]	Time 0.054 (0.056)	Loss 3.0304 (3.1212)	Acc@1 87.500 (81.759)	Acc@5 93.750 (95.276)
Test: [400/586]	Time 0.049 (0.055)	Loss 3.4080 (3.1100)	Acc@1 56.250 (82.777)	Acc@5 90.625 (95.449)
Test: [500/586]	Time 0.055 (0.057)	Loss 3.1047 (3.1150)	Acc@1 90.625 (82.473)	Acc@5 93.750 (95.341)
 * Acc@1 82.910 Acc@5 95.621
==> training...
Epoch: [73][0/600]	Time 0.259 (0.259)	Data 0.183 (0.183)	Loss 2.9140 (2.9140)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [73][100/600]	Time 0.236 (0.215)	Data 0.168 (0.147)	Loss 2.9254 (2.9265)	Acc@1 93.750 (95.931)	Acc@5 100.000 (99.520)
Epoch: [73][200/600]	Time 0.238 (0.222)	Data 0.167 (0.154)	Loss 2.8971 (2.9288)	Acc@1 98.438 (95.577)	Acc@5 100.000 (99.487)
Epoch: [73][300/600]	Time 0.213 (0.229)	Data 0.143 (0.160)	Loss 2.9582 (2.9304)	Acc@1 90.625 (95.344)	Acc@5 100.000 (99.476)
Epoch: [73][400/600]	Time 0.257 (0.234)	Data 0.189 (0.164)	Loss 2.9632 (2.9319)	Acc@1 93.750 (95.270)	Acc@5 100.000 (99.396)
Epoch: [73][500/600]	Time 0.219 (0.236)	Data 0.149 (0.166)	Loss 2.9238 (2.9313)	Acc@1 96.875 (95.278)	Acc@5 100.000 (99.389)
 * Acc@1 95.206 Acc@5 99.422
epoch 73, total time 143.59
Test: [0/586]	Time 0.061 (0.061)	Loss 3.1910 (3.1910)	Acc@1 78.125 (78.125)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.054 (0.063)	Loss 3.1868 (3.1912)	Acc@1 71.875 (76.145)	Acc@5 93.750 (94.338)
Test: [200/586]	Time 0.059 (0.061)	Loss 2.9952 (3.1327)	Acc@1 93.750 (80.986)	Acc@5 100.000 (95.289)
Test: [300/586]	Time 0.070 (0.062)	Loss 3.0199 (3.1191)	Acc@1 87.500 (82.018)	Acc@5 93.750 (95.505)
Test: [400/586]	Time 0.062 (0.062)	Loss 3.4763 (3.1043)	Acc@1 50.000 (82.980)	Acc@5 87.500 (95.706)
Test: [500/586]	Time 0.052 (0.062)	Loss 3.0855 (3.1083)	Acc@1 90.625 (82.635)	Acc@5 93.750 (95.571)
 * Acc@1 83.006 Acc@5 95.808
==> training...
Epoch: [74][0/600]	Time 0.263 (0.263)	Data 0.189 (0.189)	Loss 2.9048 (2.9048)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [74][100/600]	Time 0.235 (0.239)	Data 0.167 (0.169)	Loss 2.8965 (2.9283)	Acc@1 98.438 (95.096)	Acc@5 100.000 (99.675)
Epoch: [74][200/600]	Time 0.269 (0.240)	Data 0.197 (0.170)	Loss 2.9733 (2.9253)	Acc@1 89.062 (95.585)	Acc@5 96.875 (99.658)
Epoch: [74][300/600]	Time 0.240 (0.240)	Data 0.173 (0.170)	Loss 2.9765 (2.9261)	Acc@1 93.750 (95.603)	Acc@5 100.000 (99.631)
Epoch: [74][400/600]	Time 0.216 (0.241)	Data 0.148 (0.171)	Loss 2.9543 (2.9267)	Acc@1 93.750 (95.609)	Acc@5 100.000 (99.630)
Epoch: [74][500/600]	Time 0.241 (0.287)	Data 0.173 (0.217)	Loss 2.9793 (2.9273)	Acc@1 95.312 (95.574)	Acc@5 98.438 (99.601)
 * Acc@1 95.539 Acc@5 99.578
epoch 74, total time 168.97
Test: [0/586]	Time 0.068 (0.068)	Loss 3.1957 (3.1957)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.060 (0.059)	Loss 3.2486 (3.1737)	Acc@1 71.875 (78.249)	Acc@5 90.625 (94.462)
Test: [200/586]	Time 0.053 (0.059)	Loss 2.9648 (3.1308)	Acc@1 93.750 (81.001)	Acc@5 100.000 (95.149)
Test: [300/586]	Time 0.070 (0.060)	Loss 3.0053 (3.1153)	Acc@1 87.500 (82.008)	Acc@5 96.875 (95.473)
Test: [400/586]	Time 0.068 (0.060)	Loss 3.4569 (3.1040)	Acc@1 56.250 (83.081)	Acc@5 87.500 (95.690)
Test: [500/586]	Time 0.057 (0.060)	Loss 3.1051 (3.1074)	Acc@1 93.750 (83.009)	Acc@5 93.750 (95.590)
 * Acc@1 83.001 Acc@5 95.744
==> training...
Epoch: [75][0/600]	Time 0.247 (0.247)	Data 0.179 (0.179)	Loss 2.9710 (2.9710)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)
Epoch: [75][100/600]	Time 0.258 (0.255)	Data 0.189 (0.184)	Loss 2.9173 (2.9210)	Acc@1 96.875 (95.792)	Acc@5 100.000 (99.582)
Epoch: [75][200/600]	Time 0.225 (0.251)	Data 0.156 (0.180)	Loss 2.9103 (2.9231)	Acc@1 100.000 (95.779)	Acc@5 100.000 (99.627)
Epoch: [75][300/600]	Time 0.222 (0.247)	Data 0.150 (0.177)	Loss 2.9371 (2.9242)	Acc@1 95.312 (95.806)	Acc@5 96.875 (99.507)
Epoch: [75][400/600]	Time 0.272 (0.249)	Data 0.201 (0.178)	Loss 2.9943 (2.9243)	Acc@1 90.625 (95.772)	Acc@5 98.438 (99.560)
Epoch: [75][500/600]	Time 0.273 (0.247)	Data 0.204 (0.177)	Loss 2.9543 (2.9252)	Acc@1 93.750 (95.705)	Acc@5 100.000 (99.535)
 * Acc@1 95.724 Acc@5 99.539
epoch 75, total time 148.77
Test: [0/586]	Time 0.057 (0.057)	Loss 3.2357 (3.2357)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.068 (0.063)	Loss 3.2043 (3.1799)	Acc@1 71.875 (79.394)	Acc@5 93.750 (94.462)
Test: [200/586]	Time 0.060 (0.062)	Loss 3.0594 (3.1398)	Acc@1 90.625 (81.996)	Acc@5 100.000 (95.227)
Test: [300/586]	Time 0.054 (0.062)	Loss 3.1037 (3.1251)	Acc@1 81.250 (82.579)	Acc@5 96.875 (95.723)
Test: [400/586]	Time 0.052 (0.063)	Loss 3.4267 (3.1137)	Acc@1 59.375 (83.222)	Acc@5 93.750 (95.823)
Test: [500/586]	Time 0.063 (0.063)	Loss 3.1413 (3.1174)	Acc@1 84.375 (83.065)	Acc@5 93.750 (95.684)
 * Acc@1 82.825 Acc@5 95.818
==> training...
Epoch: [76][0/600]	Time 0.268 (0.268)	Data 0.198 (0.198)	Loss 2.8892 (2.8892)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [76][100/600]	Time 0.274 (0.250)	Data 0.201 (0.180)	Loss 2.9016 (2.9190)	Acc@1 95.312 (96.225)	Acc@5 100.000 (99.598)
Epoch: [76][200/600]	Time 0.244 (0.248)	Data 0.173 (0.177)	Loss 2.9302 (2.9202)	Acc@1 90.625 (96.098)	Acc@5 98.438 (99.588)
Epoch: [76][300/600]	Time 0.253 (0.247)	Data 0.179 (0.176)	Loss 2.9407 (2.9190)	Acc@1 90.625 (96.190)	Acc@5 100.000 (99.605)
Epoch: [76][400/600]	Time 0.224 (0.248)	Data 0.153 (0.177)	Loss 2.9068 (2.9191)	Acc@1 95.312 (96.209)	Acc@5 100.000 (99.614)
Epoch: [76][500/600]	Time 0.278 (0.247)	Data 0.206 (0.176)	Loss 2.9534 (2.9216)	Acc@1 92.188 (96.058)	Acc@5 98.438 (99.585)
 * Acc@1 96.021 Acc@5 99.586
epoch 76, total time 147.96
Test: [0/586]	Time 0.062 (0.062)	Loss 3.2453 (3.2453)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.056 (0.062)	Loss 3.3229 (3.1754)	Acc@1 81.250 (80.105)	Acc@5 100.000 (94.957)
Test: [200/586]	Time 0.060 (0.062)	Loss 3.0196 (3.1324)	Acc@1 87.500 (82.447)	Acc@5 96.875 (95.258)
Test: [300/586]	Time 0.062 (0.062)	Loss 3.0632 (3.1171)	Acc@1 81.250 (82.787)	Acc@5 93.750 (95.505)
Test: [400/586]	Time 0.060 (0.063)	Loss 3.4198 (3.1051)	Acc@1 62.500 (83.222)	Acc@5 93.750 (95.620)
Test: [500/586]	Time 0.066 (0.063)	Loss 3.1040 (3.1109)	Acc@1 84.375 (83.046)	Acc@5 93.750 (95.490)
 * Acc@1 83.188 Acc@5 95.754
==> training...
Epoch: [77][0/600]	Time 0.257 (0.257)	Data 0.185 (0.185)	Loss 2.8774 (2.8774)	Acc@1 98.438 (98.438)	Acc@5 98.438 (98.438)
Epoch: [77][100/600]	Time 0.228 (0.245)	Data 0.157 (0.175)	Loss 2.8721 (2.9128)	Acc@1 98.438 (96.550)	Acc@5 100.000 (99.660)
Epoch: [77][200/600]	Time 0.220 (0.245)	Data 0.151 (0.175)	Loss 2.9526 (2.9146)	Acc@1 96.875 (96.339)	Acc@5 98.438 (99.689)
Epoch: [77][300/600]	Time 0.225 (0.245)	Data 0.156 (0.175)	Loss 2.9077 (2.9160)	Acc@1 95.312 (96.320)	Acc@5 98.438 (99.694)
Epoch: [77][400/600]	Time 0.216 (0.246)	Data 0.149 (0.175)	Loss 2.9612 (2.9169)	Acc@1 89.062 (96.244)	Acc@5 100.000 (99.680)
Epoch: [77][500/600]	Time 0.248 (0.245)	Data 0.181 (0.175)	Loss 2.9437 (2.9177)	Acc@1 93.750 (96.251)	Acc@5 100.000 (99.682)
 * Acc@1 96.135 Acc@5 99.651
epoch 77, total time 147.48
Test: [0/586]	Time 0.070 (0.070)	Loss 3.2233 (3.2233)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.053 (0.064)	Loss 3.1656 (3.1583)	Acc@1 78.125 (79.610)	Acc@5 93.750 (94.585)
Test: [200/586]	Time 0.056 (0.064)	Loss 2.9765 (3.1125)	Acc@1 93.750 (82.292)	Acc@5 100.000 (95.211)
Test: [300/586]	Time 0.049 (0.061)	Loss 3.0429 (3.0995)	Acc@1 84.375 (82.620)	Acc@5 96.875 (95.515)
Test: [400/586]	Time 0.048 (0.060)	Loss 3.3764 (3.0895)	Acc@1 56.250 (83.315)	Acc@5 90.625 (95.745)
Test: [500/586]	Time 0.051 (0.059)	Loss 3.0762 (3.0960)	Acc@1 84.375 (82.959)	Acc@5 93.750 (95.584)
 * Acc@1 82.990 Acc@5 95.738
==> training...
Epoch: [78][0/600]	Time 0.213 (0.213)	Data 0.149 (0.149)	Loss 2.8898 (2.8898)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [78][100/600]	Time 0.177 (0.196)	Data 0.110 (0.130)	Loss 2.9196 (2.9147)	Acc@1 96.875 (96.504)	Acc@5 100.000 (99.737)
Epoch: [78][200/600]	Time 0.187 (0.191)	Data 0.119 (0.126)	Loss 2.8875 (2.9146)	Acc@1 96.875 (96.572)	Acc@5 100.000 (99.728)
Epoch: [78][300/600]	Time 0.251 (0.206)	Data 0.182 (0.139)	Loss 2.9294 (2.9144)	Acc@1 96.875 (96.538)	Acc@5 98.438 (99.709)
Epoch: [78][400/600]	Time 0.273 (0.217)	Data 0.199 (0.149)	Loss 2.8918 (2.9143)	Acc@1 100.000 (96.618)	Acc@5 100.000 (99.700)
Epoch: [78][500/600]	Time 0.269 (0.222)	Data 0.197 (0.154)	Loss 2.9993 (2.9151)	Acc@1 89.062 (96.495)	Acc@5 100.000 (99.697)
 * Acc@1 96.443 Acc@5 99.693
epoch 78, total time 135.36
Test: [0/586]	Time 0.065 (0.065)	Loss 3.3588 (3.3588)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Test: [100/586]	Time 0.056 (0.060)	Loss 3.1737 (3.1824)	Acc@1 81.250 (78.991)	Acc@5 93.750 (94.493)
Test: [200/586]	Time 0.063 (0.061)	Loss 3.0125 (3.1303)	Acc@1 87.500 (81.825)	Acc@5 96.875 (95.087)
Test: [300/586]	Time 0.075 (0.063)	Loss 3.0204 (3.1164)	Acc@1 84.375 (82.402)	Acc@5 96.875 (95.349)
Test: [400/586]	Time 0.051 (0.063)	Loss 3.3676 (3.1032)	Acc@1 53.125 (83.432)	Acc@5 96.875 (95.581)
Test: [500/586]	Time 0.065 (0.062)	Loss 3.1103 (3.1100)	Acc@1 84.375 (82.828)	Acc@5 93.750 (95.390)
 * Acc@1 83.033 Acc@5 95.642
==> training...
Epoch: [79][0/600]	Time 0.282 (0.282)	Data 0.210 (0.210)	Loss 2.8932 (2.8932)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [79][100/600]	Time 0.232 (0.247)	Data 0.164 (0.176)	Loss 2.8842 (2.9098)	Acc@1 96.875 (97.014)	Acc@5 100.000 (99.613)
Epoch: [79][200/600]	Time 0.221 (0.247)	Data 0.150 (0.176)	Loss 2.8813 (2.9119)	Acc@1 98.438 (96.859)	Acc@5 100.000 (99.681)
Epoch: [79][300/600]	Time 0.240 (0.247)	Data 0.170 (0.176)	Loss 2.8988 (2.9114)	Acc@1 96.875 (96.818)	Acc@5 100.000 (99.714)
Epoch: [79][400/600]	Time 0.266 (0.243)	Data 0.195 (0.173)	Loss 2.8981 (2.9129)	Acc@1 96.875 (96.680)	Acc@5 100.000 (99.716)
Epoch: [79][500/600]	Time 0.269 (0.243)	Data 0.199 (0.173)	Loss 2.9387 (2.9137)	Acc@1 93.750 (96.560)	Acc@5 100.000 (99.719)
 * Acc@1 96.583 Acc@5 99.701
epoch 79, total time 145.25
Test: [0/586]	Time 0.070 (0.070)	Loss 3.2176 (3.2176)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.072 (0.062)	Loss 3.2013 (3.1638)	Acc@1 68.750 (79.610)	Acc@5 96.875 (94.833)
Test: [200/586]	Time 0.057 (0.062)	Loss 3.0798 (3.1341)	Acc@1 90.625 (82.385)	Acc@5 100.000 (95.009)
Test: [300/586]	Time 0.068 (0.062)	Loss 3.0533 (3.1190)	Acc@1 84.375 (82.838)	Acc@5 96.875 (95.224)
Test: [400/586]	Time 0.057 (0.062)	Loss 3.4688 (3.1074)	Acc@1 43.750 (83.081)	Acc@5 87.500 (95.285)
Test: [500/586]	Time 0.049 (0.061)	Loss 3.1162 (3.1137)	Acc@1 90.625 (82.672)	Acc@5 93.750 (95.191)
 * Acc@1 83.060 Acc@5 95.461
==> training...
Epoch: [80][0/600]	Time 0.222 (0.222)	Data 0.154 (0.154)	Loss 2.9547 (2.9547)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [80][100/600]	Time 0.218 (0.234)	Data 0.150 (0.165)	Loss 2.9250 (2.9061)	Acc@1 96.875 (97.246)	Acc@5 100.000 (99.722)
Epoch: [80][200/600]	Time 0.207 (0.233)	Data 0.141 (0.164)	Loss 2.8808 (2.9095)	Acc@1 96.875 (97.015)	Acc@5 100.000 (99.689)
Epoch: [80][300/600]	Time 0.257 (0.230)	Data 0.186 (0.161)	Loss 2.9324 (2.9104)	Acc@1 95.312 (96.891)	Acc@5 98.438 (99.689)
Epoch: [80][400/600]	Time 0.249 (0.228)	Data 0.177 (0.160)	Loss 2.9521 (2.9106)	Acc@1 95.312 (96.856)	Acc@5 100.000 (99.719)
Epoch: [80][500/600]	Time 0.193 (0.226)	Data 0.124 (0.157)	Loss 2.9364 (2.9117)	Acc@1 96.875 (96.788)	Acc@5 98.438 (99.682)
 * Acc@1 96.753 Acc@5 99.688
epoch 80, total time 135.32
Test: [0/586]	Time 0.057 (0.057)	Loss 3.2065 (3.2065)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.050 (0.059)	Loss 3.2223 (3.1678)	Acc@1 75.000 (79.394)	Acc@5 93.750 (94.585)
Test: [200/586]	Time 0.063 (0.058)	Loss 3.0151 (3.1204)	Acc@1 87.500 (81.748)	Acc@5 100.000 (95.180)
Test: [300/586]	Time 0.055 (0.057)	Loss 3.1086 (3.1131)	Acc@1 75.000 (82.247)	Acc@5 96.875 (95.318)
Test: [400/586]	Time 0.061 (0.057)	Loss 3.5400 (3.0997)	Acc@1 50.000 (83.307)	Acc@5 84.375 (95.418)
Test: [500/586]	Time 0.049 (0.058)	Loss 3.1243 (3.1058)	Acc@1 84.375 (82.965)	Acc@5 93.750 (95.247)
 * Acc@1 83.129 Acc@5 95.461
==> Saving...
==> training...
Epoch: [81][0/600]	Time 0.262 (0.262)	Data 0.189 (0.189)	Loss 2.9259 (2.9259)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [81][100/600]	Time 0.211 (0.231)	Data 0.141 (0.162)	Loss 2.8682 (2.8951)	Acc@1 96.875 (97.664)	Acc@5 100.000 (99.861)
Epoch: [81][200/600]	Time 0.209 (0.227)	Data 0.143 (0.158)	Loss 2.9046 (2.8919)	Acc@1 98.438 (97.909)	Acc@5 100.000 (99.876)
Epoch: [81][300/600]	Time 0.222 (0.225)	Data 0.154 (0.157)	Loss 2.8904 (2.8898)	Acc@1 98.438 (98.007)	Acc@5 100.000 (99.865)
Epoch: [81][400/600]	Time 0.242 (0.223)	Data 0.173 (0.155)	Loss 2.8833 (2.8885)	Acc@1 100.000 (97.986)	Acc@5 100.000 (99.860)
Epoch: [81][500/600]	Time 0.224 (0.223)	Data 0.158 (0.155)	Loss 2.8800 (2.8883)	Acc@1 96.875 (97.945)	Acc@5 100.000 (99.847)
 * Acc@1 97.971 Acc@5 99.849
epoch 81, total time 133.62
Test: [0/586]	Time 0.061 (0.061)	Loss 3.2028 (3.2028)	Acc@1 71.875 (71.875)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.051 (0.058)	Loss 3.1906 (3.1473)	Acc@1 75.000 (80.229)	Acc@5 96.875 (95.111)
Test: [200/586]	Time 0.057 (0.060)	Loss 2.9568 (3.1007)	Acc@1 90.625 (82.836)	Acc@5 100.000 (95.662)
Test: [300/586]	Time 0.051 (0.059)	Loss 3.0493 (3.0880)	Acc@1 81.250 (83.389)	Acc@5 100.000 (96.013)
Test: [400/586]	Time 0.056 (0.059)	Loss 3.4255 (3.0761)	Acc@1 56.250 (84.281)	Acc@5 90.625 (96.049)
Test: [500/586]	Time 0.051 (0.058)	Loss 3.1046 (3.0816)	Acc@1 87.500 (84.026)	Acc@5 93.750 (95.896)
 * Acc@1 84.148 Acc@5 96.074
==> training...
Epoch: [82][0/600]	Time 0.221 (0.221)	Data 0.153 (0.153)	Loss 2.9106 (2.9106)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [82][100/600]	Time 0.223 (0.224)	Data 0.156 (0.156)	Loss 2.9149 (2.8797)	Acc@1 96.875 (98.175)	Acc@5 100.000 (99.923)
Epoch: [82][200/600]	Time 0.201 (0.221)	Data 0.133 (0.153)	Loss 2.8652 (2.8795)	Acc@1 98.438 (98.243)	Acc@5 100.000 (99.922)
Epoch: [82][300/600]	Time 0.244 (0.222)	Data 0.178 (0.154)	Loss 2.8666 (2.8773)	Acc@1 100.000 (98.328)	Acc@5 100.000 (99.891)
Epoch: [82][400/600]	Time 0.182 (0.219)	Data 0.117 (0.151)	Loss 2.8727 (2.8768)	Acc@1 98.438 (98.418)	Acc@5 100.000 (99.895)
Epoch: [82][500/600]	Time 0.209 (0.221)	Data 0.141 (0.153)	Loss 2.8801 (2.8769)	Acc@1 100.000 (98.422)	Acc@5 100.000 (99.891)
 * Acc@1 98.471 Acc@5 99.893
epoch 82, total time 133.60
Test: [0/586]	Time 0.070 (0.070)	Loss 3.1896 (3.1896)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.051 (0.055)	Loss 3.1631 (3.1435)	Acc@1 68.750 (79.858)	Acc@5 93.750 (95.235)
Test: [200/586]	Time 0.051 (0.055)	Loss 2.9722 (3.0991)	Acc@1 90.625 (82.805)	Acc@5 100.000 (95.678)
Test: [300/586]	Time 0.061 (0.055)	Loss 3.0249 (3.0874)	Acc@1 81.250 (83.493)	Acc@5 100.000 (95.920)
Test: [400/586]	Time 0.051 (0.055)	Loss 3.4120 (3.0758)	Acc@1 56.250 (84.375)	Acc@5 90.625 (96.033)
Test: [500/586]	Time 0.059 (0.056)	Loss 3.1140 (3.0816)	Acc@1 87.500 (84.138)	Acc@5 93.750 (95.883)
 * Acc@1 84.270 Acc@5 96.048
==> training...
Epoch: [83][0/600]	Time 0.214 (0.214)	Data 0.148 (0.148)	Loss 2.8700 (2.8700)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [83][100/600]	Time 0.238 (0.232)	Data 0.168 (0.164)	Loss 2.8560 (2.8742)	Acc@1 98.438 (98.515)	Acc@5 100.000 (99.861)
Epoch: [83][200/600]	Time 0.255 (0.229)	Data 0.186 (0.160)	Loss 2.9226 (2.8750)	Acc@1 98.438 (98.507)	Acc@5 98.438 (99.876)
Epoch: [83][300/600]	Time 0.232 (0.229)	Data 0.165 (0.160)	Loss 2.8657 (2.8748)	Acc@1 100.000 (98.557)	Acc@5 100.000 (99.886)
Epoch: [83][400/600]	Time 0.203 (0.228)	Data 0.137 (0.159)	Loss 2.8670 (2.8752)	Acc@1 98.438 (98.512)	Acc@5 100.000 (99.895)
Epoch: [83][500/600]	Time 0.224 (0.227)	Data 0.157 (0.159)	Loss 2.8621 (2.8748)	Acc@1 100.000 (98.550)	Acc@5 100.000 (99.897)
 * Acc@1 98.516 Acc@5 99.896
epoch 83, total time 136.58
Test: [0/586]	Time 0.066 (0.066)	Loss 3.1959 (3.1959)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.051 (0.056)	Loss 3.1744 (3.1421)	Acc@1 78.125 (79.486)	Acc@5 96.875 (95.173)
Test: [200/586]	Time 0.053 (0.059)	Loss 2.9593 (3.0973)	Acc@1 90.625 (82.696)	Acc@5 100.000 (95.756)
Test: [300/586]	Time 0.055 (0.059)	Loss 3.0398 (3.0842)	Acc@1 84.375 (83.420)	Acc@5 100.000 (96.003)
Test: [400/586]	Time 0.052 (0.059)	Loss 3.3818 (3.0717)	Acc@1 56.250 (84.320)	Acc@5 93.750 (96.103)
Test: [500/586]	Time 0.057 (0.058)	Loss 3.1042 (3.0771)	Acc@1 87.500 (84.169)	Acc@5 93.750 (96.002)
 * Acc@1 84.334 Acc@5 96.192
==> training...
Epoch: [84][0/600]	Time 0.247 (0.247)	Data 0.173 (0.173)	Loss 2.9074 (2.9074)	Acc@1 96.875 (96.875)	Acc@5 98.438 (98.438)
Epoch: [84][100/600]	Time 0.212 (0.229)	Data 0.141 (0.160)	Loss 2.8746 (2.8727)	Acc@1 98.438 (98.608)	Acc@5 100.000 (99.830)
Epoch: [84][200/600]	Time 0.217 (0.227)	Data 0.146 (0.158)	Loss 2.8680 (2.8738)	Acc@1 100.000 (98.577)	Acc@5 100.000 (99.907)
Epoch: [84][300/600]	Time 0.208 (0.230)	Data 0.140 (0.161)	Loss 2.8867 (2.8730)	Acc@1 96.875 (98.572)	Acc@5 98.438 (99.922)
Epoch: [84][400/600]	Time 0.203 (0.227)	Data 0.138 (0.158)	Loss 2.8955 (2.8727)	Acc@1 96.875 (98.636)	Acc@5 100.000 (99.918)
Epoch: [84][500/600]	Time 0.190 (0.226)	Data 0.124 (0.157)	Loss 2.8408 (2.8725)	Acc@1 100.000 (98.640)	Acc@5 100.000 (99.922)
 * Acc@1 98.591 Acc@5 99.911
epoch 84, total time 135.87
Test: [0/586]	Time 0.063 (0.063)	Loss 3.2008 (3.2008)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.064 (0.060)	Loss 3.1765 (3.1456)	Acc@1 71.875 (79.455)	Acc@5 90.625 (94.926)
Test: [200/586]	Time 0.061 (0.059)	Loss 2.9733 (3.0982)	Acc@1 90.625 (82.494)	Acc@5 100.000 (95.569)
Test: [300/586]	Time 0.062 (0.057)	Loss 3.0403 (3.0847)	Acc@1 84.375 (83.295)	Acc@5 100.000 (95.930)
Test: [400/586]	Time 0.057 (0.058)	Loss 3.3851 (3.0724)	Acc@1 56.250 (84.211)	Acc@5 93.750 (96.096)
Test: [500/586]	Time 0.050 (0.057)	Loss 3.0958 (3.0775)	Acc@1 87.500 (84.051)	Acc@5 93.750 (95.964)
 * Acc@1 84.260 Acc@5 96.160
==> training...
Epoch: [85][0/600]	Time 0.260 (0.260)	Data 0.189 (0.189)	Loss 2.8771 (2.8771)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [85][100/600]	Time 0.215 (0.231)	Data 0.148 (0.162)	Loss 2.8932 (2.8737)	Acc@1 100.000 (98.685)	Acc@5 100.000 (99.938)
Epoch: [85][200/600]	Time 0.236 (0.228)	Data 0.170 (0.160)	Loss 2.8620 (2.8720)	Acc@1 98.438 (98.725)	Acc@5 100.000 (99.930)
Epoch: [85][300/600]	Time 0.212 (0.232)	Data 0.147 (0.163)	Loss 2.8563 (2.8715)	Acc@1 100.000 (98.728)	Acc@5 100.000 (99.933)
Epoch: [85][400/600]	Time 0.228 (0.233)	Data 0.162 (0.164)	Loss 2.8417 (2.8708)	Acc@1 100.000 (98.706)	Acc@5 100.000 (99.930)
Epoch: [85][500/600]	Time 0.235 (0.234)	Data 0.165 (0.166)	Loss 2.8503 (2.8708)	Acc@1 100.000 (98.721)	Acc@5 100.000 (99.935)
 * Acc@1 98.714 Acc@5 99.927
epoch 85, total time 140.55
Test: [0/586]	Time 0.057 (0.057)	Loss 3.1933 (3.1933)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.051 (0.059)	Loss 3.1798 (3.1417)	Acc@1 75.000 (79.889)	Acc@5 93.750 (94.957)
Test: [200/586]	Time 0.048 (0.057)	Loss 2.9674 (3.0962)	Acc@1 90.625 (82.618)	Acc@5 100.000 (95.616)
Test: [300/586]	Time 0.050 (0.054)	Loss 3.0372 (3.0833)	Acc@1 84.375 (83.461)	Acc@5 100.000 (95.920)
Test: [400/586]	Time 0.047 (0.054)	Loss 3.4001 (3.0708)	Acc@1 59.375 (84.336)	Acc@5 93.750 (95.979)
Test: [500/586]	Time 0.046 (0.054)	Loss 3.0859 (3.0765)	Acc@1 87.500 (84.044)	Acc@5 93.750 (95.889)
 * Acc@1 84.233 Acc@5 96.096
==> training...
Epoch: [86][0/600]	Time 0.223 (0.223)	Data 0.156 (0.156)	Loss 2.8682 (2.8682)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [86][100/600]	Time 0.180 (0.185)	Data 0.116 (0.120)	Loss 2.8513 (2.8655)	Acc@1 100.000 (98.716)	Acc@5 100.000 (99.907)
Epoch: [86][200/600]	Time 0.213 (0.189)	Data 0.147 (0.124)	Loss 2.8811 (2.8674)	Acc@1 98.438 (98.741)	Acc@5 100.000 (99.891)
Epoch: [86][300/600]	Time 0.244 (0.201)	Data 0.176 (0.135)	Loss 2.8596 (2.8686)	Acc@1 100.000 (98.687)	Acc@5 100.000 (99.912)
Epoch: [86][400/600]	Time 0.214 (0.208)	Data 0.148 (0.142)	Loss 2.9018 (2.8690)	Acc@1 93.750 (98.675)	Acc@5 100.000 (99.922)
Epoch: [86][500/600]	Time 0.213 (0.213)	Data 0.146 (0.145)	Loss 2.9061 (2.8698)	Acc@1 98.438 (98.668)	Acc@5 98.438 (99.910)
 * Acc@1 98.688 Acc@5 99.901
epoch 86, total time 129.54
Test: [0/586]	Time 0.055 (0.055)	Loss 3.2121 (3.2121)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.053 (0.065)	Loss 3.1901 (3.1443)	Acc@1 75.000 (80.043)	Acc@5 93.750 (95.019)
Test: [200/586]	Time 0.071 (0.063)	Loss 2.9867 (3.0969)	Acc@1 90.625 (82.914)	Acc@5 100.000 (95.616)
Test: [300/586]	Time 0.055 (0.060)	Loss 3.0083 (3.0837)	Acc@1 84.375 (83.607)	Acc@5 100.000 (95.951)
Test: [400/586]	Time 0.060 (0.059)	Loss 3.3968 (3.0719)	Acc@1 59.375 (84.476)	Acc@5 93.750 (96.065)
Test: [500/586]	Time 0.056 (0.059)	Loss 3.0845 (3.0779)	Acc@1 90.625 (84.194)	Acc@5 93.750 (95.977)
 * Acc@1 84.388 Acc@5 96.160
==> training...
Epoch: [87][0/600]	Time 0.255 (0.255)	Data 0.185 (0.185)	Loss 2.8359 (2.8359)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [87][100/600]	Time 0.221 (0.234)	Data 0.152 (0.165)	Loss 2.8705 (2.8685)	Acc@1 98.438 (98.762)	Acc@5 100.000 (99.969)
Epoch: [87][200/600]	Time 0.219 (0.231)	Data 0.153 (0.162)	Loss 2.8642 (2.8686)	Acc@1 100.000 (98.787)	Acc@5 100.000 (99.930)
Epoch: [87][300/600]	Time 0.203 (0.230)	Data 0.137 (0.161)	Loss 2.8534 (2.8684)	Acc@1 100.000 (98.816)	Acc@5 100.000 (99.917)
Epoch: [87][400/600]	Time 0.222 (0.230)	Data 0.151 (0.162)	Loss 2.8670 (2.8681)	Acc@1 100.000 (98.827)	Acc@5 100.000 (99.914)
Epoch: [87][500/600]	Time 0.237 (0.231)	Data 0.170 (0.162)	Loss 2.8763 (2.8683)	Acc@1 98.438 (98.784)	Acc@5 100.000 (99.913)
 * Acc@1 98.760 Acc@5 99.914
epoch 87, total time 140.64
Test: [0/586]	Time 0.069 (0.069)	Loss 3.1985 (3.1985)	Acc@1 75.000 (75.000)	Acc@5 87.500 (87.500)
Test: [100/586]	Time 0.068 (0.058)	Loss 3.1650 (3.1434)	Acc@1 71.875 (78.960)	Acc@5 96.875 (94.616)
Test: [200/586]	Time 0.064 (0.057)	Loss 2.9719 (3.0934)	Acc@1 90.625 (82.525)	Acc@5 100.000 (95.445)
Test: [300/586]	Time 0.050 (0.059)	Loss 3.0213 (3.0799)	Acc@1 81.250 (83.233)	Acc@5 100.000 (95.785)
Test: [400/586]	Time 0.058 (0.057)	Loss 3.4075 (3.0678)	Acc@1 59.375 (84.087)	Acc@5 93.750 (95.940)
Test: [500/586]	Time 0.052 (0.057)	Loss 3.0750 (3.0737)	Acc@1 90.625 (84.051)	Acc@5 93.750 (95.877)
 * Acc@1 84.238 Acc@5 96.058
==> training...
Epoch: [88][0/600]	Time 0.269 (0.269)	Data 0.198 (0.198)	Loss 2.8574 (2.8574)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [88][100/600]	Time 0.223 (0.227)	Data 0.157 (0.159)	Loss 2.8556 (2.8687)	Acc@1 100.000 (98.778)	Acc@5 100.000 (99.861)
Epoch: [88][200/600]	Time 0.229 (0.229)	Data 0.162 (0.160)	Loss 2.8802 (2.8676)	Acc@1 98.438 (98.803)	Acc@5 100.000 (99.907)
Epoch: [88][300/600]	Time 0.244 (0.228)	Data 0.175 (0.160)	Loss 2.8512 (2.8692)	Acc@1 98.438 (98.681)	Acc@5 100.000 (99.901)
Epoch: [88][400/600]	Time 0.210 (0.229)	Data 0.141 (0.160)	Loss 2.8824 (2.8686)	Acc@1 98.438 (98.730)	Acc@5 100.000 (99.910)
Epoch: [88][500/600]	Time 0.228 (0.230)	Data 0.160 (0.161)	Loss 2.8815 (2.8682)	Acc@1 98.438 (98.743)	Acc@5 100.000 (99.919)
 * Acc@1 98.766 Acc@5 99.917
epoch 88, total time 138.73
Test: [0/586]	Time 0.064 (0.064)	Loss 3.2117 (3.2117)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.053 (0.059)	Loss 3.1526 (3.1449)	Acc@1 78.125 (79.672)	Acc@5 93.750 (94.709)
Test: [200/586]	Time 0.064 (0.059)	Loss 2.9874 (3.0958)	Acc@1 90.625 (82.929)	Acc@5 100.000 (95.398)
Test: [300/586]	Time 0.051 (0.058)	Loss 3.0329 (3.0822)	Acc@1 81.250 (83.659)	Acc@5 100.000 (95.754)
Test: [400/586]	Time 0.065 (0.059)	Loss 3.3937 (3.0702)	Acc@1 62.500 (84.391)	Acc@5 93.750 (95.909)
Test: [500/586]	Time 0.052 (0.059)	Loss 3.0873 (3.0755)	Acc@1 87.500 (84.188)	Acc@5 93.750 (95.796)
 * Acc@1 84.313 Acc@5 95.973
==> training...
Epoch: [89][0/600]	Time 0.213 (0.213)	Data 0.143 (0.143)	Loss 2.8529 (2.8529)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [89][100/600]	Time 0.259 (0.230)	Data 0.193 (0.161)	Loss 2.8729 (2.8660)	Acc@1 98.438 (98.886)	Acc@5 100.000 (99.969)
Epoch: [89][200/600]	Time 0.250 (0.227)	Data 0.182 (0.158)	Loss 2.8797 (2.8657)	Acc@1 96.875 (98.881)	Acc@5 100.000 (99.946)
Epoch: [89][300/600]	Time 0.255 (0.227)	Data 0.190 (0.158)	Loss 2.8699 (2.8670)	Acc@1 98.438 (98.806)	Acc@5 100.000 (99.933)
Epoch: [89][400/600]	Time 0.220 (0.226)	Data 0.152 (0.157)	Loss 2.8948 (2.8667)	Acc@1 96.875 (98.796)	Acc@5 98.438 (99.926)
Epoch: [89][500/600]	Time 0.238 (0.221)	Data 0.173 (0.153)	Loss 2.8776 (2.8662)	Acc@1 96.875 (98.812)	Acc@5 100.000 (99.928)
 * Acc@1 98.820 Acc@5 99.927
epoch 89, total time 133.05
Test: [0/586]	Time 0.059 (0.059)	Loss 3.1725 (3.1725)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.069 (0.060)	Loss 3.1666 (3.1392)	Acc@1 78.125 (79.703)	Acc@5 96.875 (94.926)
Test: [200/586]	Time 0.063 (0.060)	Loss 2.9864 (3.0934)	Acc@1 90.625 (82.945)	Acc@5 100.000 (95.569)
Test: [300/586]	Time 0.051 (0.059)	Loss 3.0171 (3.0816)	Acc@1 87.500 (83.461)	Acc@5 100.000 (95.795)
Test: [400/586]	Time 0.059 (0.058)	Loss 3.3896 (3.0697)	Acc@1 59.375 (84.289)	Acc@5 93.750 (95.940)
Test: [500/586]	Time 0.054 (0.059)	Loss 3.0893 (3.0749)	Acc@1 87.500 (84.163)	Acc@5 93.750 (95.852)
 * Acc@1 84.217 Acc@5 96.016
==> training...
Epoch: [90][0/600]	Time 0.255 (0.255)	Data 0.187 (0.187)	Loss 2.8733 (2.8733)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [90][100/600]	Time 0.234 (0.233)	Data 0.159 (0.164)	Loss 2.8730 (2.8658)	Acc@1 98.438 (98.886)	Acc@5 100.000 (99.938)
Epoch: [90][200/600]	Time 0.241 (0.238)	Data 0.170 (0.169)	Loss 2.8644 (2.8658)	Acc@1 98.438 (98.865)	Acc@5 100.000 (99.946)
Epoch: [90][300/600]	Time 0.209 (0.236)	Data 0.141 (0.167)	Loss 2.8441 (2.8652)	Acc@1 100.000 (98.910)	Acc@5 100.000 (99.943)
Epoch: [90][400/600]	Time 0.228 (0.237)	Data 0.159 (0.168)	Loss 2.8402 (2.8651)	Acc@1 100.000 (98.866)	Acc@5 100.000 (99.926)
Epoch: [90][500/600]	Time 0.196 (0.231)	Data 0.130 (0.162)	Loss 2.8758 (2.8649)	Acc@1 98.438 (98.915)	Acc@5 100.000 (99.941)
 * Acc@1 98.891 Acc@5 99.935
epoch 90, total time 135.40
Test: [0/586]	Time 0.049 (0.049)	Loss 3.2112 (3.2112)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.051 (0.049)	Loss 3.1532 (3.1415)	Acc@1 78.125 (80.136)	Acc@5 96.875 (94.926)
Test: [200/586]	Time 0.048 (0.049)	Loss 2.9853 (3.0951)	Acc@1 90.625 (83.100)	Acc@5 100.000 (95.522)
Test: [300/586]	Time 0.050 (0.055)	Loss 3.0116 (3.0825)	Acc@1 81.250 (83.607)	Acc@5 96.875 (95.795)
Test: [400/586]	Time 0.073 (0.055)	Loss 3.3979 (3.0700)	Acc@1 59.375 (84.469)	Acc@5 93.750 (95.963)
Test: [500/586]	Time 0.068 (0.057)	Loss 3.1006 (3.0757)	Acc@1 87.500 (84.101)	Acc@5 93.750 (95.840)
 * Acc@1 84.233 Acc@5 96.058
==> Saving...
==> training...
Epoch: [91][0/600]	Time 0.228 (0.228)	Data 0.156 (0.156)	Loss 2.8522 (2.8522)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [91][100/600]	Time 0.253 (0.238)	Data 0.184 (0.168)	Loss 2.8715 (2.8656)	Acc@1 98.438 (98.731)	Acc@5 100.000 (99.938)
Epoch: [91][200/600]	Time 0.258 (0.239)	Data 0.188 (0.169)	Loss 2.8483 (2.8662)	Acc@1 100.000 (98.787)	Acc@5 100.000 (99.938)
Epoch: [91][300/600]	Time 0.231 (0.238)	Data 0.162 (0.168)	Loss 2.8375 (2.8650)	Acc@1 100.000 (98.884)	Acc@5 100.000 (99.948)
Epoch: [91][400/600]	Time 0.263 (0.237)	Data 0.195 (0.167)	Loss 2.8493 (2.8646)	Acc@1 100.000 (98.905)	Acc@5 100.000 (99.949)
Epoch: [91][500/600]	Time 0.219 (0.238)	Data 0.153 (0.168)	Loss 2.8495 (2.8655)	Acc@1 98.438 (98.846)	Acc@5 100.000 (99.944)
 * Acc@1 98.880 Acc@5 99.943
epoch 91, total time 142.84
Test: [0/586]	Time 0.113 (0.113)	Loss 3.1873 (3.1873)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.050 (0.060)	Loss 3.1515 (3.1367)	Acc@1 75.000 (79.827)	Acc@5 96.875 (94.895)
Test: [200/586]	Time 0.053 (0.059)	Loss 2.9761 (3.0900)	Acc@1 90.625 (83.022)	Acc@5 100.000 (95.647)
Test: [300/586]	Time 0.064 (0.061)	Loss 3.0041 (3.0778)	Acc@1 84.375 (83.607)	Acc@5 100.000 (95.930)
Test: [400/586]	Time 0.065 (0.061)	Loss 3.3976 (3.0662)	Acc@1 65.625 (84.492)	Acc@5 93.750 (96.018)
Test: [500/586]	Time 0.054 (0.061)	Loss 3.0838 (3.0731)	Acc@1 87.500 (84.088)	Acc@5 93.750 (95.883)
 * Acc@1 84.356 Acc@5 96.058
==> training...
Epoch: [92][0/600]	Time 0.286 (0.286)	Data 0.216 (0.216)	Loss 2.8482 (2.8482)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [92][100/600]	Time 0.232 (0.250)	Data 0.166 (0.178)	Loss 2.8583 (2.8621)	Acc@1 98.438 (99.149)	Acc@5 100.000 (99.969)
Epoch: [92][200/600]	Time 0.208 (0.248)	Data 0.141 (0.178)	Loss 2.8485 (2.8611)	Acc@1 98.438 (99.114)	Acc@5 100.000 (99.969)
Epoch: [92][300/600]	Time 0.265 (0.246)	Data 0.194 (0.176)	Loss 2.8594 (2.8632)	Acc@1 100.000 (99.045)	Acc@5 100.000 (99.948)
Epoch: [92][400/600]	Time 0.277 (0.245)	Data 0.207 (0.175)	Loss 2.8549 (2.8630)	Acc@1 100.000 (99.057)	Acc@5 100.000 (99.942)
Epoch: [92][500/600]	Time 0.232 (0.245)	Data 0.159 (0.174)	Loss 2.8531 (2.8632)	Acc@1 100.000 (99.046)	Acc@5 100.000 (99.931)
 * Acc@1 99.029 Acc@5 99.922
epoch 92, total time 147.31
Test: [0/586]	Time 0.082 (0.082)	Loss 3.2030 (3.2030)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.059 (0.064)	Loss 3.1575 (3.1405)	Acc@1 78.125 (79.796)	Acc@5 93.750 (95.050)
Test: [200/586]	Time 0.061 (0.064)	Loss 2.9795 (3.0955)	Acc@1 90.625 (82.945)	Acc@5 100.000 (95.569)
Test: [300/586]	Time 0.053 (0.064)	Loss 3.0409 (3.0818)	Acc@1 81.250 (83.607)	Acc@5 93.750 (95.889)
Test: [400/586]	Time 0.055 (0.064)	Loss 3.3909 (3.0690)	Acc@1 59.375 (84.375)	Acc@5 93.750 (95.955)
Test: [500/586]	Time 0.050 (0.063)	Loss 3.0875 (3.0754)	Acc@1 90.625 (84.044)	Acc@5 93.750 (95.821)
 * Acc@1 84.222 Acc@5 96.026
==> training...
Epoch: [93][0/600]	Time 0.294 (0.294)	Data 0.222 (0.222)	Loss 2.8976 (2.8976)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [93][100/600]	Time 0.258 (0.248)	Data 0.188 (0.178)	Loss 2.8434 (2.8601)	Acc@1 100.000 (98.948)	Acc@5 100.000 (99.985)
Epoch: [93][200/600]	Time 0.275 (0.247)	Data 0.202 (0.176)	Loss 2.8399 (2.8624)	Acc@1 100.000 (98.966)	Acc@5 100.000 (99.930)
Epoch: [93][300/600]	Time 0.272 (0.246)	Data 0.198 (0.175)	Loss 2.8359 (2.8627)	Acc@1 100.000 (98.983)	Acc@5 100.000 (99.943)
Epoch: [93][400/600]	Time 0.250 (0.247)	Data 0.181 (0.176)	Loss 2.8370 (2.8627)	Acc@1 100.000 (98.999)	Acc@5 100.000 (99.945)
Epoch: [93][500/600]	Time 0.230 (0.249)	Data 0.159 (0.178)	Loss 2.8477 (2.8634)	Acc@1 100.000 (98.986)	Acc@5 100.000 (99.941)
 * Acc@1 99.005 Acc@5 99.940
epoch 93, total time 147.02
Test: [0/586]	Time 0.054 (0.054)	Loss 3.1915 (3.1915)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.051 (0.056)	Loss 3.1569 (3.1430)	Acc@1 75.000 (79.270)	Acc@5 93.750 (94.709)
Test: [200/586]	Time 0.047 (0.053)	Loss 2.9801 (3.0943)	Acc@1 90.625 (82.711)	Acc@5 100.000 (95.429)
Test: [300/586]	Time 0.049 (0.053)	Loss 3.0231 (3.0815)	Acc@1 81.250 (83.368)	Acc@5 100.000 (95.743)
Test: [400/586]	Time 0.058 (0.053)	Loss 3.4250 (3.0695)	Acc@1 59.375 (84.188)	Acc@5 93.750 (95.854)
Test: [500/586]	Time 0.048 (0.052)	Loss 3.0944 (3.0754)	Acc@1 90.625 (83.988)	Acc@5 93.750 (95.783)
 * Acc@1 84.153 Acc@5 95.984
==> training...
Epoch: [94][0/600]	Time 0.197 (0.197)	Data 0.131 (0.131)	Loss 2.8845 (2.8845)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [94][100/600]	Time 0.181 (0.191)	Data 0.116 (0.126)	Loss 2.8643 (2.8643)	Acc@1 98.438 (98.871)	Acc@5 100.000 (99.938)
Epoch: [94][200/600]	Time 0.213 (0.214)	Data 0.145 (0.147)	Loss 2.8396 (2.8627)	Acc@1 100.000 (98.997)	Acc@5 100.000 (99.938)
Epoch: [94][300/600]	Time 0.230 (0.228)	Data 0.163 (0.159)	Loss 2.8618 (2.8624)	Acc@1 96.875 (99.019)	Acc@5 100.000 (99.953)
Epoch: [94][400/600]	Time 0.244 (0.234)	Data 0.178 (0.165)	Loss 2.8521 (2.8627)	Acc@1 98.438 (98.987)	Acc@5 100.000 (99.953)
Epoch: [94][500/600]	Time 0.246 (0.236)	Data 0.177 (0.167)	Loss 2.8475 (2.8627)	Acc@1 98.438 (98.943)	Acc@5 100.000 (99.944)
 * Acc@1 98.911 Acc@5 99.948
epoch 94, total time 143.33
Test: [0/586]	Time 0.066 (0.066)	Loss 3.1968 (3.1968)	Acc@1 71.875 (71.875)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.051 (0.064)	Loss 3.1627 (3.1385)	Acc@1 75.000 (79.734)	Acc@5 96.875 (94.833)
Test: [200/586]	Time 0.070 (0.065)	Loss 2.9793 (3.0918)	Acc@1 90.625 (83.007)	Acc@5 100.000 (95.460)
Test: [300/586]	Time 0.070 (0.065)	Loss 3.0151 (3.0792)	Acc@1 84.375 (83.472)	Acc@5 100.000 (95.816)
Test: [400/586]	Time 0.062 (0.064)	Loss 3.3897 (3.0686)	Acc@1 65.625 (84.367)	Acc@5 93.750 (95.963)
Test: [500/586]	Time 0.067 (0.064)	Loss 3.0874 (3.0744)	Acc@1 90.625 (84.157)	Acc@5 93.750 (95.852)
 * Acc@1 84.270 Acc@5 96.042
==> training...
Epoch: [95][0/600]	Time 0.230 (0.230)	Data 0.163 (0.163)	Loss 2.8784 (2.8784)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [95][100/600]	Time 0.240 (0.250)	Data 0.166 (0.179)	Loss 2.8933 (2.8630)	Acc@1 98.438 (98.902)	Acc@5 100.000 (99.907)
Epoch: [95][200/600]	Time 0.228 (0.250)	Data 0.160 (0.179)	Loss 2.8450 (2.8622)	Acc@1 100.000 (98.873)	Acc@5 100.000 (99.946)
Epoch: [95][300/600]	Time 0.234 (0.248)	Data 0.165 (0.178)	Loss 2.8414 (2.8620)	Acc@1 100.000 (98.863)	Acc@5 100.000 (99.948)
Epoch: [95][400/600]	Time 0.211 (0.245)	Data 0.143 (0.175)	Loss 2.8523 (2.8623)	Acc@1 100.000 (98.893)	Acc@5 100.000 (99.949)
Epoch: [95][500/600]	Time 0.229 (0.243)	Data 0.161 (0.173)	Loss 2.8652 (2.8619)	Acc@1 98.438 (98.940)	Acc@5 100.000 (99.950)
 * Acc@1 98.971 Acc@5 99.951
epoch 95, total time 144.19
Test: [0/586]	Time 0.049 (0.049)	Loss 3.1977 (3.1977)	Acc@1 71.875 (71.875)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.050 (0.050)	Loss 3.1382 (3.1359)	Acc@1 78.125 (79.950)	Acc@5 96.875 (94.895)
Test: [200/586]	Time 0.049 (0.051)	Loss 2.9770 (3.0912)	Acc@1 90.625 (83.007)	Acc@5 100.000 (95.522)
Test: [300/586]	Time 0.049 (0.051)	Loss 3.0243 (3.0782)	Acc@1 84.375 (83.555)	Acc@5 96.875 (95.889)
Test: [400/586]	Time 0.049 (0.051)	Loss 3.4257 (3.0669)	Acc@1 56.250 (84.453)	Acc@5 93.750 (95.987)
Test: [500/586]	Time 0.047 (0.051)	Loss 3.0942 (3.0729)	Acc@1 90.625 (84.125)	Acc@5 93.750 (95.877)
 * Acc@1 84.324 Acc@5 96.106
==> training...
Epoch: [96][0/600]	Time 0.199 (0.199)	Data 0.134 (0.134)	Loss 2.8601 (2.8601)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [96][100/600]	Time 0.266 (0.231)	Data 0.191 (0.162)	Loss 2.8641 (2.8574)	Acc@1 100.000 (99.288)	Acc@5 100.000 (99.954)
Epoch: [96][200/600]	Time 0.249 (0.239)	Data 0.177 (0.169)	Loss 2.8614 (2.8593)	Acc@1 98.438 (99.269)	Acc@5 100.000 (99.969)
Epoch: [96][300/600]	Time 0.213 (0.240)	Data 0.144 (0.170)	Loss 2.8671 (2.8602)	Acc@1 98.438 (99.169)	Acc@5 100.000 (99.953)
Epoch: [96][400/600]	Time 0.237 (0.240)	Data 0.169 (0.170)	Loss 2.8734 (2.8608)	Acc@1 98.438 (99.115)	Acc@5 100.000 (99.953)
Epoch: [96][500/600]	Time 0.221 (0.242)	Data 0.154 (0.172)	Loss 2.8333 (2.8606)	Acc@1 100.000 (99.102)	Acc@5 100.000 (99.947)
 * Acc@1 99.096 Acc@5 99.945
epoch 96, total time 146.47
Test: [0/586]	Time 0.078 (0.078)	Loss 3.2023 (3.2023)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.052 (0.061)	Loss 3.1461 (3.1426)	Acc@1 78.125 (79.703)	Acc@5 96.875 (94.895)
Test: [200/586]	Time 0.072 (0.059)	Loss 2.9811 (3.0944)	Acc@1 90.625 (82.914)	Acc@5 100.000 (95.569)
Test: [300/586]	Time 0.058 (0.060)	Loss 3.0249 (3.0804)	Acc@1 84.375 (83.544)	Acc@5 100.000 (95.930)
Test: [400/586]	Time 0.054 (0.061)	Loss 3.4114 (3.0677)	Acc@1 56.250 (84.453)	Acc@5 93.750 (96.049)
Test: [500/586]	Time 0.071 (0.061)	Loss 3.0817 (3.0747)	Acc@1 90.625 (84.019)	Acc@5 93.750 (95.902)
 * Acc@1 84.164 Acc@5 96.080
==> training...
Epoch: [97][0/600]	Time 0.260 (0.260)	Data 0.191 (0.191)	Loss 2.8627 (2.8627)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [97][100/600]	Time 0.228 (0.241)	Data 0.158 (0.171)	Loss 2.8553 (2.8597)	Acc@1 98.438 (99.118)	Acc@5 100.000 (99.938)
Epoch: [97][200/600]	Time 0.262 (0.246)	Data 0.190 (0.175)	Loss 2.8707 (2.8604)	Acc@1 98.438 (99.114)	Acc@5 100.000 (99.953)
Epoch: [97][300/600]	Time 0.258 (0.251)	Data 0.184 (0.180)	Loss 2.8406 (2.8610)	Acc@1 100.000 (99.060)	Acc@5 100.000 (99.953)
Epoch: [97][400/600]	Time 0.273 (0.250)	Data 0.198 (0.179)	Loss 2.8684 (2.8609)	Acc@1 98.438 (99.073)	Acc@5 100.000 (99.949)
Epoch: [97][500/600]	Time 0.241 (0.249)	Data 0.169 (0.179)	Loss 2.8672 (2.8609)	Acc@1 98.438 (99.096)	Acc@5 100.000 (99.953)
 * Acc@1 99.122 Acc@5 99.951
epoch 97, total time 149.37
Test: [0/586]	Time 0.061 (0.061)	Loss 3.1969 (3.1969)	Acc@1 71.875 (71.875)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.070 (0.064)	Loss 3.1395 (3.1380)	Acc@1 75.000 (79.610)	Acc@5 96.875 (95.111)
Test: [200/586]	Time 0.065 (0.063)	Loss 2.9743 (3.0906)	Acc@1 90.625 (82.960)	Acc@5 100.000 (95.709)
Test: [300/586]	Time 0.052 (0.064)	Loss 3.0268 (3.0795)	Acc@1 84.375 (83.534)	Acc@5 96.875 (95.972)
Test: [400/586]	Time 0.054 (0.063)	Loss 3.4181 (3.0668)	Acc@1 50.000 (84.414)	Acc@5 93.750 (96.065)
Test: [500/586]	Time 0.054 (0.063)	Loss 3.0873 (3.0739)	Acc@1 87.500 (84.119)	Acc@5 93.750 (95.908)
 * Acc@1 84.313 Acc@5 96.090
==> training...
Epoch: [98][0/600]	Time 0.271 (0.271)	Data 0.197 (0.197)	Loss 2.8599 (2.8599)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [98][100/600]	Time 0.271 (0.251)	Data 0.201 (0.180)	Loss 2.8512 (2.8563)	Acc@1 100.000 (99.273)	Acc@5 100.000 (99.938)
Epoch: [98][200/600]	Time 0.218 (0.252)	Data 0.148 (0.181)	Loss 2.8548 (2.8564)	Acc@1 100.000 (99.168)	Acc@5 100.000 (99.914)
Epoch: [98][300/600]	Time 0.237 (0.250)	Data 0.167 (0.180)	Loss 2.8271 (2.8567)	Acc@1 100.000 (99.169)	Acc@5 100.000 (99.927)
Epoch: [98][400/600]	Time 0.278 (0.248)	Data 0.202 (0.178)	Loss 2.8772 (2.8571)	Acc@1 98.438 (99.166)	Acc@5 100.000 (99.942)
Epoch: [98][500/600]	Time 0.234 (0.247)	Data 0.164 (0.177)	Loss 2.8441 (2.8583)	Acc@1 100.000 (99.136)	Acc@5 100.000 (99.947)
 * Acc@1 99.138 Acc@5 99.953
epoch 98, total time 148.49
Test: [0/586]	Time 0.053 (0.053)	Loss 3.2199 (3.2199)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.070 (0.063)	Loss 3.1494 (3.1424)	Acc@1 78.125 (79.765)	Acc@5 96.875 (95.019)
Test: [200/586]	Time 0.063 (0.063)	Loss 2.9763 (3.0943)	Acc@1 90.625 (82.820)	Acc@5 100.000 (95.538)
Test: [300/586]	Time 0.067 (0.063)	Loss 3.0233 (3.0804)	Acc@1 84.375 (83.513)	Acc@5 100.000 (95.889)
Test: [400/586]	Time 0.072 (0.062)	Loss 3.4257 (3.0688)	Acc@1 50.000 (84.414)	Acc@5 93.750 (96.072)
Test: [500/586]	Time 0.056 (0.062)	Loss 3.0938 (3.0757)	Acc@1 90.625 (84.088)	Acc@5 93.750 (95.883)
 * Acc@1 84.222 Acc@5 96.080
==> training...
Epoch: [99][0/600]	Time 0.277 (0.277)	Data 0.210 (0.210)	Loss 2.8686 (2.8686)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [99][100/600]	Time 0.267 (0.249)	Data 0.197 (0.178)	Loss 2.8557 (2.8566)	Acc@1 100.000 (99.350)	Acc@5 100.000 (99.969)
Epoch: [99][200/600]	Time 0.249 (0.249)	Data 0.178 (0.177)	Loss 2.8521 (2.8575)	Acc@1 100.000 (99.293)	Acc@5 100.000 (99.961)
Epoch: [99][300/600]	Time 0.253 (0.251)	Data 0.184 (0.180)	Loss 2.8505 (2.8571)	Acc@1 100.000 (99.268)	Acc@5 100.000 (99.969)
Epoch: [99][400/600]	Time 0.216 (0.251)	Data 0.150 (0.181)	Loss 2.8670 (2.8575)	Acc@1 98.438 (99.240)	Acc@5 100.000 (99.957)
Epoch: [99][500/600]	Time 0.254 (0.251)	Data 0.182 (0.180)	Loss 2.8795 (2.8580)	Acc@1 100.000 (99.214)	Acc@5 100.000 (99.953)
 * Acc@1 99.208 Acc@5 99.953
epoch 99, total time 150.44
Test: [0/586]	Time 0.050 (0.050)	Loss 3.1964 (3.1964)	Acc@1 75.000 (75.000)	Acc@5 93.750 (93.750)
Test: [100/586]	Time 0.068 (0.063)	Loss 3.1342 (3.1350)	Acc@1 78.125 (80.105)	Acc@5 93.750 (95.111)
Test: [200/586]	Time 0.057 (0.062)	Loss 2.9752 (3.0885)	Acc@1 90.625 (83.116)	Acc@5 100.000 (95.709)
Test: [300/586]	Time 0.053 (0.062)	Loss 3.0154 (3.0765)	Acc@1 84.375 (83.700)	Acc@5 100.000 (95.982)
Test: [400/586]	Time 0.066 (0.061)	Loss 3.4210 (3.0656)	Acc@1 59.375 (84.515)	Acc@5 93.750 (96.049)
Test: [500/586]	Time 0.061 (0.061)	Loss 3.0869 (3.0730)	Acc@1 84.375 (84.026)	Acc@5 93.750 (95.883)
 * Acc@1 84.169 Acc@5 96.069
==> training...
Epoch: [100][0/600]	Time 0.289 (0.289)	Data 0.218 (0.218)	Loss 2.8568 (2.8568)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [100][100/600]	Time 0.259 (0.249)	Data 0.184 (0.178)	Loss 2.8290 (2.8568)	Acc@1 100.000 (99.165)	Acc@5 100.000 (99.923)
Epoch: [100][200/600]	Time 0.225 (0.250)	Data 0.156 (0.179)	Loss 2.8716 (2.8575)	Acc@1 98.438 (99.176)	Acc@5 100.000 (99.930)
Epoch: [100][300/600]	Time 0.281 (0.249)	Data 0.209 (0.178)	Loss 2.8752 (2.8582)	Acc@1 98.438 (99.206)	Acc@5 100.000 (99.927)
Epoch: [100][400/600]	Time 0.261 (0.249)	Data 0.190 (0.178)	Loss 2.8680 (2.8585)	Acc@1 100.000 (99.197)	Acc@5 100.000 (99.938)
Epoch: [100][500/600]	Time 0.233 (0.249)	Data 0.164 (0.178)	Loss 2.8542 (2.8587)	Acc@1 100.000 (99.198)	Acc@5 100.000 (99.944)
 * Acc@1 99.206 Acc@5 99.951
epoch 100, total time 149.83
Test: [0/586]	Time 0.064 (0.064)	Loss 3.1995 (3.1995)	Acc@1 75.000 (75.000)	Acc@5 90.625 (90.625)
Test: [100/586]	Time 0.065 (0.064)	Loss 3.1511 (3.1428)	Acc@1 78.125 (79.981)	Acc@5 93.750 (94.833)
Test: [200/586]	Time 0.067 (0.064)	Loss 2.9866 (3.0941)	Acc@1 90.625 (83.240)	Acc@5 100.000 (95.600)
Test: [300/586]	Time 0.062 (0.063)	Loss 3.0272 (3.0818)	Acc@1 84.375 (83.544)	Acc@5 93.750 (95.816)
Test: [400/586]	Time 0.073 (0.062)	Loss 3.4325 (3.0698)	Acc@1 56.250 (84.367)	Acc@5 93.750 (95.979)
Test: [500/586]	Time 0.055 (0.062)	Loss 3.0895 (3.0763)	Acc@1 90.625 (84.101)	Acc@5 93.750 (95.833)
 * Acc@1 84.308 Acc@5 96.021
==> Saving...
